{"meta":{"title":"流岚雅舍","subtitle":"","description":"猪老大同学的学习历程","author":"猪老大","url":"https://lankning.github.io"},"pages":[{"title":"","date":"2022-12-14T13:49:38.376Z","updated":"2022-12-14T13:49:38.376Z","comments":true,"path":"Readme.html","permalink":"https://lankning.github.io/Readme.html","excerpt":"","text":"这是我的博客，站点列表： https://hexo.wenyuanhome.top https://lankning.github.io https://lankning.gitee.io 推送帮助： 从0开始 12345678mkdir lankningcd lankninggit init touch README.mdgit add README.mdgit commit -m &quot;first commit&quot;git remote add origin https://gitee.com/lankning/lankning.gitgit push -u origin &quot;master&quot; 已有仓库 123cd existing_git_repogit remote add origin https://gitee.com/lankning/lankning.gitgit push -u origin &quot;master&quot;"},{"title":"关于","date":"2021-08-14T06:11:46.000Z","updated":"2021-08-15T05:31:20.000Z","comments":true,"path":"about/index.html","permalink":"https://lankning.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Go语言环境配置","slug":"Go语言环境配置","date":"2022-12-05T09:08:07.000Z","updated":"2022-12-07T03:08:17.495Z","comments":true,"path":"2022/12/05/Go语言环境配置/","link":"","permalink":"https://lankning.github.io/2022/12/05/Go%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"Go语言很火，我用的一个开源git项目gogs就是用的Go语言写的，使用很方便。我喜欢他的一点就是可以在不同平台上编译不不同的可执行二进制文件，用户直接把二进制文件拿走就好了，很方便！ 这篇介绍了Go语言换源、编译中找不到gcc等问题的解决方案。","text":"Go语言很火，我用的一个开源git项目gogs就是用的Go语言写的，使用很方便。我喜欢他的一点就是可以在不同平台上编译不不同的可执行二进制文件，用户直接把二进制文件拿走就好了，很方便！ 这篇介绍了Go语言换源、编译中找不到gcc等问题的解决方案。 Go换源 12345# 先看下go语言的设置go env# 换源go env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn 找不到gcc Windows cmd终端报错如下，找不到gcc而已，所以我们需要在windows上面装一个gcc并添加到环境变量里面 1cgo: C compiler &quot;gcc&quot; not found: exec: &quot;gcc&quot;: executable file not found in %PATH% 安装MinGW-w64软件，官网网址：MinGW-w64 - for 32 and 64 bit Windows - Browse &#x2F;mingw-w64&#x2F;mingw-w64-release at SourceForge.net 选择自己指令集的对应安装包下载后解压，记住解压路径添加环境变量即可 不能使用相对路径执行 1panic: look executable path: exec: &quot;gogs.exe&quot;: cannot run executable found relative to current directory 改为绝对路径","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"Coding","slug":"Coding","permalink":"https://lankning.github.io/tags/Coding/"}],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"论文阅读：视频插帧算法Super-SloMo","slug":"学习笔记/论文阅读：视频插帧算法Super-SloMo","date":"2022-11-11T02:41:27.000Z","updated":"2022-11-12T03:51:46.390Z","comments":true,"path":"2022/11/11/学习笔记/论文阅读：视频插帧算法Super-SloMo/","link":"","permalink":"https://lankning.github.io/2022/11/11/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E8%A7%86%E9%A2%91%E6%8F%92%E5%B8%A7%E7%AE%97%E6%B3%95Super-SloMo/","excerpt":"Super SloMo是一个视频插帧模型，提出于2018年CVPR论文《Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation 》，提出机构是NVIDIA。 该模型是VFI领域一个重要的模型，在当时存在方法均为单帧插值时应用了多帧插值，并效果领先。","text":"Super SloMo是一个视频插帧模型，提出于2018年CVPR论文《Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation 》，提出机构是NVIDIA。 该模型是VFI领域一个重要的模型，在当时存在方法均为单帧插值时应用了多帧插值，并效果领先。 阅读目标本文是阅读目标的第二篇，Super SloMo模型，阅读进度2&#x2F;7。 索引 模型名 发表期刊 提出方 年份 1 FILM ECCV 2022 Google 2022 2 Super SloMo CVPR 2018 Nvidia 2018 3 Quadratic Video Interpolation (QVI) NeurIPS 2019 商汤科技 2019 4 Depth-Aware Video Frame Interpolation (DAIN) CVPR 2019 上海交大 2019 5 Softmax Splatting (SS) CVPR 2020 波兰州立大学 2020 6 MEMC-Net IEEE Transactions on Pattern Analysis and Machine Intelligence 上海交大 2021 7 RIFE ECCV 2022 旷视&amp;北大 2022 写作逻辑Abstract摘要是文章内容的汇总，主要包括行业背景、本文工作、本文结果。实际上这篇论文摘要就是这么写的，我从这三个角度来提炼摘要内容。 行业背景：视频插值是从两个给定的空间、时间连续的视频帧中生成一个或多个中间帧（定义） 目前大多数方法关注单帧插值，即在两帧中插入一个中间帧 本文工作：我们提出了一种端到端的神经网络用于可变长度多帧插值，包括了运动插值和遮挡推理 细节：使用了U-Net进行双向光流计算，然后使用另一个U-Net来完善光流并且预测软视图（soft-visibility maps），最后将两个输入帧扭曲（warp）并线性融合得到中间帧 本文结果：消除伪影，在现存方法中中获得最好结果 1. IntroductionP1 应用场景：美好回忆发生时，你只用了标准帧率来录制视频… P2 应用场景+别人工作：视频插帧很有研究价值，既可以生成平滑的视图转换，也可以应用在自监督学习中（引用别人工作：从未标记视频中获取光流信号） P3 现有问题：由于时空都要连贯，所以多帧插值困难。 P4 别人工作：现有方法都是单帧插值，不能直接多帧插值。可以递归插值，但是至少有两个弊端： 递归插值无法并行化，并且插值错误也会传递 只能进行（2的指数次-1）插值 P5 本文工作：提出了变长度多帧插值方法（variable-length multi-frame interpolation method，这里的变长度应该指的是可以插任意多帧，对应递归插值弊端2）。结合现有问题和别人工作弊端谈自己网络结构和创新点。 P6 本文工作：训练设置 3. Proposed Approach3.1 视频帧融合 Intermediate Frame Synthesis 前文说到提出的方法是warp输入帧然后线性组合的，融合公式表述如下，g(·)代表反向补偿函数backward warping function，α0也是张量，由时序运动和遮挡推理决定，⊙代表元素尺度相乘： 考虑到遮挡问题（occlusion problem），引入了视图visibility maps变量V，把上面的α0用V和t来表达，此处的Z为归一化因子，融合公式进一步可以如下表述： 3.2 任意时间流插值 Arbitrary-time Flow Interpolation 以下面像素点为例： 橙色点p从t到1的大致光流可以使用0到1的光流来按比例截取，大致光流计算如下： 和RGB图像融合的时序连续相近，我们能使用双向光流预估t时刻到0&#x2F;1的光流： 这里不明白，为啥是二阶的呢？ 按照这种方法计算出来的光流可视化如下，第2行的是大致光流，第3行的是refined光流。 为了处理遮挡关系，作者使用了流插值网络ﬂow interpolation CNN预测了从t到0和从1到t的两种视图掩膜V。两种掩膜满足以下约束关系，否则网络训练会发散。 整个网络的架构如下： 4. Experiments 视频解析这是论文第一作者在CVPR 2018 spotlights上的分享，时长4分钟。国内有人搬运到B站了，这里直接分享。 词句积累 Given two consecutive frames 给定两个连续帧 intermediate frame(s) 中间帧 form both spatially and temporally coherent video sequences 形成空间和时间连续的视频序列 motion interpretation and occlusion reasoning 运动插值和遮挡推理 bi-directional optical ﬂow 双向光流 reﬁne the approximated ﬂow 完善大致光流 we exclude the contribution of occluded pixels to the interpolated intermediate frame to avoid artifacts 我们将被遮挡像素对插值的作用排除以避免伪影 we use 1,132 240-fps video clips 我们使用了1132个240fps的视频段 demonstrate that our approach performs consistently better than existing methods 证明了我们的方法总是比现有方法表现好 professional high-speed cameras are still required for higher frame rates 专业的高速相机仍然因更高帧率而被需要 it is of great interest to generate high-quality slow-motion video from existing videos 从现有视频产生高质量慢动作视频是有研究价值的 generate smooth view transitions 生成平滑的视图转换 It is challenging to generate multiple intermediate video frames because the frames have to be coherent, both spatially and temporally. 多帧插值有挑战性，因为时空都要连续。 Existing methods mainly focus on single-frame video interpolation and have achieved impressive performance for this problem setup. 现有方法主要关注单帧插值，并在此问题设置下取得了令人印象深刻的结果 it is an appealing idea to xx是一个很有吸引力的想法 recursive single-frame interpolation 递归单帧插值 interpolate a frame at any arbitrary time step between two frames 在两帧见任意时间插值一帧 参考文献 代码仓库：https://github.com/avinashpaliwal/Super-SloMo 知乎：视频插帧论文：Super SloMo - 知乎 (zhihu.com)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"论文阅读：视频插帧算法-FILM","slug":"学习笔记/论文阅读：视频插帧算法FILM","date":"2022-11-08T03:26:27.000Z","updated":"2022-11-11T15:35:02.766Z","comments":true,"path":"2022/11/08/学习笔记/论文阅读：视频插帧算法FILM/","link":"","permalink":"https://lankning.github.io/2022/11/08/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E8%A7%86%E9%A2%91%E6%8F%92%E5%B8%A7%E7%AE%97%E6%B3%95FILM/","excerpt":"视频插帧算法（video frame interpolation, VFI）是一种用于提高视频帧率的算法。一些较早的方法通过计算光流进行运动补偿进行视频插帧（VFI），但光流计算实现复杂，后续计算全部依赖光流对其精度要求也高。随着神经网络的兴起，很多CNN-based视频插帧算法被提出来解决VFI任务。","text":"视频插帧算法（video frame interpolation, VFI）是一种用于提高视频帧率的算法。一些较早的方法通过计算光流进行运动补偿进行视频插帧（VFI），但光流计算实现复杂，后续计算全部依赖光流对其精度要求也高。随着神经网络的兴起，很多CNN-based视频插帧算法被提出来解决VFI任务。 阅读目标本系列文章依然属于论文阅读部分，本文作为视频插帧VFI算法经典论文阅读的第一篇，阅读对象是FILM。 暂定阅读的模型和论文如下表，希望整体读完后对自己在论文写作和网络设计方面有一定启发。 索引 模型名 发表期刊 提出方 年份 1 FILM ECCV 2022 Google 2022 2 Super SloMo CVPR 2018 Nvidia 2018 3 Quadratic Video Interpolation (QVI) NeurIPS 2019 商汤科技 2019 4 Depth-Aware Video Frame Interpolation (DAIN) CVPR 2019 上海交大 2019 5 Softmax Splatting (SS) CVPR 2020 波兰州立大学 2020 6 MEMC-Net IEEE Transactions on Pattern Analysis and Machine Intelligence 上海交大 2021 7 RIFE ECCV 2022 旷视&amp;北大 2022 写作逻辑2022 ECCV会议上，Google提出了FILM网络，该网络在视频插帧任务上完成度较高。 整篇文章创新点在于首创地解决了near-duplicate photos interpolation任务 提出了multi-scale shared feature extractor，解决了大尺度运动问题 采用了Gram matrix loss来度量感知损失，最后产出了高质量帧 引入了single unified network，解决了传统算法训练复杂的问题 Abstract 已完成工作（总）：我们提出了一种FI算法，能合成图片间的慢动作 行业背景：近乎相同图片的插值是个有趣的应用，但是大尺度运动对现有方法造成挑战 已完成工作（细节）：基于大小尺度的小大运动一致性假设，提出了共享参数的特征提取器；为了解决大尺度畸变，提出了GRAM Loss；为了简化训练，提出了联合单一网络（也就是e2e）代替光流计算 已获得结果：在数据集上与SOTA对比取得最优表现 1. IntroductionP1 重要概念界定：给出FI定义P2 行业背景&#x2F;应用场景：可以为电子照相插值获得视频，并揭示一些场景运动，最后获得更愉悦的场景P3 同行工作：在小运动方面做得很好，但是较少关注大运动P4，P5，P6 自己工作和同行工作对比，同行工作哪里做的不好，自己如何解决P7 总结summary 2. Related Work总：总结其他工作的共同点，提出自己工作的独创性。 分：从大尺度运动、图像质量、单步网络三个角度总结了其他插帧工作的不足和自己工作的创新点。 3. MethodFILM有3个主要步骤：共享参数特征提取（Feature Extraction）、尺度不可知的运动预测（Flow Estimation）、融合（Fusion）。 Feature Extraction 输入图像金字塔一共有7层（pyramid level），实际上就是上图中Input pyramids，表示如下 $${I_0^l,I_1^l},l∈[1,7]$$ 对不同level输入图片提取多尺度特征，如上图Feature Extraction竖向的部分，表示如下 $$f^{l,d}&#x3D;H^d(I_0^l),d∈[1,4]$$ Hd是a stack of convolutions, f是输入l level、d层的特征 拼接concat Flow Estimation we use them (前面提取器得出的F0和F1) to calculate a bi-directional motion at each pyramid level. 这里说的bi-directional motion指的是t→0和t→1运动，t是中间帧索引 这里和其他论文一样都是从coarsest level到细粒度，即l=7-&gt; l=1。 Warp张量递推式 当前W计算方式：下一level的W + (当前level帧0特征图、当前level帧1到t特征图)的非线性组合，也就是：粗粒度 + 细粒度。 此处是不是写的有问题，括号内应该是F1才对？ 当前level帧t相对1特征图（估测） 计算方式：下一level的Warp张量2X上采样 + 当前level帧1特征图的bilinear resample 就是对当前level的F进行粗粒度的warp而已，所以是估测值，带入到上式得到准确warp矩阵。 当前level帧t相对1特征图（输出） Fusion UNet-like decoder，一笔带过 数据集 这个里面的motion magnitude如何计算的？？ 其他部分：略视频解析搬运自youtube 词句积累 英文 中文 synthesizes an engaging slow-motion video 合成一个连续的慢动作视频 near-duplicate photos which often exhibit large scene motion 展示了大尺度运动的几乎相同的照片 pose challenges to 给..带来挑战 a feature extractor 一个特征提取器 relies on the intuition that 基于…的假设 large motion at fine scale 小尺度的大运动 small motion at coarser scales 粗尺度的小运动 boosts the number of available pixels 增加了可用像素数 inpaint wide disocclusions 粉饰大尺度畸变 synthesize crisp frames 合成清晰帧 measures the correlation differenc ebetwee nfeature 度量相关性区别 outperforms state-of-the-art methods 比SOTAs好 video synthesis 视频合成 synthesize intermediate images between a pair of input frames 在一系列输入帧中合成中间图像 with increasing reach 随着影响力不断扩大的… temporal up-sampling 时序上采样 increase refresh rate or create slow-motion videos 增强刷新率或者创造慢动作视频 with the advent of 随着..…的问世 the temporal spacing between near duplicates can be a second or more 临近重复帧时间间隔可以是一秒钟甚至更多 with commensurately 同时 consecutive video frames 连续视频帧 interpolation for large scene motion 大尺度运动的插值 CNN-based frame interpolation methods 基于CNN的帧插值方法 up-scale frame rate of videos 上采样视频帧率 perceptual loss 感知损失 Hd is a stack of convolutions Hd是一堆卷积 directly predict task oriented flow 直接预测任务姿态流 参考文献 FILM: Frame Interpolation for Large Motion (film-net.github.io) google-research&#x2F;frame-interpolation: FILM: Frame Interpolation for Large Motion, In ECCV 2022. (github.com) 附件 预训练模型：源文件在作者谷歌云盘 论文视频：源文件在youtube 链接: https://pan.baidu.com/s/1TvH_7IZT12xSpOr6ARKwGg?pwd=m3zx 提取码: m3zx 复制这段内容后打开百度网盘手机App，操作更方便哦","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"论文阅读：PP-YOLOv2","slug":"学习笔记/论文阅读：PP-YOLOv2","date":"2022-08-22T15:12:56.000Z","updated":"2022-08-23T13:48:58.900Z","comments":true,"path":"2022/08/22/学习笔记/论文阅读：PP-YOLOv2/","link":"","permalink":"https://lankning.github.io/2022/08/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APP-YOLOv2/","excerpt":"","text":"PP-YOLOv2是在PP-YOLOv1基础上进一步提高效率得到的，最后结果是性能进一步提高而推理时间几乎没有变化。PP-YOLOv2（Resnet50）的mAP从45.9%提升到49.5%（COCO2017测试集上），基于Resnet101的mAP达到了50.3%,在640*640输入下帧率为68.9FPS，经过TensorRT FP16精度的加速，最后帧率提升到106.5FPS。 1. 介绍PP-YOLOv2和YOLOv5l和YOLOv4-CSP具有几乎相同的参数，但性能好一些。PP-YOLOv2的baseline是PP-YOLO，而PP-YOLO又是YOLO-v3的增强版本。Github仓库：https://github.com/PaddlePaddle/PaddleDetectionGitee镜像：https://gitee.com/paddlepaddle/PaddleDetection 2. 回看PP-YOLO2.1 预处理 模型权重初始化使用Beta(α,β)分布 图片使用随机颜色崩坏、随机扩充、随机裁剪、随机翻转等tricks 将图片RGB归一化 2.2 基线模型在YOLO-v3上使用了10个提高性能但不损失效率的tricks，包括Deformable Conv，SSLD，CoordConv，DropBlock，SPP等。 2.3 训练策略使用了SGD优化，使用了小batch（96张图片分8个GPU），学习率逐步升高…. 3. PP-YOLOv2的改进3.1 路径聚合网络（Path Aggregation Network）在目标检测领域，探测不同尺度的目标是一个重要的挑战。在PP-YOLO里面使用了FPN（Feature Pyramid Network，特征金字塔网络）来组建自底向上的路径；此处，PP-YOLOv2采用了PAN的设计使用自顶向下的信息。 3.2 激活函数：MishMish公式如下： 3.3 更大的输入尺寸增大输入尺寸会扩大目标的区域，因此小尺度目标的信息会比以前更容易保存（我不理解！） Increasing the input size enlarges the area of objects. Thus, information of the objects on a small scale will be preserved easier than before. 3.4 IoU感知分支定义了IoU损失如下。感觉类似交叉熵，不过把输入p换成了σ(p) 4. 实验4.2 消融实验他们还做了消融实验，A是基线模型，每一个创新点加上去mAP都有一些提升。 5. 没用的尝试以下tricks尝试过，但没有带来性能提升： 余弦学习率衰减 骨干参数冻结 SiLU激活函数 pp yolov2.pdf","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"论文阅读：wenet","slug":"学习笔记/论文阅读：Wenet","date":"2022-08-09T10:00:00.000Z","updated":"2022-09-07T14:35:28.584Z","comments":true,"path":"2022/08/09/学习笔记/论文阅读：Wenet/","link":"","permalink":"https://lankning.github.io/2022/08/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AWenet/","excerpt":"Wenet是业内比较有名的语音识别网络，可以统一识别流式和非流式语音，并且是一个end2end网络。相比其他理论研究注重实用性，可以真实部署（咋感觉这么奇怪樂）","text":"Wenet是业内比较有名的语音识别网络，可以统一识别流式和非流式语音，并且是一个end2end网络。相比其他理论研究注重实用性，可以真实部署（咋感觉这么奇怪樂） 本文主要是wenet第一个版本的阅读笔记，对应论文地址 Abstract 主要工作：提出了WeNet，在单个模型中使用了双通道的U2来统一了流式&amp;非流式的端到端语音识别。 a new two-pass approach named U2 is implemented to unify streaming and non-streaming end-to-end (E2E) speech recognition in a single model. 动机：跨越了研究与应用的鸿沟，提供了一种高效的方式在真实世界部署自动语音识别的方法（ASR, automatic speech recognition），这也是和其他开源e2e工具的区别。 方法： 网络架构：开发了一种混合连接时序分类（CTC）&#x2F;注意力架构，transformer&#x2F;conformer作为编码器，注意力解码器对编码器的假设重新评分 We develop a hybird connectionist temporal classification (CTC)&#x2F;attention architecture with transformer or conformer as encoder and an attention decoder to rescore th CTC hypotheses. 流式&#x2F;非流式统一：使用动态的基于块的注意力机制，这会允许自注意力关注任意长度的正确内容 结果：相对错误率降低了5.03%（AISHELL-1数据集，非流式，比标准的transformer） WeNet2.1 模型架构Shared Encoder：由多个Transformer或Conformer组成，在适宜的延迟下考虑有限的上下文 CTC Decoder：由一系列线性层组成；根据shared encoder输出得到初步结果 Attention Decoder：由多个Transformer解析层组成；结合shared encoder的输出重新评估CTC输出，得到更精确结果 2.2.1 训练定义了一个组合损失函数，将CTC和AED（attention based encoder-decoder）模块的损失加权相加$$L_{combined}(x,y)&#x3D;\\lambda L_{CTC}(x,y)+(1-\\lambda)L_{AED}(x,y)$$对于流式&#x2F;非流式统一，在流式识别中采用固定的chunk size&#x3D;C将声音信号分割，这样就把流式识别问题转化成了chunk size为C的非流式问题。 2.2.2 解析（音频）Wenet提供了4种基于python的音频解析模式，分别是以下四种： 2.2 System Design这就是wenet整个流程，主要流程是数据准备、训练、解码、导出、runtime，底层使用pytorch写的。 注意：这里的Decoding不是前面网络里面的解析器，而是Python based音频解析","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorFlow2自定义算子","slug":"学习笔记/TensorFlow2自定义算子","date":"2022-07-31T08:57:26.000Z","updated":"2022-07-31T09:11:34.964Z","comments":true,"path":"2022/07/31/学习笔记/TensorFlow2自定义算子/","link":"","permalink":"https://lankning.github.io/2022/07/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/TensorFlow2%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AE%97%E5%AD%90/","excerpt":"仓库地址：https://github.com/tensorflow/custom-op 将仓库拉到本地，假设自定义算子名字是inno，复制zero_out文件夹重命名为tensorflow_inno，功能是（1）保留input的第一个数字；（2）input其他位置上的元素都变为原来2倍。","text":"仓库地址：https://github.com/tensorflow/custom-op 将仓库拉到本地，假设自定义算子名字是inno，复制zero_out文件夹重命名为tensorflow_inno，功能是（1）保留input的第一个数字；（2）input其他位置上的元素都变为原来2倍。 经过文件名修改，自定义算子tensorflow_inno的目录树如下： 123456789101112131415.├── BUILD├── cc│ ├── kernels（实现）│ │ └── inno_kernels.cc│ └── ops（注册）│ └── inno_ops.cc├── __init__.py└── python ├── __init__.py（空） └── ops ├── __init__.py（空） ├── inno_ops.py（调用.so动态链接库） ├── _inno_ops.so（编译后产生） └── inno_ops_test.py（调用inno_ops.py测试） 1. C实现（cc&#x2F;目录下）目录中，cc&#x2F;下的所有程序都调用tensorflow的c接口，cc&#x2F;ops注册了inno算子，cc&#x2F;kernels实现了inno算子。 12345├── cc│ ├── kernels（实现）│ │ └── inno_kernels.cc│ └── ops（注册）│ └── inno_ops.cc 先在ops目录下的inno_ops.cc中注册算子： 123456789101112#include &quot;tensorflow/core/framework/op.h&quot;#include &quot;tensorflow/core/framework/shape_inference.h&quot;using namespace tensorflow;REGISTER_OP(&quot;Inno&quot;) .Input(&quot;inp: int32&quot;) .Output(&quot;out: int32&quot;) .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) &#123; c-&gt;set_output(0, c-&gt;input(0)); return Status::OK();&#125;); 这里定义了算子的名称是Inno，输入名称inp，输出名称out，输出的shape（存疑：等于输入的shape？）。 在kernels下的inno_kernels.cc中实现算子（注意命名需要采用CamelCase，驼峰拼写法）： 1234567891011121314151617181920212223242526272829#include &quot;tensorflow/core/framework/op_kernel.h&quot;using namespace tensorflow;class InnoOp : public OpKernel &#123; public: explicit InnoOp(OpKernelConstruction* context) : OpKernel(context) &#123;&#125; void Compute(OpKernelContext* context) override &#123; // Grab the input tensor const Tensor&amp; input_tensor = context-&gt;input(0); auto input = input_tensor.flat&lt;int32&gt;(); // Create an output tensor Tensor* output_tensor = NULL; OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(), &amp;output_tensor)); auto output_flat = output_tensor-&gt;flat&lt;int32&gt;(); // Set all but the first element of the output tensor to double input. const int N = input.size(); for (int i = 1; i &lt; N; i++) &#123; output_flat(i) = (input(i) &lt;&lt; 1); &#125; // Preserve the first input value if possible. if (N &gt; 0) output_flat(0) = input(0); &#125;&#125;; 到此为止，已经定义好了tensorflow的算子。 2. Python Package（python&#x2F;目录下）后面我们会编译Python包（.whl），安装后目录和这里一样，因此可以推断这里是在书写Python Package的脚本。其编译过程是：c脚本-&gt;.so动态链接库-&gt;Python调用-&gt;.whl包。 1234567└── python ├── __init__.py（空） └── ops ├── __init__.py（空） ├── inno_ops.py（调用.so动态链接库） ├── _inno_ops.so（编译后产生） └── inno_ops_test.py（调用inno_ops.py测试） inno_ops.py里面调用了.so动态链接库，定义了一个接口inno_out。Python安装完成后，可以直接调用inno_out。 12345678910from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionfrom tensorflow.python.framework import load_libraryfrom tensorflow.python.platform import resource_loaderinno_ops = load_library.load_op_library( resource_loader.get_path_to_datafile(&#x27;_inno_ops.so&#x27;))inno_out = inno_ops.Inno inno_ops_test.py调用了inno_ops.py测试inno_out算子，使用以下语句判断输入和输出是否相等：self.assertAllClose(inno_out([[1, 2], [3, 4]]), np.array([[1, 4], [6, 8]]))。代码如下： 1234567891011121314151617181920212223from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport numpy as npfrom tensorflow.python.platform import testtry: from tensorflow_inno.python.ops.inno_ops import inno_outexcept ImportError: from inno_ops import inno_outclass InnoTest(test.TestCase): def testinno(self): with self.test_session(): self.assertAllClose( inno_out([[1, 2], [3, 4]]), np.array([[1, 4], [6, 8]]))if __name__ == &#x27;__main__&#x27;: test.main() 3. 其他文件 tensorflow_inno目录下，有一个BUILD文件。注意将其中文件名改为自己的。 tensorflow_inno上级目录（自定义算子的根目录），Makefile文件中的路径需要修改为自定义的路径。 MANIFEST.in文件里面有两行文字，需要改为自定义名字recursive-include tensorflow_zero_out *.sorecursive-include tensorflow_time_two *.so setup.py文件中定义了包的名称、版本号，可以保持默认。 4. 编译、安装在custom-op文件夹（tensorflow-inno上级目录）中，编译算子得到.so文件和.whl文件。执行下面三行命令即可安装完成。 123(zhouyi) inno-suanfa@ubuntu:~/zhuwk/custom-op$ make inno_pip_pkg(zhouyi) inno-suanfa@ubuntu:~/zhuwk/custom-op$ cd artifacts/(zhouyi) inno-suanfa@ubuntu:~/zhuwk/custom-op/artifacts$ pip install tensorflow_custom_ops-0.0.1-cp38-cp38-linux_x86_64.whl 进入Python测试算子功能，发现功能正常。 12345678910(zhouyi) inno-suanfa@ubuntu:~/zhuwk/custom-op/artifacts$ pythonPython 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tensorflow_inno as tfno&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; tfno.inno_out(inp=tf.constant([[1,2,3],[4,5,6]]),name=&quot;inno_op&quot;)&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=array([[ 1, 4, 6], [ 8, 10, 12]], dtype=int32)&gt; 5. 保存为单算子pb模型代码： 123456789101112131415161718192021222324import tensorflow as tfimport tensorflow_inno as tfnoclass newop(tf.keras.models.Model): def __init__(self): super(newop, self).__init__() def call(self, x): x = tfno.inno_out(inp=x, name=&quot;inno_op&quot;) return xopmodel = newop()opmodel.predict(tf.constant([[1,2],[3,4]]))print(opmodel.summary())import numpy as npfull_model = tf.function(lambda x: opmodel(x))full_model = full_model.get_concrete_function( tf.TensorSpec((2,2), np.int32))from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2# Get frozen ConcreteFunctionfrozen_func = convert_variables_to_constants_v2(full_model)frozen_func.graph.as_graph_def()# Save frozen graph from frozen ConcreteFunction to hard drivetf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=&quot;./&quot;, name=&quot;inno_op.pb&quot;, as_text=False) 输出： 12345678910Model: &quot;newop&quot;_________________________________________________________________Layer (type) Output Shape Param # =================================================================Total params: 0Trainable params: 0Non-trainable params: 0_________________________________________________________________None&#x27;./inno_op.pb&#x27; 使用netron可视化，节点属性如下","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://lankning.github.io/tags/TensorFlow/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorRT--Ubuntu下安装","slug":"学习笔记/TensorRT-Ubuntu下安装","date":"2022-07-19T05:37:00.000Z","updated":"2022-07-23T04:47:47.087Z","comments":true,"path":"2022/07/19/学习笔记/TensorRT-Ubuntu下安装/","link":"","permalink":"https://lankning.github.io/2022/07/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/TensorRT-Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85/","excerpt":"很多时候我们还是用的Linux环境作为开发环境，需要在Linux上安装TensorRT。这篇文章总结了在Ubuntu上安装TensorRT的步骤。","text":"很多时候我们还是用的Linux环境作为开发环境，需要在Linux上安装TensorRT。这篇文章总结了在Ubuntu上安装TensorRT的步骤。 软硬件环境：系统：Ubuntu 20.04 显卡：nVidia RTX 2060 laptop 一、安装显卡驱动去nVidia官网查找对应型号驱动下载并安装，linux下是.run后缀的文件。 https://www.nvidia.cn/Download/index.aspx 二、安装TensorRT1. 下载先去nVidia官网下载TensorRT安装包 链接：https://developer.nvidia.com/zh-cn/tensorrt 2. 安装环境我下载的文件名是：TensorRT-8.4.1.5.Linux.x86_64-gnu.cuda-11.6.cudnn8.4.tar.gz。需要安装对应版本的cudatoolkit和cudnn，先在conda里面查询cudatoolkit和cudnn可用版本，然后选择最相近的版本安装。 为了和其他环境隔离，创建一个tensorrt的专属环境。之后跟TensorRT相关的包全部安装在这个环境内。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879(base) inno-suanfa@ubuntu:~$ conda create -n trt python=3.10(base) inno-suanfa@ubuntu:~$ conda activate trt(trt) inno-suanfa@ubuntu:~$ conda search cudatoolkitLoading channels: done\\# Name Version Build Channel cudatoolkit 9.0 h13b8566_0 pkgs/main cudatoolkit 9.2 0 pkgs/main cudatoolkit 10.0.130 0 pkgs/main cudatoolkit 10.1.168 0 pkgs/main cudatoolkit 10.1.243 h6bb024c_0 pkgs/main cudatoolkit 10.2.89 hfd86e86_0 pkgs/main cudatoolkit 10.2.89 hfd86e86_1 pkgs/main cudatoolkit 11.0.221 h6bb024c_0 pkgs/main cudatoolkit 11.3.1 h2bc3f7f_2 pkgs/main(trt) inno-suanfa@ubuntu:~$ conda install cudatoolkit==11.3.1(trt) inno-suanfa@ubuntu:~$ conda search cudnnLoading channels: done\\# Name Version Build Channel cudnn 7.0.5 cuda8.0_0 pkgs/main cudnn 7.1.2 cuda9.0_0 pkgs/main cudnn 7.1.3 cuda8.0_0 pkgs/main cudnn 7.2.1 cuda9.2_0 pkgs/main cudnn 7.3.1 cuda10.0_0 pkgs/main cudnn 7.3.1 cuda9.0_0 pkgs/main cudnn 7.3.1 cuda9.2_0 pkgs/main cudnn 7.6.0 cuda10.0_0 pkgs/main cudnn 7.6.0 cuda10.1_0 pkgs/main cudnn 7.6.0 cuda9.0_0 pkgs/main cudnn 7.6.0 cuda9.2_0 pkgs/main cudnn 7.6.4 cuda10.0_0 pkgs/main cudnn 7.6.4 cuda10.1_0 pkgs/main cudnn 7.6.4 cuda9.0_0 pkgs/main cudnn 7.6.4 cuda9.2_0 pkgs/main cudnn 7.6.5 cuda10.0_0 pkgs/main cudnn 7.6.5 cuda10.1_0 pkgs/main cudnn 7.6.5 cuda10.2_0 pkgs/main cudnn 7.6.5 cuda9.0_0 pkgs/main cudnn 7.6.5 cuda9.2_0 pkgs/main cudnn 8.2.1 cuda11.3_0 pkgs/main(trt) inno-suanfa@ubuntu:~$ conda install cudnn==8.2.1 3. 安装TensorRT解压TensorRT的tar压缩包，添加解压后文件夹中的lib库到系统变量： 1(trt) inno-suanfa@ubuntu:~$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/inno-suanfa/Downloads/TensorRT-8.4.1.5/lib 安装python、uff、graphsurgeon、onnx_graphsurgeon子目录下面对应的wheel： 123(trt) inno-suanfa@ubuntu:~$ cd ~/Downloads/TensorRT-8.4.1.5/python(trt) inno-suanfa@ubuntu:~/Downloads/TensorRT-8.4.1.5/python$ pip3 install tensorrt-8.4.1.5-cp310-none-linux_x86_64.whl （代码仅演示安装python下的wheel，其他略） 安装完成对应的3个wheel后，可在python中import trt验证是否安装成功。 三、安装pycuda在trt环境中，先安装gcc和g++，然后用镜像安装pycuda。 123(trt) inno-suanfa@ubuntu:~$ conda install gcc gxx -c conda-forge(trt) inno-suanfa@ubuntu:~$ pip3 install pycuda -i [https://pypi.mirrors.ustc.edu.cn/simple/](http://pypi.mirrors.ustc.edu.cn/simple/)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"TensorRT","slug":"TensorRT","permalink":"https://lankning.github.io/tags/TensorRT/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"OpenCV连通域操作","slug":"学习笔记/OpenCV连通域操作","date":"2022-07-05T03:32:33.000Z","updated":"2022-07-07T06:57:24.000Z","comments":true,"path":"2022/07/05/学习笔记/OpenCV连通域操作/","link":"","permalink":"https://lankning.github.io/2022/07/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/OpenCV%E8%BF%9E%E9%80%9A%E5%9F%9F%E6%93%8D%E4%BD%9C/","excerpt":"图像中连通域是很有用的一个属性，自己实现会很麻烦，OpenCV已经实现。本文最终目的是调用OpenCV寻找图片中前2大连通域。 附件：contour.py","text":"图像中连通域是很有用的一个属性，自己实现会很麻烦，OpenCV已经实现。本文最终目的是调用OpenCV寻找图片中前2大连通域。 附件：contour.py 1. OpenCV读取、展示图片因为后面连通域函数接受的是二值化矩阵，因此要将图片读取并二值化。 12345img = cv2.imread(&quot;1.png&quot;,cv2.IMREAD_GRAYSCALE)img[img&gt;0] = 255cv2.imshow(&quot;img&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows() 2. OpenCV寻找连通域OpenCV寻找连通域的函数是cv2.findContours()，输入为图片矩阵image，模式mode，方法method，…，输出为外形元组contours，轮廓对应的属性hierarchy。 使用cv2.drawContours()函数即可将轮廓画在原图上，结果和原图是一样的。 12345678contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) print(type(contours)) # &lt;class &#x27;tuple&#x27;&gt;print(len(contours)) # 9print(contours[0].shape) # (6, 1, 2)cv2.drawContours(img,contours,-1,255,-1)cv2.imshow(&quot;img&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows() cv2.findContours()注释12345678(image: Mat, mode: Any, method: int, contours: ... = ..., hierarchy: ... = ..., offset: ... = ...) -&gt; Anyimage Source, an 8-bit single-channel image. Non-zero pixels are treated as 1&#x27;s. ZerofindContours(image, mode, method[, contours[, hierarchy[, offset]]]) -&gt; contours, hierarchy@brief Finds contours in a binary image.The function retrieves contours from the binary image using the algorithm @cite Suzuki85 . The contours are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the OpenCV sample directory. cv2.drawContours()注释12345678(image: Mat, contours: Any, contourIdx: Any, color: Any, thickness: ... = ..., lineType: ... = ..., hierarchy: ... = ..., maxLevel: ... = ..., offset: ... = ...) -&gt; Anyimage Destination image.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -&gt; image@brief Draws contours outlines or filled contours.The function draws contour outlines in the image if \\f$\\texttt&#123;thickness&#125; \\ge 0\\f$ or fills the area bounded by the contours if \\f$\\texttt&#123;thickness&#125;&lt;0\\f$ . The example below shows how to retrieve connected components from the binary image and label them: : 3. 保留前2大连通域相当于把除了前两大连通域之外的其他连通域赋值为0，使用contourArea()函数计算每一个连通域面积。 12345678910111213area = []for j in range(len(contours)): area.append(cv2.contourArea(contours[j]))max_idx = np.argmax(area)area[max_idx] = 0sub_max_idx = np.argmax(area)for k in range(len(contours)): if k != max_idx and k != sub_max_idx: cv2.fillPoly(img, [contours[k]], 0)cv2.imshow(&quot;img&quot;,img)cv2.waitKey(0)cv2.destroyAllWindows() 4. 函数封装 FCN网络返回one-hot编码的分割结果，第一层是背景，第二、三层是识别的目标。使用OpenCV实现最大拾取如下： 1234567891011121314151617181920212223def find_max_contour(img): &#x27;&#x27;&#x27; input shape: (300, 300, 3) first channel: background second channel: class 1 third channel: class 2 &#x27;&#x27;&#x27; h,w,d = img.shape label = np.zeros((h,w)) for i in range(d): if i == 0: continue else: img_channel = img[:,:,i] contours, _ = cv2.findContours(img_channel, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) area = [] for j in range(len(contours)): area.append(cv2.contourArea(contours[j])) max_idx = np.argmax(area) for k in range(len(contours)): if k == max_idx: cv2.fillPoly(label, [contours[k]], i) return label 结果如图 参考文献 https://blog.csdn.net/gaoranfighting/article/details/34877549 https://blog.csdn.net/qq_33854260/article/details/106297999 https://blog.csdn.net/fujian87232/article/details/115712763","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://lankning.github.io/tags/OpenCV/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorRT--Windows下使用","slug":"学习笔记/TensorRT--Windows下使用","date":"2022-05-31T03:37:31.000Z","updated":"2022-06-04T03:48:00.000Z","comments":true,"path":"2022/05/31/学习笔记/TensorRT--Windows下使用/","link":"","permalink":"https://lankning.github.io/2022/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/TensorRT--Windows%E4%B8%8B%E4%BD%BF%E7%94%A8/","excerpt":"上篇文章记录了如何在Win10下配置TensorRT，这篇将记录如何将一个最简单的超分辨率SRCNN的TensorFlow模型.tf转化为TensorRT的engin文件，最后使用TensorRT推导。","text":"上篇文章记录了如何在Win10下配置TensorRT，这篇将记录如何将一个最简单的超分辨率SRCNN的TensorFlow模型.tf转化为TensorRT的engin文件，最后使用TensorRT推导。 模型格式转换：.tf-&gt;.onnx 安装tf2onnx和onnxruntime 12pip install onnxruntimepip install git+https://github.com/onnx/tensorflow-onnx 转换命令 1python -m tf2onnx.convert --saved-model ./checkpoints/yolov4.tf --output model.onnx --opset 11 --verbose 成功生成onnx模型： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142(base) C:\\Users\\11197\\Desktop\\vitsr\\models&gt;python -m tf2onnx.convert --saved-model vitsr_4x.tf --output model.onnx --opset 11 --verbose2022-05-31 11:44:25.907286: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dllC:\\Users\\11197\\Miniconda3\\lib\\runpy.py:127: RuntimeWarning: &#x27;tf2onnx.convert&#x27; found in sys.modules after import of package &#x27;tf2onnx&#x27;, but prior to execution of &#x27;tf2onnx.convert&#x27;; this may result in unpredictable behaviour warn(RuntimeWarning(msg))2022-05-31 11:44:27,590 - WARNING - tf2onnx: ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/15572022-05-31 11:44:27.592219: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll2022-05-31 11:44:27.605153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 Laptop GPU computeCapability: 8.6coreClock: 1.56GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s2022-05-31 11:44:27.605279: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll2022-05-31 11:44:27.612433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll2022-05-31 11:44:27.612553: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll2022-05-31 11:44:27.615466: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll2022-05-31 11:44:27.616751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll2022-05-31 11:44:27.619042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll2022-05-31 11:44:27.621767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll2022-05-31 11:44:27.622415: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll2022-05-31 11:44:27.622605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 02022-05-31 11:44:27.623070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX AVX2To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.2022-05-31 11:44:27.623904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 Laptop GPU computeCapability: 8.6coreClock: 1.56GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s2022-05-31 11:44:27.624021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 02022-05-31 11:44:27.951984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:2022-05-31 11:44:27.952142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 02022-05-31 11:44:27.952264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N2022-05-31 11:44:27.952483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5484 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)2022-05-31 11:44:27,953 - WARNING - tf2onnx.tf_loader: &#x27;--tag&#x27; not specified for saved_model. Using --tag serve2022-05-31 11:44:36,348 - INFO - tf2onnx.tf_loader: Signatures found in model: [serving_default].2022-05-31 11:44:36,348 - WARNING - tf2onnx.tf_loader: &#x27;--signature_def&#x27; not specified, using first signature: serving_default2022-05-31 11:44:36,348 - INFO - tf2onnx.tf_loader: Output names: [&#x27;output_1&#x27;]2022-05-31 11:44:36.633737: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 12022-05-31 11:44:36.633977: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session2022-05-31 11:44:36.635395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 Laptop GPU computeCapability: 8.6coreClock: 1.56GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s2022-05-31 11:44:36.635531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 02022-05-31 11:44:36.635679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:2022-05-31 11:44:36.635805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 02022-05-31 11:44:36.635919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N2022-05-31 11:44:36.636120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5484 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)2022-05-31 11:44:36.699775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize function_optimizer: Graph size after: 702 nodes (567), 1002 edges (867), time = 11.066ms. function_optimizer: function_optimizer did nothing. time = 0.291ms.2022-05-31 11:44:37.342929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 Laptop GPU computeCapability: 8.6coreClock: 1.56GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s2022-05-31 11:44:37.343116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 02022-05-31 11:44:37.343250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:2022-05-31 11:44:37.343378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 02022-05-31 11:44:37.343482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N2022-05-31 11:44:37.343648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5484 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)WARNING:tensorflow:From C:\\Users\\11197\\Miniconda3\\lib\\site-packages\\tf2onnx\\tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.Instructions for updating:Use `tf.compat.v1.graph_util.extract_sub_graph`2022-05-31 11:44:37,499 - WARNING - tensorflow: From C:\\Users\\11197\\Miniconda3\\lib\\site-packages\\tf2onnx\\tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.Instructions for updating:Use `tf.compat.v1.graph_util.extract_sub_graph`2022-05-31 11:44:37.851693: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 12022-05-31 11:44:37.851885: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session2022-05-31 11:44:37.852918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 Laptop GPU computeCapability: 8.6coreClock: 1.56GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s2022-05-31 11:44:37.853025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 02022-05-31 11:44:37.853114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:2022-05-31 11:44:37.853190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 02022-05-31 11:44:37.853276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N2022-05-31 11:44:37.853433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5484 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)2022-05-31 11:44:37.999328: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize constant_folding: Graph size after: 348 nodes (-354), 538 edges (-464), time = 22.997ms. function_optimizer: function_optimizer did nothing. time = 0.407ms. constant_folding: Graph size after: 348 nodes (0), 538 edges (0), time = 4.128ms. function_optimizer: function_optimizer did nothing. time = 0.246ms.2022-05-31 11:44:39,646 - INFO - tf2onnx: inputs: [&#x27;input_1:0&#x27;]2022-05-31 11:44:39,646 - INFO - tf2onnx: outputs: [&#x27;Identity:0&#x27;]2022-05-31 11:44:39,894 - INFO - tf2onnx.tfonnx: Using tensorflow=2.5.0, onnx=1.11.0, tf2onnx=1.10.0/16eb4b2022-05-31 11:44:39,895 - INFO - tf2onnx.tfonnx: Using opset &lt;onnx, 11&gt;2022-05-31 11:44:48,170 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding2022-05-31 11:44:54,755 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)2022-05-31 11:44:54,810 - VERBOSE - tf2onnx.tfonnx: Summay Stats: tensorflow ops: Counter(&#123;&#x27;Const&#x27;: 199, &#x27;Mul&#x27;: 26, &#x27;AddV2&#x27;: 25, &#x27;Conv3D&#x27;: 22, &#x27;BiasAdd&#x27;: 22, &#x27;Relu&#x27;: 22, &#x27;ConcatV2&#x27;: 7, &#x27;Squeeze&#x27;: 6, &#x27;Identity&#x27;: 5, &#x27;StridedSlice&#x27;: 4, &#x27;DepthToSpace&#x27;: 3, &#x27;Split&#x27;: 2, &#x27;Softmax&#x27;: 2, &#x27;Placeholder&#x27;: 1, &#x27;NoOp&#x27;: 1, &#x27;ResizeBilinear&#x27;: 1, &#x27;Pad&#x27;: 1&#125;) tensorflow attr: Counter(&#123;&#x27;dtype&#x27;: 200, &#x27;value&#x27;: 199, &#x27;data_format&#x27;: 47, &#x27;dilations&#x27;: 22, &#x27;padding&#x27;: 22, &#x27;strides&#x27;: 22, &#x27;N&#x27;: 7, &#x27;Tidx&#x27;: 7, &#x27;squeeze_dims&#x27;: 6, &#x27;begin_mask&#x27;: 4, &#x27;ellipsis_mask&#x27;: 4, &#x27;end_mask&#x27;: 4, &#x27;new_axis_mask&#x27;: 4, &#x27;shrink_axis_mask&#x27;: 4, &#x27;block_size&#x27;: 3, &#x27;num_split&#x27;: 2, &#x27;shape&#x27;: 1, &#x27;align_corners&#x27;: 1, &#x27;half_pixel_centers&#x27;: 1&#125;) onnx mapped: Counter(&#123;&#x27;Const&#x27;: 111, &#x27;Mul&#x27;: 26, &#x27;AddV2&#x27;: 25, &#x27;Conv3D&#x27;: 22, &#x27;BiasAdd&#x27;: 22, &#x27;Relu&#x27;: 22, &#x27;ConcatV2&#x27;: 7, &#x27;Squeeze&#x27;: 6, &#x27;Identity&#x27;: 4, &#x27;StridedSlice&#x27;: 4, &#x27;DepthToSpace&#x27;: 3, &#x27;Split&#x27;: 2, &#x27;Softmax&#x27;: 2, &#x27;Placeholder&#x27;: 1, &#x27;ResizeBilinear&#x27;: 1, &#x27;Pad&#x27;: 1&#125;) onnx unmapped: Counter()2022-05-31 11:44:54,811 - INFO - tf2onnx.optimizer: Optimizing ONNX model2022-05-31 11:44:54,811 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose2022-05-31 11:44:54,969 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Add -22 (47-&gt;25), Const +23 (128-&gt;151), Identity -3 (5-&gt;2), Reshape +45 (0-&gt;45), Transpose -44 (52-&gt;8)2022-05-31 11:44:54,970 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample2022-05-31 11:44:54,991 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change2022-05-31 11:44:54,992 - VERBOSE - tf2onnx.optimizer: Apply fold_constants2022-05-31 11:44:55,022 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -1 (1-&gt;0), Const -43 (151-&gt;108), Reshape -43 (45-&gt;2), Transpose -1 (8-&gt;7)2022-05-31 11:44:55,023 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer2022-05-31 11:44:55,039 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change2022-05-31 11:44:55,039 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer2022-05-31 11:44:55,056 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change2022-05-31 11:44:55,056 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication2022-05-31 11:44:55,075 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -3 (108-&gt;105)2022-05-31 11:44:55,076 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer2022-05-31 11:44:55,092 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change2022-05-31 11:44:55,093 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer2022-05-31 11:44:55,109 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change2022-05-31 11:44:55,109 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer2022-05-31 11:44:55,127 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change2022-05-31 11:44:55,127 - VERBOSE - tf2onnx.optimizer: Apply remove_identity2022-05-31 11:44:55,143 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Identity -2 (2-&gt;0)2022-05-31 11:44:55,143 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back2022-05-31 11:44:55,159 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change2022-05-31 11:44:55,159 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer2022-05-31 11:44:55,176 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change2022-05-31 11:44:55,176 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose2022-05-31 11:44:55,196 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change2022-05-31 11:44:55,197 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample2022-05-31 11:44:55,213 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change2022-05-31 11:44:55,214 - VERBOSE - tf2onnx.optimizer: Apply fold_constants2022-05-31 11:44:55,756 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change2022-05-31 11:44:55,757 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer2022-05-31 11:44:55,773 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change2022-05-31 11:44:55,773 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer2022-05-31 11:44:55,789 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change2022-05-31 11:44:55,790 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication2022-05-31 11:44:55,807 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: no change2022-05-31 11:44:55,807 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer2022-05-31 11:44:55,824 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change2022-05-31 11:44:55,824 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer2022-05-31 11:44:55,841 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change2022-05-31 11:44:55,842 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer2022-05-31 11:44:55,858 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change2022-05-31 11:44:55,858 - VERBOSE - tf2onnx.optimizer: Apply remove_identity2022-05-31 11:44:55,875 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change2022-05-31 11:44:55,875 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back2022-05-31 11:44:55,892 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change2022-05-31 11:44:55,892 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer2022-05-31 11:44:55,909 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change2022-05-31 11:44:55,911 - INFO - tf2onnx.optimizer: After optimization: Add -22 (47-&gt;25), Cast -1 (1-&gt;0), Const -23 (128-&gt;105), Identity -5 (5-&gt;0), Reshape +2 (0-&gt;2), Transpose -45 (52-&gt;7)2022-05-31 11:44:55,935 - INFO - tf2onnx:2022-05-31 11:44:55,935 - INFO - tf2onnx: Successfully converted TensorFlow model vitsr_4x.tf to ONNX2022-05-31 11:44:55,935 - INFO - tf2onnx: Model inputs: [&#x27;input_1&#x27;]2022-05-31 11:44:55,935 - INFO - tf2onnx: Model outputs: [&#x27;output_1&#x27;]2022-05-31 11:44:55,935 - INFO - tf2onnx: ONNX model is saved at model.onnx 生成engin文件在开发者手册里面第4章介绍了Python API，给了一些基本用法： 12345678910111213141516import tensorrt as trtlogger = trt.Logger(trt.Logger.WARNING)builder = trt.Builder(logger)network = builder.create_network(1 &lt;&lt; int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))parser = trt.OnnxParser(network, logger)success = parser.parse_from_file(&quot;models/model.onnx&quot;)for idx in range(parser.num_errors): print(parser.get_error(idx))if not success: pass # Error handling code hereconfig = builder.create_builder_config()config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 &lt;&lt; 20) # 1 MiBserialized_engine = builder.build_serialized_network(network, config)with open(&quot;sample.engine&quot;, &quot;wb&quot;) as f: f.write(serialized_engine) 使用该程序报错如下： 12345678(base) C:\\Users\\11197\\Desktop\\vitsr&gt;python quantization.py[05/31/2022-12:11:18] [TRT] [W] onnx2trt_utils.cpp:365: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.[05/31/2022-12:11:18] [TRT] [E] 4: [network.cpp::nvinfer1::Network::validate::3011] Error Code 4: Internal Error (Network has dynamic or shape inputs, but no optimization profile has been defined.)[05/31/2022-12:11:18] [TRT] [E] 2: [builder.cpp::nvinfer1::builder::Builder::buildSerializedNetwork::619] Error Code 2: Internal Error (Assertion engine != nullptr failed. )Traceback (most recent call last): File &quot;C:\\Users\\11197\\Desktop\\vitsr\\quantization.py&quot;, line 21, in &lt;module&gt; f.write(serialized_engine)TypeError: a bytes-like object is required, not &#x27;NoneType&#x27; 按照报错，根据开发者手册8.2 Optimization Profiles添加了一些配置： 1234profile = builder.create_optimization_profile()profile.set_shape(&quot;input_1&quot;, (1, 75, 75, 3), (1, 75, 75, 3), (1, 75, 75, 3))profile.set_shape(&quot;output_1&quot;, (1, 300, 300, 3), (1, 300, 300, 3), (1, 300, 300, 3))config.add_optimization_profile(profile) 最后生成成功 1234(base) C:\\Users\\11197\\Desktop\\srcnn&gt;python serialize.py[06/01/2022-11:54:18] [TRT] [W] onnx2trt_utils.cpp:365: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.[06/01/2022-11:54:19] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.8.0 but loaded cuBLAS/cuBLAS LT 11.5.1[06/01/2022-11:54:19] [TRT] [W] TensorRT was linked against cuDNN 8.3.2 but loaded cuDNN 8.2.1 推理这里我不太会写，在一篇知乎文章上修改：https://zhuanlan.zhihu.com/p/347172593 要注意的是，.engin文件的输入输出如下 12input_1 16875 &lt;class &#x27;numpy.float32&#x27;&gt;output_1 270000 &lt;class &#x27;numpy.float32&#x27;&gt; 字段分别是：name，size，dtype。输入时需要把图片flatten，输出时需要把图片reshape。 核心代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import numpy as npimport pycuda.autoinitimport pycuda.driver as cudaimport tensorrt as trtcfx = cuda.Device(0).make_context()stream = cuda.Stream()TRT_LOGGER = trt.Logger(trt.Logger.INFO)runtime = trt.Runtime(TRT_LOGGER)engine_file_path = &quot;sample.engine&quot;with open(engine_file_path, &quot;rb&quot;) as f: engine = runtime.deserialize_cuda_engine(f.read())context = engine.create_execution_context()host_inputs = []cuda_inputs = []host_outputs = []cuda_outputs = []bindings = []for binding in engine: size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size dtype = trt.nptype(engine.get_binding_dtype(binding)) print(binding, size, dtype) # 分配主机和设备buffers host_mem = cuda.pagelocked_empty(size, dtype) # 主机 cuda_mem = cuda.mem_alloc(host_mem.nbytes) # 设备 # 将设备buffer绑定到设备. bindings.append(int(cuda_mem)) # 绑定到输入输出 if engine.binding_is_input(binding): host_inputs.append(host_mem) # CPU cuda_inputs.append(cuda_mem) # GPU else: host_outputs.append(host_mem) cuda_outputs.append(cuda_mem)import timeimport numpy as npfrom PIL import Imagefor i in range(701,761): image = np.array(Image.open(&quot;./data/40_10_test/LR/Frame0%d.png&quot; % i))[np.newaxis,...] t1 = time.time() # 拷贝输入图像到主机buffer np.copyto(host_inputs[0], image.flatten()) # 将输入数据转到GPU. cuda.memcpy_htod_async(cuda_inputs[0], host_inputs[0], stream) # 推理. context.execute_async(bindings=bindings, stream_handle=stream.handle) # 将推理结果传到CPU. cuda.memcpy_dtoh_async(host_outputs[0], cuda_outputs[0], stream) # 同步 stream stream.synchronize() # 拿到推理结果 batch_size = 1 output = host_outputs[0].reshape(300,300,3) t2 = time.time() print(&quot;Inference time: %.2f ms&quot;%(1000*t2-1000*t1))cfx.pop() 命令行输出： 12345678910111213(base) C:\\Users\\11197\\Desktop\\srcnn&gt;python inference.py[06/01/2022-11:59:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +395, GPU +0, now: CPU 6761, GPU 1332 (MiB)[06/01/2022-11:59:25] [TRT] [I] Loaded engine size: 0 MiB[06/01/2022-11:59:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)[06/01/2022-11:59:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +34, now: CPU 0, GPU 35 (MiB)input_1 16875 &lt;class &#x27;numpy.float32&#x27;&gt;output_1 270000 &lt;class &#x27;numpy.float32&#x27;&gt;Inference time: 1.00 msInference time: 1.00 msInference time: 1.00 msInference time: 1.00 msInference time: 1.03 ms... 原来使用TensorFlow-GPU推理速度是50ms，现在竟然只要1ms，速度提升了50倍！！！ 参考文献 将 TensorFlow 模型转换为 ONNX：https://docs.microsoft.com/zh-cn/windows/ai/windows-ml/tutorials/tensorflow-convert-model https://github.com/NVIDIA/TensorRT/issues/301 https://zhuanlan.zhihu.com/p/347172593","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"TensorRT","slug":"TensorRT","permalink":"https://lankning.github.io/tags/TensorRT/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorRT--Windows下安装","slug":"学习笔记/TensorRT--Windows下安装","date":"2022-05-30T14:25:41.000Z","updated":"2022-06-01T04:07:48.000Z","comments":true,"path":"2022/05/30/学习笔记/TensorRT--Windows下安装/","link":"","permalink":"https://lankning.github.io/2022/05/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/TensorRT--Windows%E4%B8%8B%E5%AE%89%E8%A3%85/","excerpt":"使用NVIDIA产品进行量化后推理必须使用TensorRT才能加速，否则会默认使用CPU处理，比TensorFlow-GPU推理还慢。这篇文章记录如何在Windows上配置TensorFlow+TensorRT。","text":"使用NVIDIA产品进行量化后推理必须使用TensorRT才能加速，否则会默认使用CPU处理，比TensorFlow-GPU推理还慢。这篇文章记录如何在Windows上配置TensorFlow+TensorRT。 基本思路网上查到：先安装CUDA+cuDNN，下载对应版本的TensorRT将lib和include文件夹下的文件移到CUDA文件下覆盖即可。 安装过程实际操作我是先下载了TensorRT-8.4.0.6.Windows10.x86_64.CUDA-11.6.cuDNN8.3.zip包，对应CUDA 11.6和cuDNN 8.3，但是离谱的是在cuDNN官网上找不到适用CUDA 11.6版本的cuDNN，只好下了一个cuDNN 8.4 for CUDA 11.x，最后发现也能行。 根据NVIDIA官方文档，需要将下载后的TensorRT lib添文件夹加到系统路径（后面把include文件夹也添加扔进去了，不知道实际上需不需要），有两种方法： 去系统路径添加lib文件夹 将lib文件夹复制到 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.Y\\bin目录下 打开python子目录，安装tensorrt的wheel 在python内导入tensorrt，出现错误FileNotFoundError: Could not find: nvinfer.dll. Is it on your PATH? 1234567891011121314(base) C:\\WINDOWS\\system32&gt;pythonPython 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tensorrtTraceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;C:\\Users\\11197\\Miniconda3\\lib\\site-packages\\tensorrt\\__init__.py&quot;, line 127, in &lt;module&gt; ctypes.CDLL(find_lib(lib)) File &quot;C:\\Users\\11197\\Miniconda3\\lib\\site-packages\\tensorrt\\__init__.py&quot;, line 91, in find_lib raise FileNotFoundError(FileNotFoundError: Could not find: nvinfer.dll. Is it on your PATH?Note: Paths searched were:[&#x27;C:\\\\Users\\\\11197\\\\Miniconda3&#x27;, &#x27;C:\\\\Users\\\\11197\\\\Miniconda3\\\\Library\\\\mingw-w64\\\\bin&#x27;, &#x27;C:\\\\Users\\\\11197\\\\Miniconda3\\\\Library\\\\usr\\\\bin&#x27;, &#x27;C:\\\\Users\\\\11197\\\\Miniconda3\\\\Library\\\\bin&#x27;, &#x27;C:\\\\Users\\\\11197\\\\Miniconda3\\\\Scripts&#x27;, &#x27;C:\\\\Users\\\\11197\\\\Miniconda3\\\\bin&#x27;, &#x27;C:\\\\Users\\\\11197\\\\miniconda3\\\\condabin&#x27;, &#x27;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.6\\\\bin&#x27;, &#x27;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.6\\\\libnvvp&#x27;, &#x27;C:\\\\WINDOWS\\\\system32&#x27;, &#x27;C:\\\\WINDOWS&#x27;, &#x27;C:\\\\WINDOWS\\\\System32\\\\Wbem&#x27;, &#x27;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0&#x27;, &#x27;C:\\\\WINDOWS\\\\System32\\\\OpenSSH&#x27;, &#x27;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common&#x27;, &#x27;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin&#x27;, &#x27;C:\\\\Program Files\\\\Git\\\\cmd&#x27;, &#x27;C:\\\\Program Files\\\\dotnet&#x27;, &#x27;C:\\\\Program Files\\\\nodejs&#x27;, &#x27;C:\\\\Program Files\\\\NVIDIA Corporation\\\\Nsight Compute 2022.1.0&#x27;, &#x27;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR&#x27;, &#x27;C:\\\\Users\\\\11197\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\Scripts&#x27;, &#x27;C:\\\\Users\\\\11197\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39&#x27;, &#x27;C:\\\\Users\\\\11197\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps&#x27;, &#x27;C:\\\\Users\\\\11197\\\\.dotnet\\\\tools&#x27;, &#x27;C:\\\\Users\\\\11197\\\\AppData\\\\Roaming\\\\npm&#x27;]&gt;&gt;&gt; 打开TensorRT的__init__.py文件，发现find_lib函数如下： 12345678910111213141516171819def find_lib(name): paths = os.environ[&quot;PATH&quot;].split(os.path.pathsep) for path in paths: libpath = os.path.join(path, name) if os.path.isfile(libpath): return libpath raise FileNotFoundError( &quot;Could not find: &#123;:&#125;. Is it on your PATH?\\nNote: Paths searched were:\\n&#123;:&#125;&quot;.format(name, paths) ) 所有的lib都是在“Path”名称的变量下搜索的，因此在里面添加nvinfer.dll所在的目录 安装完成！ 顺便安装一下pycuda，之后会用到。 123456789101112131415161718192021(base) C:\\WINDOWS\\system32&gt;pip install pycudaLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.comCollecting pycuda Downloading pycuda-2021.1.tar.gz (1.7 MB) |████████████████████████████████| 1.7 MB 1.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... doneRequirement already satisfied: appdirs&gt;=1.4.0 in c:\\users\\11197\\miniconda3\\lib\\site-packages (from pycuda) (1.4.4)Requirement already satisfied: pytools&gt;=2011.2 in c:\\users\\11197\\miniconda3\\lib\\site-packages (from pycuda) (2022.1.9)Requirement already satisfied: mako in c:\\users\\11197\\miniconda3\\lib\\site-packages (from pycuda) (1.2.0)Requirement already satisfied: platformdirs&gt;=2.2.0 in c:\\users\\11197\\miniconda3\\lib\\site-packages (from pytools&gt;=2011.2-&gt;pycuda) (2.5.2)Requirement already satisfied: typing_extensions&gt;=4.0 in c:\\users\\11197\\miniconda3\\lib\\site-packages (from pytools&gt;=2011.2-&gt;pycuda) (4.1.1)Requirement already satisfied: MarkupSafe&gt;=0.9.2 in c:\\users\\11197\\miniconda3\\lib\\site-packages (from mako-&gt;pycuda) (2.1.1)Building wheels for collected packages: pycuda Building wheel for pycuda (PEP 517) ... done Created wheel for pycuda: filename=pycuda-2021.1-cp39-cp39-win_amd64.whl size=366136 sha256=51aa63305e507b7b54e47e1656f8ac8ee07f7311a55ec3266987f98ec67adb96 Stored in directory: C:\\Users\\11197\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ss72konn\\wheels\\8e\\e2\\ce\\6dbdd116792fcc3b7f5732eba784df2dbd8467a6c10f1592f5Successfully built pycudaInstalling collected packages: pycudaSuccessfully installed pycuda-2021.1 参考文献 https://developer.nvidia.com/zh-cn/tensorrt TrensorRT安装手册 TrensorRT开发者手册","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"TensorRT","slug":"TensorRT","permalink":"https://lankning.github.io/tags/TensorRT/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"部署Frp内网穿透","slug":"小技巧/2022-04-26-部署Frps内网穿透","date":"2022-04-26T14:01:43.000Z","updated":"2022-05-02T08:11:52.000Z","comments":true,"path":"2022/04/26/小技巧/2022-04-26-部署Frps内网穿透/","link":"","permalink":"https://lankning.github.io/2022/04/26/%E5%B0%8F%E6%8A%80%E5%B7%A7/2022-04-26-%E9%83%A8%E7%BD%B2Frps%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/","excerpt":"Frp是一个简单高效的内网穿透工具，在GitHub上开源，并有一直更新的release版本。","text":"Frp是一个简单高效的内网穿透工具，在GitHub上开源，并有一直更新的release版本。 官网 gofrp官网 gofrp官网示例 配置服务端修改.ini文件 12345678[common]bind_port = 7000dashboard_port = 7500token = passworddashboard_user = usernamedashboard_pwd = passwordvhost_http_port = 80vhost_https_port = 443 这里的vhost_http_port和vhost_https_port表示默认的http和https穿透端口，我们改成默认端口80和443。 如果设置vhost_http_port = 8080，那么客户端选择http服务时，要在子域名后面加上端口号才可以访问。 客户端修改.ini文件，如果http网站没有域名，可以使用tcp（如下方的ssh）；如果需要穿透到域名，则使用http&#x2F;https。 如果选择https，一般直接把SSL证书交给frp客户端，使用https转http的插件（自带）即可。如果内网部署的服务不在80端口，一定要在plugin_host_header_rewrite里面加上端口号！ 下面是我的配置，网站可以只开https，关掉http。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[common]server_addr = 公网IPserver_port = 7000token = password[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 7022[main_http]type = httplocal_port = 80custom_domains = doamin.com[main_https]type = httpscustom_domains = doamin.complugin = https2httpplugin_local_addr = 127.0.0.1:80# HTTPS 证书相关的配置plugin_crt_path = ./doamin.com_bundle.crtplugin_key_path = ./doamin.com.keyplugin_host_header_rewrite = 127.0.0.1plugin_header_X-From-Where = frp[hexo_http]type = httplocal_port = 7080custom_domains = hexo.doamin.com[hexo_https]type = httpscustom_domains = hexo.doamin.complugin = https2httpplugin_local_addr = 127.0.0.1:7080# HTTPS 证书相关的配置plugin_crt_path = ./hexo.doamin.com_bundle.crtplugin_key_path = ./hexo.doamin.com.keyplugin_host_header_rewrite = 127.0.0.1:7080plugin_header_X-From-Where = frp[trans_http]type = httplocal_port = 7050custom_domains = trans.doamin.com[trans_https]type = httpscustom_domains = trans.doamin.complugin = https2httpplugin_local_addr = 127.0.0.1:7050# HTTPS 证书相关的配置plugin_crt_path = ./trans.doamin.com_bundle.crtplugin_key_path = ./trans.doamin.com.keyplugin_host_header_rewrite = 127.0.0.1:7050plugin_header_X-From-Where = frp 然后开机自启动，在/etc/rc.local中添加，记得把frpc的地址改为自己的： 1nohup /root/tools/frp/frpc -c /root/tools/frp/frpc.ini &gt; /tmp/frp_client.log 2&gt;&amp;1 &amp; 域名解析域名解析是困扰我最多的一个问题，最后还是在frp官网上找到了答案。 http下面的二级域名不需要通过隐式url转到主域名:端口，而是直接A解析到IP地址即可。而https的话，在申请ssl证书时候，腾讯云会自动给加上解析。 参考文献 使用frp进行内网穿透 - 少数派 (sspai.com) 新手入门 - 详解 frp 内网穿透 frpc.ini 配置 - 思有云 - IOIOX 安装 | frp (gofrp.org) https://github.com/fatedier/frp/ 新手入门 - 详解 frp 内网穿透 frpc.ini 配置 - 思有云 - IOIOX 使用frp无域名http内网穿透配置 - 掘金 (juejin.cn)","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"论文阅读：Vision Transformer with Progressive Sampling","slug":"学习笔记/论文阅读：Vision-Transformer-with-Progressive-Sampling","date":"2021-10-12T02:33:45.000Z","updated":"2022-08-23T13:49:48.930Z","comments":true,"path":"2021/10/12/学习笔记/论文阅读：Vision-Transformer-with-Progressive-Sampling/","link":"","permalink":"https://lankning.github.io/2021/10/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AVision-Transformer-with-Progressive-Sampling/","excerpt":"PS-ViT是一个分类网络，发表于ICCV 2021上，特点是在ViT的基础上加入Progressive Sampling，获得更准确的结果。","text":"PS-ViT是一个分类网络，发表于ICCV 2021上，特点是在ViT的基础上加入Progressive Sampling，获得更准确的结果。 Abstract &amp; IntroductionTransformer的复杂度和输入序列的长度的平方成正比，因此ViT会将图片分为几个patch展开为1维向量输入Transformer进行计算，但是这种朴素的token化方法割裂了patch之间的自然结构，并且将网格分配在不感兴趣的地方例如背景，此外还引入了干扰信号。（However, such naive tokenization could destruct object structures, assign grids to uninterested regions such as background, and introduce interference signals.） 为了解决上述问题，我们提出了一种迭代渐进的采样策略来定位判别区域。To mitigate the above issues, in this paper, we propose an iterative and progressive sampling strategy to locate discriminative regions. 每一次迭代，当前采样步的嵌入会被送到Transformer中的编码器中，然后一组采样偏移将会被预测得出，以此来更新下一步采样的位置。At each iteration, embeddings of the current sampling step are fed into a transformer encoder layer, and a group of sampling offsets is predicted to update the sampling locations for the next step. Methodology这部分将介绍PS策略的具体实现，PS-ViT网络的总体架构，最后将阐述（elaborate）网络的细节。 Progressive Sampling渐进式采样的架构如下图所示，输入为$F\\in R^{C,H,W}$，输出为Token的序列$T_N\\in R^{C*(n*n)}$， 根据采样矩阵$p_t$在F上轴向采样得到$T’_i,i\\in[0,n^2]$， $T’i$和位置编码$P_t$，$T{t-1}$相加， 输入到Transformer Encoder得到编码后的$T_t$， $T_t$一方面输出，一方面经过FC Layer得到新的采样矩阵$p_{t+1}$。 此处的(nn)表示采样的数量，N表示迭代的次数。下一次的采样位置等于当前采样位置与偏置相加：$$p_{t+1}&#x3D;p_t+o_t,t\\in [1,2,…,N-1]$$$p_t$和$o_t$都在空间$R_{2(n*n)}$上，在第一次迭代的时候$p_1$初始化为规则间隔的样子。 用公式来表示，一目了然：$$T’_t&#x3D;F(p_t)\\\\P_t&#x3D;W_tp_t\\\\X_t&#x3D;T’t㊉P_t㊉T{t-1}\\\\T_t&#x3D;Transformer(X_t),t\\in[1,…,N]\\\\o_t&#x3D;M_tT_t,t\\in[1,…,N-1]$$上面的$M_t$是一种可学习的线性变换（应该是数层全连接层）。 Overall architecturePS-ViT的总体架构如下，总共有4个部分组成：(1) Feature Extraction; (2) Progressive Sampling; (3) Vision Transformer; (4) Classification Module 参考文献 论文地址：https://arxiv.org/pdf/2108.01684.pdf 仓库地址：https://github.com/yuexy/PS-ViT 百家号：https://baijiahao.baidu.com/s?id=1709038078774214330","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"论文阅读：Learning Texture Transformer Network for Image Super-Resolution","slug":"学习笔记/2021-09-19-论文阅读：Learning-Texture-Transformer-Network-for-Image-Super-Resolution","date":"2021-09-19T07:43:09.000Z","updated":"2022-08-23T13:49:58.051Z","comments":true,"path":"2021/09/19/学习笔记/2021-09-19-论文阅读：Learning-Texture-Transformer-Network-for-Image-Super-Resolution/","link":"","permalink":"https://lankning.github.io/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-09-19-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ALearning-Texture-Transformer-Network-for-Image-Super-Resolution/","excerpt":"CVPR 2020论文，提出了TTSR(Texture Transformer Network for Image Super-Resolution)网络，使用Transformer对图像超分重建。 论文地址：Learning-Texture-Transformer-Network-for-Image-Super-Resolution","text":"CVPR 2020论文，提出了TTSR(Texture Transformer Network for Image Super-Resolution)网络，使用Transformer对图像超分重建。 论文地址：Learning-Texture-Transformer-Network-for-Image-Super-Resolution 划过重点版本：Learning-Texture-Transformer-Network-for-Image-Super-Resolution 1. Abstract &amp; Introduction近来的研究都将HR Images作为reference(Ref)，在TTSR中，将LR和Ref分别作为Transformer中的queries和keys。TTSR包含了4个紧密相关的部分：纹理提取器DNN( learnable texture extractor, LTE)，相关性嵌入模块（a relevance embedding module, RE），纹理传输的硬注意力模块（a hard-attention module for texture transfer, HA），纹理合成的软注意力模块（a soft-attention module for texture synthesis, SA）。 此外，还提出了 a cross-scale feature integration module to stack the texture transformer，用于学习不同比例下的特征来得到更有力的特征表示。 2. Related Work2.1 Single Image Super ResolutionModels: SRCNN, VDSR, DRCN, EDSR, SRGAN, … Loss Function: MSE, MAE, perceptual loss(recent years), Gram matrix based texture matching loss, .. 2.2 Reference-based Image Super-ResolutionRefSR可以从Ref image获得更加准确的细节，这可以通过image aligning或者patch matching（搜索合适的Reference Information）造成。 Image aligning缺点：依赖于对齐质量，且对齐方法如光流法等是耗时的。 Patch matching缺点：However, SRNTT ignores the relevance between original and swapped features and feeds all the swapped features equally into the main network. (?) 3. Approach3.1 Texture TransformerTexture Transformer包含4个部分，LTE，RE，HA，SA，结构如图所示： 输入为Backbone(LR), Ref, Ref↓↑, LR↑，这里的↓↑分别代表使用Bicubic进行下、上插值，之所以对Ref先↓后↑是因为需要保持Ref↓↑与LR↑的域一致性（which is domain-consistent with LR↑）然后通过LTE得到K和Q；输出为合成的特征图（synthesized feature map）。 learnable texture extractor(LTE) $$Q&#x3D;LTE(LR↑),\\\\K&#x3D;LTE(Ref↓↑),\\\\V&#x3D;LTE(Ref),$$ relevance embedding module(RE) Relevance embedding aims to embed the relevance between the LR and Ref image by estimating the similarity between Q and K. 将Q&#x2F;K输出的结果patch为小块，相关性r即可由qi和ki通过标准化内积计算出来：$$q_i,(i \\in [1, H_{LR}×W_{LR}])\\\\k_j,(j \\in [1, H_{Ref}×W_{Ref}])\\\\r_{i,j}&#x3D;&lt;\\frac{q_i}{||q_i||},\\frac{k_i}{||k_i||}&gt;$$ hard-attention module for feature transfer(HA) 这一部分是将Ref的feature转移到当前图片的feature map中。传统方法是对不同的qi求V的加权和，但是这一操作可能会因为缺少Ref的feature导致模糊，所以我们在HA中仅仅将每个qi对应最相关的V值迁移出来。 具体来说，先由前述的ri,j计算hard-attention map H$$h_i&#x3D;\\mathop{argmax}\\limits_{j}r_{i,j}$$上述argmax函数是当ri,j最大时，返回对应的自变量，文中应该就是j，即qi确定时，对应最相关的kj存储在hi中。（原文： The value of hi can be regarded as a hard index, which represents the most relevant position in the Ref image to the i-th position in the LR image.） 为了获得tranferred HR texture features T，我们将拾取对应的V值到矩阵T中：$$t_i&#x3D;v_{h_i}$$因此，图中的T代表从Ref中迁移的最相关的对应纹理特征。 soft-attention module for feature synthesis(SA) 到了这一步，我们有了Ref的特征迁移矩阵T，LR的特征图F，本模块提出了一个soft-attention来合成特征。 Soft-attention map的矩阵S可由相关性ri,j计算得出：$$s_i&#x3D;\\mathop{max}\\limits_{j}r_{i,j}$$最后的特征图有下面计算得出：$$F_{out}&#x3D;F+Conv(Concat(F,T))⊙S$$⊙代表元素对应相乘。 3.2 Cross-Scale Feature Integration 使用上面提出的Texture Transformer堆叠，分别由1x&#x2F;2x&#x2F;4x混合，得到output。（套娃也可以这么6，学到了） 3.3 Loss Function本文的loss function包括Reconstruction loss，Adversarial loss，Perceptual loss三大块，总体的损失函数为三者的线性和，表示如下：$$L_{overall} &#x3D; λ_{rec}L_{rec} + λ_{adv}L_{adv} + λ_{per}L_{per}$$ 好的表述Image super-resolution aims to recover natural and realistic textures for a high-resolution image from its degraded low-resolution counterpart.（从其退化的低分辨率图片） The research on image SR is usually conducted on two paradigms, including single image super-resolution (SISR), and reference-based image super-resolution (RefSR).（范式） Although GANs…, the resultant hallucinations and artifacts caused by GANs further pose grand challenges to image SR tasks.（幻觉；伪影） SOTA（State-of-the-Art） First, … | Second, … | More specifically, … | Finally, … To the best of our knowledge, … （据我们所知，…）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"论文阅读：ConvTransformer A Convolutional Transformer Network for Video Frame Synthesis","slug":"学习笔记/2021-09-17-论文阅读：ConvTransformer","date":"2021-09-17T06:00:00.000Z","updated":"2022-08-23T13:50:05.381Z","comments":true,"path":"2021/09/17/学习笔记/2021-09-17-论文阅读：ConvTransformer/","link":"","permalink":"https://lankning.github.io/2021/09/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-09-17-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AConvTransformer/","excerpt":"这篇文章使用了Transformer对图像进行了帧合成操作，文章链接如下： ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis","text":"这篇文章使用了Transformer对图像进行了帧合成操作，文章链接如下： ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis 放上划过重点的论文文件：ConvTransformer Abstract &amp; IntroductionCNNs在视频帧合成时因为物体变形和移动、环境光改变、相机视角的移动，表现不佳。本文提出了ConvTransformer网络，核心组成要素（core ingredient）是attention layer &amp; multi-head convolutional self-attention，这些要素可以学习视频中帧的顺序依赖。经过实验，这个模型比ConvLSTM模型表现要好。 Related WorksVFI先说视频帧融合问题是长期存在的，具有挑战性和内在ill-posed的一个问题，因为自然图片和视频是多模态的。Video frame synthesis is a longstanding low-level computer vision problem, which is very challenging and inherently ill-posed since the multi-modal distribution of natural images and videos. 传统使用的是光流法（optical flow），但是optical flow对视频中的motion和光变十分敏感。 一些基于深度神经网络的算法替代了光流法，称为optical based methods。[18]训练了一个通用CNN来直接合成中间帧，但有时会导致运动模糊；[17]提出了一种3D光流网络，但是面对大尺度运动仍然力不从心；[20,21]将帧插值认为是局部卷积问题，提出了一种CNN对每个像素点都生成空间适应的卷积核，效果不错，但计算量大（suffer from heavy computation），而且面临着同样的对运动敏感的问题。 如今，针对VFI的包括了运动估计和运动补偿的子模块模型被提出，称为warping based methods。虽然warping based methods不仅获得了好的插值结果并有无监督运动估计的光明前景，these warping based deep models are mainly developed based on two consecutive frames for frame interpolation, while the higher-order motion information of video frame sequence is ignored and not be well exploited. 不同于warping based methods，Vilegas et al. 提出了一种ConvLSTM based method MC-Net for extrapolation方法，但是这种方法在两帧有长距离位移时不能建立有效的关联，且由于递归模型导致计算量大，和optical based methods相比表现也不佳。 TransformerTransformer是一种为了学习长范围的序列关系设计的一种新架构，开始成功应用于NLP任务如机器翻译、语音识别中。 具体而言，Zihang Dai et al. [8] 为了去除编码长度限制，在模型最后一部分采取了self-attention层建立各部分之间的联系，同时相对位置编码也被包含在他们的工作中。 Wu et al. [33] 减少了Transformer中的channel数，他们认为传统Transformer中有冗余信息，于是introduce了Long-Short Range Attention (LARA)来减少内存占用。 近期， Nicolas et al. 拓展了Transformer用于目标检测并且提出了DETR算法，并在COCO数据集上取得了和Faster RCNN相媲美的结果。DETR算法将二维分解为一维，通过self-attention替代了传统卷积的感受野。但DERT也不能应用于VFI领域，因为VFI和时间、空间高度相关。 Convolutional Transformer Architecture Algorithm Review输入 $$X&#x3D;{X_0,X_1,…,X_n}\\in R^{H×W×C}$$ 输出 $$X&#x3D;{X_{i+t_0},X_{i+t_1},…,X_{i+t_k}},t_k\\in [0,1]$$ 首先，特征嵌入模块嵌入了所有输入视频帧，然后生成对应的特征图feature map。 随后，特征图feature map与位置图positioned map相加得到positioned feature map用于位置标识。 接下来，positioned feature map输入到encoder中建立长范围的序列依赖关系，得到编码后的高级特征图high-level feature map。 再后面，high-level feature map和positioned frame queries同时被传入Decoder中，然后对query frames和 input sequential video frames之间的顺序依赖性进行解码。 最后，得到decoded feature maps，输入到Synthesis Feed-Forward Networks (SFFN)中得到interpolated frames。 Feature Embedding Feature Embedding模块采用了一个共享的卷积模块，包含了4个LeakyRelu激活的卷积，提取得到了Feature map。 Positional Encoding 与原始面向向量的Transformer不同的是，此处的positional encodings是一个3D Tensor，与frame feature map有相同的维度，因此两者可以求和。公式如下：$$PosMap_{(p,(i,j,2k))}&#x3D;sin(n&#x2F;10000^{2k&#x2F;d_{model}})\\\\PosMap_{(p,(i,j,2k+1))}&#x3D;cos(n&#x2F;10000^{2k&#x2F;d_{model}})$$此处，p代表position token，(i,j,2k)代表特征图上的空间位置，n代表输入的序列数量，$d_{model}$代表模型feature map的通道数(?)。 Encoder &amp; Decoder Encoder模块接收positioned feature map（表示为图中的${Z_t}$序列），the encoder is modeled as a stack of N identical layers，每一个stack由两个子层组成：多头卷积子注意力层、简单的2D卷积前馈层。模型中所有的子层都会采用相同维度的输出$d_{models}&#x3D;32$ Decoder模块也是composed of a stack of N identical layers，每个stack包含了3个子层，除了Encoder中的两个子层，还插入了一个称为查询自注意（query self-attention）的附加层，以对输出帧查询执行卷积自注意。 Multi-Head Convolutional Self-Attention 整个文章的灵魂，最重要的创新点！可以看到Convolution Self-Attention是使用一个CNN得到Q、K、V三个值（shape为H×W×3）；将所有的K值加上Qi（第i个输入的查询矩阵）再经过CNN得到H(i,j)，即key值j对输入i的attention map；当0&lt;&#x3D;j&lt;n的H(i,j)全部计算出来，就有了其集合$H(i)&#x3D;{H(i,1), H(i,2), · · ·, H(i,n)}$ ，在第3维度上取softmax；将所有输入的H和V对应相加，再将结果相加，输出得到第i个输入的convolutional self-attention；公式表达如下：$$Q_i,K_i,V_i&#x3D;CNN_1(U_i),Q,K,V\\in R^{H×W×3}\\\\H(i,j)&#x3D;CNN_2(Q_t,K_j),H\\in R^{H×W×1}\\\\H(i)&#x3D;Softmax({H(i,1), H(i,2), · · ·, H(i,n)})_d,d&#x3D;3\\\\V_i&#x3D;sum(V_j+H(i,j))$$使用多个这样的Conv Self-Attention Block并行，就可以得到每一个输入的self-attention矩阵。 Synthesis Feed-Forward Network没啥好说的，是一个unet类型的结构。 In order to synthesize the fifinal photo realistic video frames, we construct a frame synthesis feed-forward network, which consists of 2 cascaded sub-networks built upon a U-Net-like structure. 参考资料 https://arxiv.org/pdf/2012.12556 https://zhuanlan.zhihu.com/p/336169274","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"体重称制作2：系统设计","slug":"学习笔记/2021-09-02-体重称制作2：系统设计","date":"2021-09-02T14:17:09.000Z","updated":"2021-09-06T15:46:50.000Z","comments":true,"path":"2021/09/02/学习笔记/2021-09-02-体重称制作2：系统设计/","link":"","permalink":"https://lankning.github.io/2021/09/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-09-02-%E4%BD%93%E9%87%8D%E7%A7%B0%E5%88%B6%E4%BD%9C2%EF%BC%9A%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","excerpt":"记录制作一个体重称的流程，这一篇记录的是体重秤系统的组成。","text":"记录制作一个体重称的流程，这一篇记录的是体重秤系统的组成。 MISO和MOSI是什么意思https://blog.csdn.net/janifer_he/article/details/8236018 一、组成购买途径：淘宝 1. MircoPython ESP32开发板（LoLin32 Lite） 表1：Pin脚类型和数目 | Pin | LoLin32 | Lite version | | ------------------------------------------------------------ | ------- | ------------ | | 3V3 | x2 | x1 | | 5V | x1 | – | | GND | x5 | x1 | | EN | X | X | | VP | X | X | | VN | X | X | | RX/TX | X | – | | I/O GPIO 34, 35, 32, 33, 25, 26, 27, 14, 12, 22, 19, 23, 18, 5, 17, 16, 4, 0, 2, 15, 13 | x21 | x21 | 基本配置： Soc： Espressive ESP32-DOWD6Q Rev 1.0. Tensilica Xtensa LX6 双核处理器 连接： WiFi 802.11 b &#x2F; g &#x2F; n Bluetooth LE 接口： 所有Pin脚都以3.3V电压工作 micro USB供电 开发板资料：https://diyprojects.io/wemos-lolin32-lite-compact-revision-lolin32-4-90/ MicroPython教程：https://docs.micropython.org/en/latest/esp32/quickref.html 2. 应变式压力传感器 如图2，红&#x2F;黑线分别在上下端，白&#x2F;绿线在中间，后面红&#x2F;绿线一个通正点，一个接地，两者之间有电压，中间两根线就可以测量电势变化，传给下方的HX711模块转为数字信号。 3. XFW-HX711模块 HX711模块接线如图3所示，红&#x2F;黑接E+&#x2F;E-，蓝绿接A+&#x2F;A-。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"嵌入式","slug":"嵌入式","permalink":"https://lankning.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Transformer学习","slug":"学习笔记/2021-08-22-Transformer学习","date":"2021-08-22T07:04:14.000Z","updated":"2021-09-19T07:45:24.000Z","comments":true,"path":"2021/08/22/学习笔记/2021-08-22-Transformer学习/","link":"","permalink":"https://lankning.github.io/2021/08/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-08-22-Transformer%E5%AD%A6%E4%B9%A0/","excerpt":"公众号上看到有一些Transformer的跨界应用，感觉可以继续跨界，所以趁着周末学习一下Transformer网络。","text":"公众号上看到有一些Transformer的跨界应用，感觉可以继续跨界，所以趁着周末学习一下Transformer网络。 Transformer初始论文：Attention Is All You Need Self-Attention举个例子：输入为x1, x2，通过Transformer输出为z1, z2$$q_i&#x3D;x_iW^Q\\\\k_i&#x3D;x_iW^K\\\\v_i&#x3D;x_iW^V$$ x1和x2通过共享的系数阵$W^Q,W^K,W^V$得到了相应的$q,k,v$值，然后计算z1, z2$$z_1&#x3D;softmax(q_1k_1^T&#x2F;\\sqrt(d_k),q_1k_2^T&#x2F;\\sqrt(d_k))(v_1,v_2)^T\\\\z_2&#x3D;softmax(q_2k_1^T&#x2F;\\sqrt(d_k),q_2k_2^T&#x2F;\\sqrt(d_k))(v_1,v_2)^T$$ 此处的$d_k$指的是向量q,k的维度，q为query（查询），k为key（键），v为value（值），上面softmax做的工作实际上是用q去查询k，得到q1（q2）与k1、k2的相关性，再点积v1、v2得到结果值z1（z2）。 Vision Transformer综述论文：A Survey on Vision Transformer (Submitted on 23 Dec 2020) 参考资料 https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer https://www.tensorflow.org/tutorials/text/transformer https://zhuanlan.zhihu.com/p/343248914 测试视频：http://ultravideo.fi/#testsequences","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"ML","slug":"ML","permalink":"https://lankning.github.io/tags/ML/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"体重称制作1：MicroPython开发板","slug":"学习笔记/2021-08-21-体重称制作1：MicroPython开发板","date":"2021-08-21T08:44:28.000Z","updated":"2021-08-21T08:55:52.000Z","comments":true,"path":"2021/08/21/学习笔记/2021-08-21-体重称制作1：MicroPython开发板/","link":"","permalink":"https://lankning.github.io/2021/08/21/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-08-21-%E4%BD%93%E9%87%8D%E7%A7%B0%E5%88%B6%E4%BD%9C1%EF%BC%9AMicroPython%E5%BC%80%E5%8F%91%E6%9D%BF/","excerpt":"记录制作一个体重称的流程。这一篇讲的是如何让ESP32的MicroPython开发板连接电脑并刷入固件。","text":"记录制作一个体重称的流程。这一篇讲的是如何让ESP32的MicroPython开发板连接电脑并刷入固件。 开箱 刷固件 下载CH341的Windows串口驱动，下载地址：http://www.wch.cn/download/CH341SER_EXE.html 重新插拔开发板，发现电脑上识别出来开发板的串口COM3。！！注意下面要用到这个串口号！！ 先去MircoPython官网下载固件，因为我从淘宝上买的不知名板子，稳妥点刷通用版固件吧，下载页面：https://micropython.org/download/esp32/ 安装esptool的Python包 1pip install esptool 刷入固件，分为两步。先清除Flash，再写入固件。 12esptool --chip esp32 --port COM3 erase_flashesptool --chip esp32 --port COM3 write_flash -z 0x1000 esp32-20210623-v1.16.bin ThonnyThonny是一个Python IDE，在这里使用它的好处是可以方便地与开发板交互。在Thonny的主界面点击工具-设置-解释器，选择MicroPython (ESP32)解释器。如果一切顺利，则下面的Shell会变成MircoPython的样式，我们可以在Shell中指挥开发板运行命令。 在Shell中输入help()可以获得帮助信息： 12345678910111213141516171819202122232425262728293031323334&gt;&gt;&gt; help()Welcome to MicroPython on the ESP32!For generic online docs please visit http://docs.micropython.org/For access to the hardware use the &#x27;machine&#x27; module:import machinepin12 = machine.Pin(12, machine.Pin.OUT)pin12.value(1)pin13 = machine.Pin(13, machine.Pin.IN, machine.Pin.PULL_UP)print(pin13.value())i2c = machine.I2C(scl=machine.Pin(21), sda=machine.Pin(22))i2c.scan()i2c.writeto(addr, b&#x27;1234&#x27;)i2c.readfrom(addr, 4)Basic WiFi configuration:import networksta_if = network.WLAN(network.STA_IF); sta_if.active(True)sta_if.scan() # Scan for available access pointssta_if.connect(&quot;&lt;AP_name&gt;&quot;, &quot;&lt;password&gt;&quot;) # Connect to an APsta_if.isconnected() # Check for successful connectionControl commands: CTRL-A -- on a blank line, enter raw REPL mode CTRL-B -- on a blank line, enter normal REPL mode CTRL-C -- interrupt a running program CTRL-D -- on a blank line, do a soft reset of the board CTRL-E -- on a blank line, enter paste modeFor further help on a specific object, type help(obj)For a list of available modules, type help(&#x27;modules&#x27;) 附件下载 驱动下载 esp32 1.16通用固件下载 参考资料 MicroPython官方文档 MicroPython中文文档 https://thonny.org/ CSDN: 使用MicroPython开发ESP32 CH341 Windows驱动 Windows10下的固件烧录 LoLin32 Lite开发板信息 https://micropython.org/","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"嵌入式","slug":"嵌入式","permalink":"https://lankning.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"LSTM网络笔记","slug":"学习笔记/2021-08-18-LSTM","date":"2021-08-17T16:03:37.000Z","updated":"2022-06-01T09:57:52.000Z","comments":true,"path":"2021/08/18/学习笔记/2021-08-18-LSTM/","link":"","permalink":"https://lankning.github.io/2021/08/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-08-18-LSTM/","excerpt":"$LSTM$全称是$Long-Short Term Memory$，中文是“长短期记忆神经网络”。$LSTM$是$RNN$的一个变种，传统的$RNN$虽然有网络的中间值在按照时间序列传递，但是只拥有短期记忆，$LSTM$在传统$RNN$的基础上补上了长期记忆。","text":"$LSTM$全称是$Long-Short Term Memory$，中文是“长短期记忆神经网络”。$LSTM$是$RNN$的一个变种，传统的$RNN$虽然有网络的中间值在按照时间序列传递，但是只拥有短期记忆，$LSTM$在传统$RNN$的基础上补上了长期记忆。 特征$LSTM$中有两个重要概念： $hidden state$ &amp; $cell state$: 实际上$hidden state$里存储的，主要是“近期记忆”；$cell state$里存储的，主要是“远期记忆”。$cell state$的存在，使得$LSTM$得以对长依赖进行很好地刻画[1]。 [2]中详细描述了$LSTM$的结构。如图，$LSTM$先对输入进行$sigmoid$映射后，对之前传来的$cell$信息进行点乘（可以理解为$and$），这一步对之前的$cell$信息进行了部分遗忘。对$Input$信息进行非线性处理之后与$cell$信息相加，继续更新$cell$值，然而实际上的$Output$是$Input$经过了一个$sigmoid$函数的映射，并和更新后的$cell state$的数据相乘的结果。[2]的PDF版本获取：colah.github.io-2015-08-Understanding-LSTMs.pdf 下面为[3]中附带的视频，纯英文无字幕，对应网站原文阅读体验更佳，原文PDF获取：Illustrated Guide to LSTM’s and GRU’s.pdf 您的浏览器不支持 video 标签。 应用举个栗子，在论文”Neural State Machine for Character-Scene Interactions”中，构造了一种LSTM网络对游戏角色的动作进行捕获和预测，论文获取：https://github.com/sebastianstarke/AI... 演示视频搬运自Youtube 您的浏览器不支持 video 标签。 参考链接 https://zhuanlan.zhihu.com/p/115026734 http://colah.github.io/posts/2015-08-Understanding-LSTMs/ https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21 https://zhuanlan.zhihu.com/p/32085405 https://blog.csdn.net/PKU_Jade&#x2F;article&#x2F;details&#x2F;70195892","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Socket网络通讯","slug":"学习笔记/2021-08-15-Socket网络通讯","date":"2021-08-14T16:28:08.000Z","updated":"2021-08-15T05:00:28.000Z","comments":true,"path":"2021/08/15/学习笔记/2021-08-15-Socket网络通讯/","link":"","permalink":"https://lankning.github.io/2021/08/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-08-15-Socket%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/","excerpt":"Socket是一种基础的网络协议，在这种协议的基础上可以做很多事比如聊天室、文件传递等。","text":"Socket是一种基础的网络协议，在这种协议的基础上可以做很多事比如聊天室、文件传递等。 Socket通信原理 服务端new一个实例和socket绑定，然后监听 accept客户端的connect请求之后，read其内容 根据客户端的内容做出处理，反写（write）给客户端 客户端读取server的数据 … close Python代码Python代码分为server端和client端，实测通讯成功。C++因为VS的版本会报错（采用了新的接口之类），因此暂缓实现。 server.py 123456789101112131415161718192021222324#!/usr/bin/python# -*- coding: UTF-8 -*-# 文件名：server.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象# host = socket.gethostname() # 获取本地主机名host = &#x27;0.0.0.0&#x27; # 设置外网通讯port = 12123 # 设置端口s.bind((host, port)) # 绑定端口s.listen(5) # 等待客户端连接print(&quot;host:&quot;,host,&quot;port:&quot;,port,&quot;waiting...&quot;)while True: c,addr = s.accept() # 建立客户端连接 print(&#x27;Get connection from&#x27;, addr) c.send(bytes(&#x27;Success connecting from %s:%s&#x27;%addr, encoding=&#x27;UTF-8&#x27;)) while True: data = c.recv(1024) if not data: break print(data) c.send(data) c.close() # 关闭连接 client.py 123456789101112131415161718192021#!/usr/bin/python# -*- coding: UTF-8 -*-# 文件名：client.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象#host = socket.gethostname() # 获取本地主机名host = &#x27;1.117.177.117&#x27;port = 12123 # 设置端口号 s.connect((host, port))print(s.recv(1024))while True: inp = input(&quot;&gt;&gt;&gt;&quot;) if not inp: continue s.send(bytes(inp,encoding=&quot;utf-8&quot;)) print(s.recv(1024))# s.close() 参考文献 https://cloud.tencent.com/developer/article/1569435 https://www.runoob.com/w3cnote/android-tutorial-socket1.html https://www.runoob.com/python/python-socket.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"hexo添加Mathjax支持","slug":"学习笔记/2021-08-14-Hexo添加Mathjax支持","date":"2021-08-14T08:49:47.000Z","updated":"2021-08-14T09:02:10.000Z","comments":true,"path":"2021/08/14/学习笔记/2021-08-14-Hexo添加Mathjax支持/","link":"","permalink":"https://lankning.github.io/2021/08/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-08-14-Hexo%E6%B7%BB%E5%8A%A0Mathjax%E6%94%AF%E6%8C%81/","excerpt":"hexo换了一个主题，但是不支持Mathjax公式渲染。本文描述了如何向hexo的theme中加入Mathjax公式支持。","text":"hexo换了一个主题，但是不支持Mathjax公式渲染。本文描述了如何向hexo的theme中加入Mathjax公式支持。 操作方法 先在主题的layout/_partial/文件夹，创建一个叫做mathjax.ejs的文件，内容如下： 1234567891011121314151617181920&lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config(&#123; showProcessingMessages: false, messageStyle: &quot;none&quot;, extensions: [&quot;tex2jax.js&quot;], jax: [&quot;input/TeX&quot;, &quot;output/HTML-CSS&quot;], tex2jax: &#123; inlineMath: [ [&quot;$&quot;, &quot;$&quot;] ], displayMath: [ [&quot;$$&quot;,&quot;$$&quot;] ], skipTags: [&#x27;script&#x27;, &#x27;noscript&#x27;, &#x27;style&#x27;, &#x27;textarea&#x27;, &#x27;pre&#x27;,&#x27;code&#x27;,&#x27;a&#x27;], ignoreClass:&quot;comment-content&quot; &#125;, &quot;HTML-CSS&quot;: &#123; availableFonts: [&quot;STIX&quot;,&quot;TeX&quot;], showMathMenu: false &#125; &#125;); MathJax.Hub.Queue([&quot;Typeset&quot;,MathJax.Hub]); &lt;/script&gt; &lt;script src=&quot;//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt; 因为Hexo渲染文章的时候是通过layout/post.ejs进行的，所以在该文件最后一行的&lt;% &#125; %&gt;前面加载layout/_partial/mathjax.ejs文件，内容如下： 1&lt;%- partial(&#x27;_partial/mathjax&#x27;) %&gt; 参考链接 https://www.jianshu.com/p/0422327ce632 https://www.cnblogs.com/tianshifu/p/6388391.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lankning.github.io/tags/Hexo/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"共形几何的应用","slug":"学习笔记/2021-07-14-共形几何的应用","date":"2021-07-14T08:43:00.000Z","updated":"2022-04-29T09:48:04.000Z","comments":true,"path":"2021/07/14/学习笔记/2021-07-14-共形几何的应用/","link":"","permalink":"https://lankning.github.io/2021/07/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-07-14-%E5%85%B1%E5%BD%A2%E5%87%A0%E4%BD%95%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"顾险峰，清华大学计算机学士，哈佛大学博士，师从国际微分几何大师丘成桐先生。顾博士是计算共形几何领域的主要创始人之一，共形几何对于计算机视觉、机器视觉有着重要的意义。目前是纽约州立大学计算机系终身教授，哈佛大学数学科学与应用中心兼职教授。","text":"顾险峰，清华大学计算机学士，哈佛大学博士，师从国际微分几何大师丘成桐先生。顾博士是计算共形几何领域的主要创始人之一，共形几何对于计算机视觉、机器视觉有着重要的意义。目前是纽约州立大学计算机系终身教授，哈佛大学数学科学与应用中心兼职教授。 共形几何可以将3D模型的纹理细节变换到3个标准面上： 3D球面 欧式平面 双曲空间 流行的渲染方式：3D建模-&gt;共形几何展开-&gt;绘制纹理-&gt;纹理3D贴图 您的浏览器不支持 video 标签。 信息公开博客：https://www3.cs.stonybrook.edu/~gu&#x2F;公众号：老顾谈几何","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"IC设计流程简介","slug":"学习笔记/2021-07-12-IC设计流程简介","date":"2021-07-12T04:11:00.000Z","updated":"2021-08-14T07:31:12.000Z","comments":true,"path":"2021/07/12/学习笔记/2021-07-12-IC设计流程简介/","link":"","permalink":"https://lankning.github.io/2021/07/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-07-12-IC%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%E7%AE%80%E4%BB%8B/","excerpt":"今天上午由Coaship-阎如斌线上主讲，前面十几分钟都是无关紧要的背景部分，后面从17:40开始介绍整个芯片的设计流程。","text":"今天上午由Coaship-阎如斌线上主讲，前面十几分钟都是无关紧要的背景部分，后面从17:40开始介绍整个芯片的设计流程。 视频录屏Onedrive直链下载：https://link.jscdn.cn/sharepoint/aHR0cHM6Ly93aHVlZHVjbi1teS5zaGFyZXBvaW50LmNvbS86djovZy9wZXJzb25hbC93ZW5rYW5nX3podV93aHVfZWR1X2NuL0VTQXZCcnVKblQ5SW9kRFdiTWRuU05jQmMxcDNLVHcxNU04UVZUZmc3ODVOcEE_ZT1FUlBST1g.mp4 您的浏览器不支持 video 标签。 全流程流程图 设计算法部分主要是做这部分工作，C++进行功能搭建，RTL仿真等。 需求 验证 后端 Tips: Onedrive文件共享直链解析：https://onedrive.gimhoy.com/ Typecho嵌入video标签，需要在代码前后写上!!!","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"大文件传输方法","slug":"小技巧/2021-07-11-大文件传输方法","date":"2021-07-11T09:16:00.000Z","updated":"2021-08-14T08:02:02.000Z","comments":true,"path":"2021/07/11/小技巧/2021-07-11-大文件传输方法/","link":"","permalink":"https://lankning.github.io/2021/07/11/%E5%B0%8F%E6%8A%80%E5%B7%A7/2021-07-11-%E5%A4%A7%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E6%96%B9%E6%B3%95/","excerpt":"发送一个5G的文件，QQ邮箱超大附件限制3G，QQ传离线文件是有上限的，而且只为用户保存7天。逾期接收方不接收文件，系统将自动删除该文件。离线传送的文件，单个文件大小上限为4G。非会员享有2G&#x2F;天发送文件流量，文件保存7天。那么怎么办呢？","text":"发送一个5G的文件，QQ邮箱超大附件限制3G，QQ传离线文件是有上限的，而且只为用户保存7天。逾期接收方不接收文件，系统将自动删除该文件。离线传送的文件，单个文件大小上限为4G。非会员享有2G&#x2F;天发送文件流量，文件保存7天。那么怎么办呢？ QQ：在线传文件 小鹿快传：https://deershare.com/，一种P2P传输文件的方式 PP直连：https://www.ppzhilian.com/，一种P2P传输文件的方式","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"图床的使用心得","slug":"小技巧/2021-07-10-图床的使用心得","date":"2021-07-10T11:44:00.000Z","updated":"2021-08-14T08:03:58.000Z","comments":true,"path":"2021/07/10/小技巧/2021-07-10-图床的使用心得/","link":"","permalink":"https://lankning.github.io/2021/07/10/%E5%B0%8F%E6%8A%80%E5%B7%A7/2021-07-10-%E5%9B%BE%E5%BA%8A%E7%9A%84%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","excerpt":"博客文章图片可以放在服务器本机，也可以放在图床上。网络上有很多提供图床服务的网站，选用这类图床需要谨防站长跑路或被封；还可以利用Onedrive&#x2F;Github&#x2F;Gitee等搭建图床服务。","text":"博客文章图片可以放在服务器本机，也可以放在图床上。网络上有很多提供图床服务的网站，选用这类图床需要谨防站长跑路或被封；还可以利用Onedrive&#x2F;Github&#x2F;Gitee等搭建图床服务。 一、成熟的方案：使用已有图床服务结合网友推荐和自身实践，推荐以下几个图床： 路过图床：https://imgtu.com/这个图床服务稳定，加载速度很快！非常适合一般站长使用，但是上传频率限制在45次&#x2F;小时，上传大小也限制在10Mb以下。 picbed：https://www.picbed.cn/该图床服务稳定，加载速度慢了些。但是上传大小限制在80Mb以下，上传频率限制尚未知。 不推荐的图床： https://sm.ms/：有些网络下访问不了，直链打不开。 二、搭建图床服务按道理说Github和Gitee是代码托管平台，图片之类的文件也可以上传，上传就可以通过外链直接访问。这样的话，就可以使用Github或者Gitee搭建图床服务，但是这样未免有滥用之嫌疑。 可以手动上传，然后使用外链。也可使用脚本进行部署。 Onedrive等云盘直链获取：https://link.gimhoy.com/","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"Montgomery算法","slug":"学习笔记/2021-04-09-Montgomery算法","date":"2021-04-09T04:12:00.000Z","updated":"2021-08-14T07:31:16.000Z","comments":true,"path":"2021/04/09/学习笔记/2021-04-09-Montgomery算法/","link":"","permalink":"https://lankning.github.io/2021/04/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2021-04-09-Montgomery%E7%AE%97%E6%B3%95/","excerpt":"用途：一种高速的取模算法，当$a$，$b$，$N$很大时，加速计算$a*b(modN)$。","text":"用途：一种高速的取模算法，当$a$，$b$，$N$很大时，加速计算$a*b(modN)$。 一、原理1. 将$a$，$b$映射到Montgomery域内：$$a’&#x3D;aR(modN),b’&#x3D;bR(modN)$$ ​ 此处的$R&#x3D;2^k&gt;N$，令$X&#x3D;a’b’&#x3D;abR^2(modN)$ 2. $Montgomery$约简：$$\\begin{align}&amp;Input:X \\&amp;Output:X&#x2F;R\\end{align}$$ ​ 约简1次：$X&#x3D;abR^2(modN)$ -&gt; $X&#x2F;R&#x3D;abR(modN)$ ​ 约简2次：$X&#x3D;abR(modN)$ -&gt; $X&#x2F;R&#x3D;ab(modN)$ ​ $X&#x2F;R$是不可以直接除的，因为$X$的低$k$位很可能不都为0。因此希望有一个数$m$使得$$X+mN&#x3D;0(modR)$$​ 这样，约简函数的输入输出就变为：$$\\begin{align}&amp;Input:X \\&amp;Output:(X+mN)&#x2F;R\\end{align}$$ ​ 由拓展的欧几里得算法可以解出以下方程的一组特解：$$RR’-NN’&#x3D;gcd(R,N)$$​ 对上述两个公式进行推导，就可以得到$m$的计算方法：$$\\begin{align}&amp;XN’+mNN’&#x3D;0(modR)\\&amp;XN’+m(RR’-gcd(R,N))&#x3D;0(modR)\\&amp;XN’&#x3D;m*gcd(R,N)(modR)\\&amp;m&#x3D;XN’&#x2F;gcd(R,N)(modR)\\end{align}$$ ​ 通过阅读蒙哥马利算法原文可知，该算法限制$gcd(R,N)&#x3D;1$，​ 所以接着推演可以得到$$\\begin{align}&amp;X+mN&#x3D;X+XNN’(modR)&#x3D;X+(XN’(modR))N\\&amp;(X+mN)&#x2F;R&#x3D;(X+(XN’(modR))N)&#x2F;R\\end{align}$$ 二、优化加速1. 分析1次蒙哥马利算法中，进行了2次对$N$取模（$a-&gt;a’，b-&gt;b’$），2次对$R$取模（$reduction$），这就是我们需要优化的地方。对于Montgomery算法本身，它是把除法转化为移位算法，以下运算得到了简化：$$\\begin{align}&amp;aR&#x3D;a&lt;&lt;k\\&amp;bR&#x3D;b&lt;&lt;k\\&amp;(X+mN)&#x2F;R&#x3D;(X+mN)&gt;&gt;k\\end{align}$$ 2. 对$N$取模第1步计算$a’&#x3D;aR(modN),b’&#x3D;bR(modN)$时，若按照原来计算方法，一条转换的运算量可能就超过了$a*b(modN)$，所以通过模运算法则简化为：$$\\begin{align}&amp;a’&#x3D;(a(modN)*R(modN))(modN)\\&amp;b’&#x3D;(b(modN)*R(modN))(modN)\\end{align}$$ 3. 对$R$取模在reduction函数里面，进行了对R取模的运算，具体为$XN’(modR)$。因为$R&#x3D;2^k$，所以$XN’(modR)$相当于取$XN’$的后$k-1$位。$$XN’MODR &#x3D; XN’[0:k-1]$$此处，$[0:k-1]$为XN’的第$0~(k-1)$位。 三、Python实现声明：下面的代码来自GitHub，原作者是LivingLeopold 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import mathdef get_gcd(a,b): if a%b == 0: return b else : return get_gcd(b,a%b)def get_(a, b): if b == 0: return 1, 0 else: k = a // b remainder = a % b x1, y1 = get_(b, remainder) x, y = y1, x1 - k * y1 return x, ydef Multiplicative_inverse_modulo( a , b ): if b &lt; 0: m = abs(b) else: m = b flag = get_gcd(a, b) if flag == 1: x, y = get_(a, b) x0 = x % m return x0 else: print(&quot;Error!&quot;) exit()print(&#x27;To calculate a * b ( mod N ),&#x27;)a , b , N = eval(input(&#x27;Please input a , b , N (Like 68,57,109)：&#x27;))R = 2**(int(math.log2(N)+1))N1 = Multiplicative_inverse_modulo( N , R )N2 = R-N1a_ =( a * R ) % Nb_ =( b * R ) % Nc_ =((( a_ * b_ ) + ((( a_ * b_ ) * N2 ) % R ) * N )/ R ) % Nc = int(((c_ + ( c_* N2 ) % R * N ))/R)print( str(a) + &#x27; * &#x27; + str(b) + &#x27; ( mod &#x27; + str(N) +&#x27; ) = &#x27; + str(c)) 参考文献[1] 高效幂模算法探究：Montgomery算法解析[2] 蒙哥马利算法详解[3] 蒙哥马利算法约简、模乘、幂模[4] 欧几里得算法&amp;辗转相除法，百度百科[5] 拓展的欧几里得算法[6] RSA大数运算实现（1024位n）（5）蒙哥马利模幂[7] Python代码实现蒙哥马利算法[8] Markdown中输入多行并列的公式","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"考研：红宝书必考词","slug":"学习笔记/2020-10-18-考研：红宝书必考词","date":"2020-10-18T02:18:00.000Z","updated":"2021-08-14T07:31:26.000Z","comments":true,"path":"2020/10/18/学习笔记/2020-10-18-考研：红宝书必考词/","link":"","permalink":"https://lankning.github.io/2020/10/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-10-18-%E8%80%83%E7%A0%94%EF%BC%9A%E7%BA%A2%E5%AE%9D%E4%B9%A6%E5%BF%85%E8%80%83%E8%AF%8D/","excerpt":"单词很重要，红宝书很重要！","text":"单词很重要，红宝书很重要！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://lankning.github.io/tags/%E8%80%83%E7%A0%94/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"考研：高数18讲难题集","slug":"学习笔记/2020-10-18-考研：高数18讲难题集","date":"2020-10-18T01:09:00.000Z","updated":"2021-08-14T07:31:30.000Z","comments":true,"path":"2020/10/18/学习笔记/2020-10-18-考研：高数18讲难题集/","link":"","permalink":"https://lankning.github.io/2020/10/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-10-18-%E8%80%83%E7%A0%94%EF%BC%9A%E9%AB%98%E6%95%B018%E8%AE%B2%E9%9A%BE%E9%A2%98%E9%9B%86/","excerpt":"18讲是考研数学复习中几乎人手必备的一本书，我将自己在做题过程中不会的、做错的整理在这里。","text":"18讲是考研数学复习中几乎人手必备的一本书，我将自己在做题过程中不会的、做错的整理在这里。 参考资料：1、张宇–《高数18讲》及相关视频","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://lankning.github.io/tags/%E8%80%83%E7%A0%94/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"考研：概率论","slug":"学习笔记/2020-09-04-考研：概率论","date":"2020-09-04T07:15:00.000Z","updated":"2021-08-14T07:32:46.000Z","comments":true,"path":"2020/09/04/学习笔记/2020-09-04-考研：概率论/","link":"","permalink":"https://lankning.github.io/2020/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-09-04-%E8%80%83%E7%A0%94%EF%BC%9A%E6%A6%82%E7%8E%87%E8%AE%BA/","excerpt":"概率论一般不会出难题，主要记忆。","text":"概率论一般不会出难题，主要记忆。 第一讲 随机条件与概率 全概率公式 贝叶斯公式 n重伯努利公式 第二讲 一维随机变量及其分布 要明白几大离散型分布的实际情况，八大分布的概率密度和分布函数。 正态分布记得看图。 第三讲 多维随机变量及其分布 联合概率密度和边缘概率密度之间的关系 Z&#x3D;X+Y型的边缘概率密度求解（公式法，分布函数家法） 全概率公式 第四讲 随机变量的数字特征不难，多背多记，防切比雪夫出题。 第五、六讲 大数定律和中心极限定律&amp;数理统计这一块三大分布写了两遍，第二次写完才大概明白意思。 参考资料：1、张宇–《考研数学基础30讲》及相关视频2、汤家凤–《概率论》（数理统计部分）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://lankning.github.io/tags/%E8%80%83%E7%A0%94/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"考研：高数下","slug":"学习笔记/2020-08-25-考研：高数下","date":"2020-08-25T05:14:00.000Z","updated":"2021-08-14T07:33:36.000Z","comments":true,"path":"2020/08/25/学习笔记/2020-08-25-考研：高数下/","link":"","permalink":"https://lankning.github.io/2020/08/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-08-25-%E8%80%83%E7%A0%94%EF%BC%9A%E9%AB%98%E6%95%B0%E4%B8%8B/","excerpt":"高数占整个数学一考研的56%，属于数学一的基本盘。","text":"高数占整个数学一考研的56%，属于数学一的基本盘。 第11讲 多元函数微分学P157-170，这一讲概念比较多，东西比较杂，但是内容不难，计算量比较大。 第12讲 二重积分二重积分原理上不太难，但是需要掌握几个要点。 几何意义 对称性，其中轮换对称性还比较重要 直角坐标和极坐标的互化 积分次序的变更 用二重积分解决一元积分问题 第13讲 常微分方程这一章要背的好多，主要是各种微分方程的通解和特解。最好把一阶的和二阶的区分开背，这样可能比较简单。计算的时候用到不少常见的积分和微分等式。 第14讲 无穷级数这个很难，需要重点复习。考点有： 正项级数及其敛散性（达朗贝尔和柯西） 交错级数及其敛散性（莱布尼茨判据） 任意项级数及其敛散性 幂级数（阿贝尔和收敛域） 幂级数求和、函数展开为幂级数 经验： 7个常见的重要展开式及收敛域（麦克劳林展开） 调和级数，交错调和级数，p级数等常见级数 不等式公式有一些会用在敛散性证明的构造上 幂级数求和常用逐项求导或逐项积分 第15讲 数一应用题闭关第1天：完成第15讲，主要讲的是数学一应用题，欧拉公式和傅立叶级数。 第17章 多元函数积分学的基本知识这讲也是多元函数微积分的应用题，涉及到空间解几问题。需要背好的有： 空间旋转曲面的求法 空间曲面的切平面和法线 空间曲线的切线和法平面 方向导数与梯度 散度和旋度 散度和旋度的物理意义是什么？.pdf 第18章 三重积分+曲线、曲面积分这一讲的概念跟物理结合很紧密。 第一型的曲线、曲面积分都可以看作是求密度为f的曲线、曲面质量，第二型的曲线、曲面积分是矢量性的积分。格林公式有环线的和指向中间的形式，分别从二维向三维推广，就可以得到斯托克斯公式和高斯公式。 格林公式的几何意义.pdf理解斯托克斯公式.pdf 参考资料：1、张宇–《考研数学基础30讲》及相关视频2、知乎马同学高赞答案","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://lankning.github.io/tags/%E8%80%83%E7%A0%94/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"考研：线代","slug":"学习笔记/2020-08-25-考研：线代","date":"2020-08-25T04:24:00.000Z","updated":"2021-08-14T07:34:14.000Z","comments":true,"path":"2020/08/25/学习笔记/2020-08-25-考研：线代/","link":"","permalink":"https://lankning.github.io/2020/08/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-08-25-%E8%80%83%E7%A0%94%EF%BC%9A%E7%BA%BF%E4%BB%A3/","excerpt":"线性代数里面方法很重要，要熟知题型和考点。","text":"线性代数里面方法很重要，要熟知题型和考点。 第一章 行列式 第二章 矩阵线性代数中最重要的一环——鲁迅。 第三章 向量组3、4两章（向量组和方程组）是一体的，内容相同，注意多做题总结规律。 第四章 方程组 第五章 特征值和特征向量5、6两章（特征值和二次型）相关性比较大，第五章可以单独出题，也可以夹杂在二次型里面考。 第六章 二次型 牢记常见题目的套路: 将二次型化为规范型和标准型的方法有配方法、正交变换 牢记f正定的充要条件和必要条件 参考资料：1、张宇–《考研数学基础30讲》及相关视频","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://lankning.github.io/tags/%E8%80%83%E7%A0%94/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"一行python搭建webdav","slug":"骚操作/2020-07-30-一行python搭建webdav","date":"2020-07-30T06:52:00.000Z","updated":"2021-08-14T08:16:28.000Z","comments":true,"path":"2020/07/30/骚操作/2020-07-30-一行python搭建webdav/","link":"","permalink":"https://lankning.github.io/2020/07/30/%E9%AA%9A%E6%93%8D%E4%BD%9C/2020-07-30-%E4%B8%80%E8%A1%8Cpython%E6%90%AD%E5%BB%BAwebdav/","excerpt":"想要建一个webdav，然后研究了apache，nginx均失败，最后还是python最简单地完成了我们的要求。","text":"想要建一个webdav，然后研究了apache，nginx均失败，最后还是python最简单地完成了我们的要求。 一、Wsgidav 官网：https://wsgidav.readthedocs.io/en/latest/index.html 安装1pip install cheroot wsgidav cheroot lxml pam 使用123wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=anonymous # 匿名wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=pam-login # Linux下账号wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=nt # Windows下账号 二、大问题Ubuntu下实测，pam模块是有问题的。经过观察代码，这是python2时代的产物，而wsgidav采用pam来验证会带来一些坑。 坑1：字符报错，无效字符python3的print有括号的，到该路径的文件中加上去即可 坑2：AttributeError: module ‘pam’ has no attribute ‘pam’找到文件，随便改一下，能用就行。 坑3：Linux下密码登录失效，一直在报pam.authenticate错误。重写，反正就我一个人用。把用户名密码写死！pam_dc.py文件全文如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# -*- coding: utf-8 -*-# (c) 2009-2020 Martin Wendt and contributors; see WsgiDAV https://github.com/mar10/wsgidav# Licensed under the MIT license: http://www.opensource.org/licenses/mit-license.php&quot;&quot;&quot;Implementation of a domain controller that allows users to authenticate againsta Pluggable Authentication Module (&#x27;PAM&#x27;).Used by HTTPAuthenticator. Only available on linux and macOS.See https://wsgidav.readthedocs.io/en/latest/user_guide_configure.html&quot;&quot;&quot;from __future__ import print_functionfrom wsgidav import utilfrom wsgidav.dc.base_dc import BaseDomainControllerimport pam__docformat__ = &quot;reStructuredText&quot;_logger = util.get_module_logger(__name__)class PAMDomainController(BaseDomainController): def __init__(self, wsgidav_app, config): super(PAMDomainController, self).__init__(wsgidav_app, config) self.pam = pam.PamHandle()# origin is pam.pam, replace it # auth_conf = config[&quot;http_authenticator&quot;] dc_conf = config.get(&quot;pam_dc&quot;, &#123;&#125;) self.pam_service = dc_conf.get(&quot;service&quot;, &quot;login&quot;) self.pam_encoding = dc_conf.get(&quot;encoding&quot;, &quot;utf-8&quot;) self.pam_resetcreds = dc_conf.get(&quot;resetcreds&quot;, True) def __str__(self): return &quot;&#123;&#125;(&#x27;&#123;&#125;&#x27;)&quot;.format(self.__class__.__name__, self.pam_service) def get_domain_realm(self, path_info, environ): return &quot;PAM(&#123;&#125;)&quot;.format(self.pam_service) def require_authentication(self, realm, environ): return True def verify(self, user_name,password):# write die, 写死 if user_name==&#x27;lankning&#x27; and password==&#x27;123456&#x27;: return True else: return False def basic_auth_user(self, realm, user_name, password, environ): pam = self.pam is_ok = self.verify(user_name,password) # pam.authenticate( # user_name, # password, # service=self.pam_service, # resetcreds=self.pam_resetcreds, # encoding=self.pam_encoding, # ) if is_ok: _logger.debug(&quot;User &#x27;&#123;&#125;&#x27; logged on.&quot;.format(user_name)) return True _logger.warning( &quot;pam.authenticate(&#x27;&#123;&#125;&#x27;, &#x27;***&#x27;, &#x27;&#123;&#125;&#x27;) failed with code &#123;&#125;: &#123;&#125;&quot;.format( user_name, self.pam_service, pam.code, pam.reason ) ) return False def supports_http_digest_auth(self): # We don&#x27;t have access to a plaintext password (or stored hash) return False 这就可以用了。。。 参考： https://github.com/mar10/wsgidav/","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"安卓手机Ksweb食用指南","slug":"骚操作/2020-07-07-安卓手机Ksweb食用指南","date":"2020-07-07T08:52:00.000Z","updated":"2021-08-14T08:16:54.000Z","comments":true,"path":"2020/07/07/骚操作/2020-07-07-安卓手机Ksweb食用指南/","link":"","permalink":"https://lankning.github.io/2020/07/07/%E9%AA%9A%E6%93%8D%E4%BD%9C/2020-07-07-%E5%AE%89%E5%8D%93%E6%89%8B%E6%9C%BAKsweb%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"Ksweb由老毛子开发，是一款可以在手机上部署PHP网页的APP，它没有Termux和Linux Deploy的麻烦，开箱即用，对于PHP程序猿来可以说是歪瑞古德。","text":"Ksweb由老毛子开发，是一款可以在手机上部署PHP网页的APP，它没有Termux和Linux Deploy的麻烦，开箱即用，对于PHP程序猿来可以说是歪瑞古德。 一、下载、安装下载链接发在参考资料中，低调自取。 二、目录结构 PHP文件目录：\\htdocs把PHP文件放到该目录，盘它、盘它！ Ksweb目录：\\ksweb 参考资料： 1、Kslab官网：http://www.kslabs.ru/ 2、APP下载： 蓝奏云（推荐）：https://wws.lanzous.com/ibN2dedkekb 3、百度论坛：https://tieba.baidu.com/f?kw=ksweb","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"局域网下全平台传输利器","slug":"小技巧/2020-07-05-局域网下全平台传输利器","date":"2020-07-05T03:11:00.000Z","updated":"2021-08-14T08:04:24.000Z","comments":true,"path":"2020/07/05/小技巧/2020-07-05-局域网下全平台传输利器/","link":"","permalink":"https://lankning.github.io/2020/07/05/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-07-05-%E5%B1%80%E5%9F%9F%E7%BD%91%E4%B8%8B%E5%85%A8%E5%B9%B3%E5%8F%B0%E4%BC%A0%E8%BE%93%E5%88%A9%E5%99%A8/","excerpt":"对于我们这种一会儿用Android，一会儿用Windows，偶尔用用Linux和iOS的肥宅来说，一个真正的跨平台文件传输软件可以解决一些让我们我们很烦躁的问题。","text":"对于我们这种一会儿用Android，一会儿用Windows，偶尔用用Linux和iOS的肥宅来说，一个真正的跨平台文件传输软件可以解决一些让我们我们很烦躁的问题。 Feem——全平台文件传输软件 优点 缺点 全平台 仅局域网传输 易用、速度快 免费版有广告 免费版无限制 官网被墙 特点： 自动配对连接 &#x2F; 不需注册登录帐号 局域网传输 &#x2F; 速度飞快而且更安全 WiFi 热点直连 (离线传输文件 &#x2F; 无需路由器) 支持文字传输 全平台支持 &#x2F; 跨设备双向互传 WebShare 网页文件共享，无需安装客户端 下载链接： 1、蓝奏云（安卓+Windows+Linux）：https://wws.lanzous.com/iUSHDedkfyb 参考资料： 1、Feem官方网站：https://www.feem.io/ 2、异次元推荐文章（含下载链接）：https://www.iplaysoft.com/feem.html","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"deepin硬盘权限问题","slug":"小技巧/2020-06-04-deepin硬盘权限问题","date":"2020-06-04T06:03:00.000Z","updated":"2021-08-14T08:05:12.000Z","comments":true,"path":"2020/06/04/小技巧/2020-06-04-deepin硬盘权限问题/","link":"","permalink":"https://lankning.github.io/2020/06/04/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-06-04-deepin%E7%A1%AC%E7%9B%98%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/","excerpt":"今天第一次把deepin做在了固态盘上面，速度快很多，同时带来这个小问题。 社区已经有人提问过了，https://bbs.deepin.org/forum.php?mod=viewthread&amp;tid=173682&amp;extra=","text":"今天第一次把deepin做在了固态盘上面，速度快很多，同时带来这个小问题。 社区已经有人提问过了，https://bbs.deepin.org/forum.php?mod=viewthread&amp;tid=173682&amp;extra= 此处进行归纳和搬运： 先用文件管理器进入硬盘目录，按下ctrl+L得到其挂载的目录 执行下面的命令 12sudo setfacl -m &quot;g:sudo:rwx&quot; &quot;复制的路径&quot;sudo setfacl -d -m &quot;g:sudo:rwx&quot; &quot;复制的路径&quot;","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"CAD课程总结","slug":"学习笔记/2020-06-04-CAD课程总结","date":"2020-06-04T03:11:00.000Z","updated":"2021-08-14T07:34:44.000Z","comments":true,"path":"2020/06/04/学习笔记/2020-06-04-CAD课程总结/","link":"","permalink":"https://lankning.github.io/2020/06/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-06-04-CAD%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/","excerpt":"CAD这门课不是太难，主要是一些程序性的东西。 题型 对应章 题数 分值 工程数据的处理 3 1 15 图形坐标变换与裁剪 4 2 30 参数化绘图程序设计 ５ 1 15 AutoCAD二次开发 7 1 10","text":"CAD这门课不是太难，主要是一些程序性的东西。 题型 对应章 题数 分值 工程数据的处理 3 1 15 图形坐标变换与裁剪 4 2 30 参数化绘图程序设计 ５ 1 15 AutoCAD二次开发 7 1 10 一、工程数据的处理 拉格朗日插值法的几何解释 以二次插值法为例，设$y&#x3D;a_0+a_1x+a_2x^2$，用已知的ＡＢＣ三点代入求解$a_0,a_1,a_2$即可。 插值法的选点－－选最近的几个点 最小二乘法的损失公式 $$\\phi&#x3D;\\sum_{i&#x3D;1}^N(P(x_i)-y_i)$$ 二、图形坐标变换与裁剪 三、参数化绘图 四、CAD二次开发略","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"AutoCAD绘图基操","slug":"学习笔记/2020-05-31-AutoCAD绘图基操","date":"2020-05-31T03:11:00.000Z","updated":"2022-04-29T10:07:08.000Z","comments":true,"path":"2020/05/31/学习笔记/2020-05-31-AutoCAD绘图基操/","link":"","permalink":"https://lankning.github.io/2020/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-05-31-AutoCAD%E7%BB%98%E5%9B%BE%E5%9F%BA%E6%93%8D/","excerpt":"2020年5月份，我终于再次更新了一篇文章。主要是CAD课程结课要用到Autocad绘制二维图，期间遇到很多初学者的问题，记录在本文。","text":"2020年5月份，我终于再次更新了一篇文章。主要是CAD课程结课要用到Autocad绘制二维图，期间遇到很多初学者的问题，记录在本文。 一、绘制A3图纸并保存到块 矩形命令rect选择基点后可以用D来规定长宽 命令X可以使线段独立 命令overkill可以去除重叠线段 ctrl+鼠标右键可以快速选择捕捉点类型和设置 二、如何修改线型 为了不让线型互相干扰，需要新建图层2020版本CAD的图层在常用-图层-图层特性内 线性的选择就在图层特性管理器内一般轴线使用Center线型（点划线），虚线使用Hidden线型 三、圆角失败点击圆角之后，要先输入R半径，再才能选定两边 四、有用的命令 命令 意义 tr 裁剪线段 mirror 镜像 x+空格 分离粘连的线段 overkill 删除重复的线段 标注直径$\\phi$ 在尺寸前面加上%%c 附：作业老师布置的作业是用CAD画2D三视图，用Solidworks画一个3D图。 解决完上面的问题后，我用CAD画了左边的三视图。 CAD绘制2D图 您的浏览器不支持 video 标签。 最终成果如下： Solidworks绘制3D图 您的浏览器不支持 video 标签。 参考文献： 1、https://jingyan.baidu.com/article/29697b91e1eaffeb21de3c3a.html 2、https://zhidao.baidu.com/question/430701680.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"nginx挂载静态网页","slug":"骚操作/2020-04-09-nginx挂载静态网页","date":"2020-04-09T12:14:00.000Z","updated":"2022-04-25T15:37:30.000Z","comments":true,"path":"2020/04/09/骚操作/2020-04-09-nginx挂载静态网页/","link":"","permalink":"https://lankning.github.io/2020/04/09/%E9%AA%9A%E6%93%8D%E4%BD%9C/2020-04-09-nginx%E6%8C%82%E8%BD%BD%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5/","excerpt":"nginx用的很广，之前在想要内网穿透的时候似乎见过这个名字，但是由于知识储备问题并没有去纠缠。这次我打算用它来挂静态网页。","text":"nginx用的很广，之前在想要内网穿透的时候似乎见过这个名字，但是由于知识储备问题并没有去纠缠。这次我打算用它来挂静态网页。 1、安装nginx首先，直接用apt安装nginx即可，不需要太麻烦。 1sudo apt-get install nginx 安装好了之后，命令行输入sudo nginx。如果安装成功，在浏览器内访问服务器的ip即可得到以下画面。 2、配置网页地址 我这里使用的是hexo生成的静态网页文件，把public目录下的文件复制到Linux下的/home/share/hidden/blog文件夹里面。 接下来修改nginx的配置文件。 1sudo vim /etc/nginx/sites-available/default ​ 找到下面这一段 123456location / &#123; # First attempt to serve request as file, then# as directory, then fall back to displaying a 404.try_files $uri $uri/ =404;# Uncomment to enable naxsi on this location# include /etc/nginx/naxsi.rules &#125; 加入两行进行修改 12345678location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; index index.html; root /home/share/hidden/blog; # Uncomment to enable naxsi on this location # include /etc/nginx/naxsi.rules &#125; 保存之后退出 重新加载nginx配置文件 1sudo nginx -s reload 重启nginx服务 1sudo service nginx restart 3、访问nginx服务打开浏览器输入http://your_linux_ip，应该就可以看见你的网页了。 参考资料： 1、nginx部署前端页面： https://www.jianshu.com/p/e84238f11517 2、基于nginx的静态网页部署：https://blog.csdn.net/ljp1919/article/details/72833982","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"deepin上安装安卓虚拟机","slug":"小技巧/2020-04-08-deepin上安装安卓虚拟机","date":"2020-04-08T04:12:00.000Z","updated":"2021-08-14T08:06:14.000Z","comments":true,"path":"2020/04/08/小技巧/2020-04-08-deepin上安装安卓虚拟机/","link":"","permalink":"https://lankning.github.io/2020/04/08/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-04-08-deepin%E4%B8%8A%E5%AE%89%E8%A3%85%E5%AE%89%E5%8D%93%E8%99%9A%E6%8B%9F%E6%9C%BA/","excerpt":"腾讯对于linux的适配是很差的，我想要在deepin上面使用腾讯会议，可是目前没有发现wine版和linux版，但我还想要……所以还是装个安卓虚拟机吧。 [补充] 事实证明我想多了，虽然同为android，但大部分软件都是在arm平台上运行的，换成x86平台就不一定跑的了了，例如腾讯会议。&#x2F;(ㄒoㄒ)&#x2F;~~ 讲真，在这之前我从来不知道安卓还有x86的版本（尽管它一直处于更新状态）。","text":"腾讯对于linux的适配是很差的，我想要在deepin上面使用腾讯会议，可是目前没有发现wine版和linux版，但我还想要……所以还是装个安卓虚拟机吧。 [补充] 事实证明我想多了，虽然同为android，但大部分软件都是在arm平台上运行的，换成x86平台就不一定跑的了了，例如腾讯会议。&#x2F;(ㄒoㄒ)&#x2F;~~ 讲真，在这之前我从来不知道安卓还有x86的版本（尽管它一直处于更新状态）。 1、安装Vmware 主要步骤如下，具体操作略 应用市场下载Vmware-Install 安装 2、下载最新的android x86 从fosshub下载（首选） fosshub的Android X86地址：https://www.fosshub.com/Android-x86.html 其中，9.0-r2版本64位的ISO文件下载地址如下：https://www.fosshub.com/Android-x86.html?dwl=android-x86_64-9.0-r2.iso 从android x86中文站下载 android x86中文站的网址：http://www.x86android.com/ 其中，9.0-r2版本64位的ISO文件下载地址如下：http://down.kejianjidi.com/x86_9.0_r2/android-x86_64-9.0-r2.iso 但是，据站长的说法，服务器的带宽很小，属于1Mbps的小水管。大家一起下载的话，速度非常慢（实测）。 3、安装android x86虚拟机 主要步骤有： 命名、选择类型 分配内存 创建虚拟硬盘、分配空间 选择虚拟光盘文件 启动、修改grub 启动、正常配置 详细图文教程参考资料1：VMware 14 安装 Android x86 7.1 rc1 参考资料： 1、VMware 14 安装 Android x86 7.1 rc1 2、安卓X86中文站 3、fosshub下载站","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"解决deepin-qq/tim无法显示头像和图片的问题","slug":"小技巧/2020-04-07-解决deepin-qq_tim无法显示头像和图片的问题","date":"2020-04-07T05:24:00.000Z","updated":"2021-08-14T08:08:10.000Z","comments":true,"path":"2020/04/07/小技巧/2020-04-07-解决deepin-qq_tim无法显示头像和图片的问题/","link":"","permalink":"https://lankning.github.io/2020/04/07/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-04-07-%E8%A7%A3%E5%86%B3deepin-qq_tim%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E5%A4%B4%E5%83%8F%E5%92%8C%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"之前我一直以为deepin里面的TIM和QQ都是不怎么能重度使用的那种，因为TIM上面的qq头像总是long long ago的久远记忆，这严重影响了使用体验。直到我上网查询后,…. 图片和头像无法显示的原因是打开了ipv6，关掉就好了。关掉ipv6之后几乎所有的wine应用的图片显示都会变正常。","text":"之前我一直以为deepin里面的TIM和QQ都是不怎么能重度使用的那种，因为TIM上面的qq头像总是long long ago的久远记忆，这严重影响了使用体验。直到我上网查询后,…. 图片和头像无法显示的原因是打开了ipv6，关掉就好了。关掉ipv6之后几乎所有的wine应用的图片显示都会变正常。 以下方法应该用一个就可以了，如果不可以可以三个全部使用后重启。 1、方法一123sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1sudo sysctl -w net.ipv6.conf.lo.disable_ipv6=1 2、方法二按下ctrl+alt+T，打开终端 1sudo gedit /etc/sysctl.conf 在文件的最后追加这样几行（关闭ipv6）： 1234# IPv6 disablednet.ipv6.conf.all.disable_ipv6 =1net.ipv6.conf.default.disable_ipv6 =1net.ipv6.conf.lo.disable_ipv6 =1 保存退出，清除缓存 1sudo rm -rf ~/.deepinwine/Deepin-QQ 当然如果你安装的是其他容器，比如Tim，Wechat，替换上面的QQ就好。 然后打开QQ，登录的时候头像显示为默认头像，登录完毕正式上线就是最新头像了！浏览聊天记录，问题解决。 3、方法三 编辑 &#x2F;etc&#x2F;default&#x2F;grub1sudo vim /etc/default/grub 将1GRUB_CMDLINE_LINUX_DEFAULT=&quot;spalsh quiet &quot; 修改为1GRUB_CMDLINE_LINUX_DEFAULT=&quot;ipv6.disable=1 splash quiet &quot; 执行命令1sudo update-grub 重启系统 参考资料： 1、博客园：deepin-wine-qq无法加载图片解决方案 2、深度论坛：终于发现QQ图片转圈的原因了 3、deepin15.11下QQ闪退和图片不加载问题","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"使用Python优雅地将PDF转化为图片","slug":"骚操作/2020-03-15-使用Python优雅地将PDF转化为图片","date":"2020-03-15T15:01:00.000Z","updated":"2021-08-15T05:49:34.000Z","comments":true,"path":"2020/03/15/骚操作/2020-03-15-使用Python优雅地将PDF转化为图片/","link":"","permalink":"https://lankning.github.io/2020/03/15/%E9%AA%9A%E6%93%8D%E4%BD%9C/2020-03-15-%E4%BD%BF%E7%94%A8Python%E4%BC%98%E9%9B%85%E5%9C%B0%E5%B0%86PDF%E8%BD%AC%E5%8C%96%E4%B8%BA%E5%9B%BE%E7%89%87/","excerpt":"疫情期间，内燃机老师要我们每周在QQ小程序上面用图片的形式提交两次作业，然而我的WPS会员过期了，pdf转图片会有水印，网上逛了一圈，python可以解决这个问题。","text":"疫情期间，内燃机老师要我们每周在QQ小程序上面用图片的形式提交两次作业，然而我的WPS会员过期了，pdf转图片会有水印，网上逛了一圈，python可以解决这个问题。 一、准备工作fitz是对PDF文件操作的一个包，安装依赖于traits和PyMuPDF 在 https://www.lfd.uci.edu/~gohlke/pythonlibs/#traits 找到对于python版本的traits.whl下载安装 1pip3 install traits.whl 安装PyMuPDF==1.16.7（Python 3.5）和fitz 1pip3 install PyMuPDF==1.16.7 fitz 二、程序主体源码下载：https://github.com/lankning/pyutils/blob/master/pdf2img.py 库的导入、函数封装 1234567891011121314151617181920212223242526import sys, fitzimport osimport datetime def pyMuPDF_fitz(pdfPath, imagePath): startTime_pdf2img = datetime.datetime.now()#开始时间 print(&quot;imagePath=&quot;+imagePath) pdfDoc = fitz.open(pdfPath) for pg in range(pdfDoc.pageCount): page = pdfDoc[pg] rotate = int(0) # 每个尺寸的缩放系数为1.3，这将为我们生成分辨率提高2.6的图像。 # 此处若是不做设置，默认图片大小为：792X612, dpi=96 zoom_x = 1.33333333*2 #(1.33333333--&gt;1056x816) (2--&gt;1584x1224) zoom_y = 1.33333333*2 mat = fitz.Matrix(zoom_x, zoom_y).preRotate(rotate) pix = page.getPixmap(matrix=mat, alpha=False) if not os.path.exists(imagePath):#判断存放图片的文件夹是否存在 os.makedirs(imagePath) # 若图片文件夹不存在就创建 pix.writePNG(imagePath+&#x27;/&#x27;+&#x27;images_%s.png&#x27; % pg)#将图片写入指定的文件夹内 endTime_pdf2img = datetime.datetime.now()#结束时间 print(&#x27;pdf2img时间=&#x27;,(endTime_pdf2img - startTime_pdf2img).seconds,&#x27;s&#x27;) 主函数 12345if __name__ == &quot;__main__&quot;: homeworkname=&#x27;内燃机构造与原理平时作业七&#x27; pdfPath = &#x27;../&#x27;+homeworkname+&#x27;.pdf&#x27; imagePath = &#x27;../&#x27;+homeworkname+&#x27;/&#x27; pyMuPDF_fitz(pdfPath, imagePath) 参考资料 https://blog.csdn.net/zbj18314469395/article/details/98329442 https://zhuanlan.zhihu.com/p/102742847 https://github.com/pymupdf/PyMuPDF/issues/414","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"单片机--点亮数码管","slug":"学习笔记/2020-03-04-单片机--点亮数码管","date":"2020-03-04T07:29:00.000Z","updated":"2021-08-21T08:56:28.000Z","comments":true,"path":"2020/03/04/学习笔记/2020-03-04-单片机--点亮数码管/","link":"","permalink":"https://lankning.github.io/2020/03/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-03-04-%E5%8D%95%E7%89%87%E6%9C%BA--%E7%82%B9%E4%BA%AE%E6%95%B0%E7%A0%81%E7%AE%A1/","excerpt":"经过几个晚上的初步学习，我渐渐结合起来一年前学习的微机原理的一些知识。虽然不一定能搞懂，但是现在确实是通过看原理图、看引脚，逐渐掌握了一点东西。本篇记录在点亮单片机数码管中遇到的问题。","text":"经过几个晚上的初步学习，我渐渐结合起来一年前学习的微机原理的一些知识。虽然不一定能搞懂，但是现在确实是通过看原理图、看引脚，逐渐掌握了一点东西。本篇记录在点亮单片机数码管中遇到的问题。 1、动态数码管 原理：动态显示的特点是将所有数码管的段选线并联在一起，由位选线控制是哪一位数码管有效。选亮数码管采用动态扫描显示。所谓动态扫描显示即轮流向各位数码管送出字形码和相应的位选，利用发光管的余辉和人眼视觉暂留作用，使人的感觉好像各位数码管同时都在显示。动态显示的亮度比静态显示要差一些，所以在选择限流电阻时应略小于静态显示电路中的。 位选就是数码管位置（亮灭）的选择；段选就是数码管笔段（亮灭）的选择。 共阳和共阴： 简单来讲，共阴数码管就是把com端接地，其他要点亮的某段就接高电平；共阳数码管，就把com接高电平，其他需要点亮的某段就接地。 LED代码表 这个表很有用，编程的时候需要对照着它来摘取段选码。需要注意的是，段选码是十六进制的，因此编程时需要写成0x3F类似的格式。 引脚图： 当我们需要从头开始开发的时候，我们需要一个引脚图，如下所示。 段选信号：单片机的P00-P07这8个IO口控制的是数码管的段选信号，因此所有数码管的段选都是一样的。 位选信号：上面COM口连接的是非常重要的位选信号，为了节约IO口，单片机会通过38译码器来转换，通过查阅74HC138译码器得知对应的IO口为P22&#x2F;P23&#x2F;P24。 2、程序实现123typedef unsigned char u8;u8 code smgduan[16]=&#123;0x3f,0x06,0x5b,0x4f,0x66,0x6d,0x7d,0x07, 0x7f,0x6f,0x77,0x7c,0x39,0x5e,0x79,0x71&#125;;//共阴 code的作用：code的作用是告诉单片机，定义的数据要放在ROM（程序存储区）里面，写入后就不能再更改。因为C语言中没办法详细描述存入的是ROM还是RAM（寄存器），所以在软件中添加了这一个语句起到代替汇编指令的作用，对应的还有data是存入RAM的意思。 123456789101112131415161718192021void digdisplay()//全部点亮，一次&#123; u8 i; for(i=0;i&lt;8;i++) &#123; switch(i)//位选操作 &#123; case 0: LSA=0;LSB=0;LSC=0;break; case 1: LSA=1;LSB=0;LSC=0;break; case 2: LSA=0;LSB=1;LSC=0;break; case 3: LSA=1;LSB=1;LSC=0;break; case 4: LSA=0;LSB=0;LSC=1;break; case 5: LSA=1;LSB=0;LSC=1;break; case 6: LSA=0;LSB=1;LSC=1;break; case 7: LSA=1;LSB=1;LSC=1;break; &#125; P0=smgduan[i];//段选操作 delay(100);//太小会来不及清零，混合或相同；太大会不连续； P0=0x00;//归零，消影 &#125; &#125; 要注意delay的大小，如果delay太大会造成类似于流水灯的效果。 P0=0x00这句经过实测没有影响。 参考资料： 1、数码管的段选和位选是什么意思? https://www.uyuyao.com/zuoye/5576154 2、数码管共阳和共阴是什么意思？https://www.zhihu.com/question/39882534 3、C语言中的“code”是什么意思啊？https://zhidao.baidu.com/question/106734427.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"嵌入式","slug":"嵌入式","permalink":"https://lankning.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"初识单片机--点亮led","slug":"学习笔记/2020-03-01-初识单片机--点亮led","date":"2020-03-01T13:28:00.000Z","updated":"2021-08-21T08:56:18.000Z","comments":true,"path":"2020/03/01/学习笔记/2020-03-01-初识单片机--点亮led/","link":"","permalink":"https://lankning.github.io/2020/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2020-03-01-%E5%88%9D%E8%AF%86%E5%8D%95%E7%89%87%E6%9C%BA--%E7%82%B9%E4%BA%AEled/","excerpt":"淘宝买了一个51单片机，今天到货开始学习。本专题将记录在学习过程中遇到的问题，本篇记录单片机的初次上手中遇到的驱动问题和烧录问题。","text":"淘宝买了一个51单片机，今天到货开始学习。本专题将记录在学习过程中遇到的问题，本篇记录单片机的初次上手中遇到的驱动问题和烧录问题。 1、单片机品牌型号品牌：普中 型号：STC89C52 2、Windows10下烧写 安装CH340驱动 CH340&#x2F;CH341驱动适用于win7、win8 64位操作系统，安装后就可以进行各种参数操作了，适用于WINDOWS 98&#x2F;ME&#x2F;2000&#x2F;XP&#x2F;Vista&#x2F;Linux等操作系统。CH340&#x2F;CH341驱动可以用于usb转串口操作，转换后可以与各类串口监控软件和调试工具配合使用。 下载链接：https://pan.baidu.com/s/1i4esgIh 下载STC-ISP烧写程序 淘宝客服发给我的普中的烧写程序每次都超时，无法真正写入到单片机里面。搜索了大量相关问题之后，有人推荐使用STC-ISP原厂的烧写程序，果然解决了问题。 下载链接：http://www.stcisp.com/_download_stcisp_new.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"嵌入式","slug":"嵌入式","permalink":"https://lankning.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"安卓手机安装Linux","slug":"骚操作/2020-02-19-安卓手机安装Linux","date":"2020-02-19T08:14:00.000Z","updated":"2022-12-14T14:00:52.292Z","comments":true,"path":"2020/02/19/骚操作/2020-02-19-安卓手机安装Linux/","link":"","permalink":"https://lankning.github.io/2020/02/19/%E9%AA%9A%E6%93%8D%E4%BD%9C/2020-02-19-%E5%AE%89%E5%8D%93%E6%89%8B%E6%9C%BA%E5%AE%89%E8%A3%85Linux/","excerpt":"无论是为了发扬极客精神还是为了学习Linux亦或者进行一些小项目的开发，使用淘汰下来的安卓手机都是一件经济实效的事情。","text":"无论是为了发扬极客精神还是为了学习Linux亦或者进行一些小项目的开发，使用淘汰下来的安卓手机都是一件经济实效的事情。 准备工作： 电脑 x 1 安卓手机 x 1 数据线 x 1 一、手机获得管理员权限1. 先尝试使用360一键获取我手边的手机是VIVO Y29L，我先使用刷机APP进行刷机。多次刷机之后仍然显示失败。 2. 使用“奇兔刷机”进行刷机奇兔刷机下载： http://www.7to.cn/ 在ROM市场可以找到一些符合条件的ROM包，下载到本地之后选用本地ROM进行刷机。安装指示进行操作，示意图如下。我这里刷的是MIUI8，因为MIUI可以直接给系统设置中给应用管理员权限。 二、安装Linux2.1 安装Linux deploy由于高版本的linuxdeploy.apk安装包无法在安卓4系统下解析，因此需要根据手机的出厂时间，选择附近时间的Linux Deploy发行版apk文件。 Linux Deploy的Github地址： https://github.com/meefik/linuxdeploy/releases 2.2 授予Linux deploy权限在运行Linux deploy时，点击安装，系统自带的管理器会弹出是否允许使用管理员权限的对话框，选择“是”。 2.3 选择要安装的选项尤其关注要安装的linux发行版、是否安装ssh和VNC。 三、完成下载VNC Viewer：https://www.realvnc.com/en/connect/download/viewer/ 通过VNC连接手机上的Linux系统。","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"使用VM虚拟机安装运行Deepin","slug":"小技巧/2020-02-10-使用VM虚拟机安装运行Deepin","date":"2020-02-10T06:10:00.000Z","updated":"2021-08-14T08:09:24.000Z","comments":true,"path":"2020/02/10/小技巧/2020-02-10-使用VM虚拟机安装运行Deepin/","link":"","permalink":"https://lankning.github.io/2020/02/10/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-02-10-%E4%BD%BF%E7%94%A8VM%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8CDeepin/","excerpt":"兜兜转转，又回到了纯Win10的系统下。然而确实是好久没见到deepin了，因此甚是想念。遂尝试了VM虚拟机。分享我的经验，以下。","text":"兜兜转转，又回到了纯Win10的系统下。然而确实是好久没见到deepin了，因此甚是想念。遂尝试了VM虚拟机。分享我的经验，以下。 1、安装VM WorkStation不必多言，直接上安装教程：https://mp.weixin.qq.com/s/Rdj5AA7aVOzFDMnXeousWg 2、下载deepin的ISO包搜索deepin，找到“最新版本”。 选择“ISO仓库” 进入之后，选择一个离自己近一点的仓库，一般速度能够达到10+（Mb&#x2F;s）。 3、安装deepin打开VM Workstation，点击“创建新的虚拟机”，然后按照提示进行操作即可。 4、享受linux的美","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"电脑驱动安装","slug":"小技巧/2020-01-16-电脑驱动安装","date":"2020-01-16T12:45:00.000Z","updated":"2021-08-14T08:09:50.000Z","comments":true,"path":"2020/01/16/小技巧/2020-01-16-电脑驱动安装/","link":"","permalink":"https://lankning.github.io/2020/01/16/%E5%B0%8F%E6%8A%80%E5%B7%A7/2020-01-16-%E7%94%B5%E8%84%91%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/","excerpt":"电脑驱动有手动更新和自动更新两种方法，自动更新就是安装驱动精灵或者360等，本文介绍手动更新。","text":"电脑驱动有手动更新和自动更新两种方法，自动更新就是安装驱动精灵或者360等，本文介绍手动更新。 1.左键单击“我的电脑”（计算机），选择管理，右键单击。 2.选择“设备管理器”。 3.找到你需要更新的驱动，右键单击，选择更新驱动程序就可以了。 扩展资料 驱动程序即添加到操作系统中的一小块代码，其中包含有关硬件设备的信息。有了此信息，计算机就可以与设备进行通信。驱动程序是硬件厂商根据操作系统编写的配置文件，可以说没有驱动程序，计算机中的硬件就无法工作。 参考资料： 1、百度百科-驱动：https://baike.baidu.com/item/驱动/2765136 2、百度知道：https://zhidao.baidu.com/question/1180615761717135739.html","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"Python数据库","slug":"学习笔记/2019-12-31-Python数据库","date":"2019-12-31T10:28:00.000Z","updated":"2021-08-14T07:42:06.000Z","comments":true,"path":"2019/12/31/学习笔记/2019-12-31-Python数据库/","link":"","permalink":"https://lankning.github.io/2019/12/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-12-31-Python%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"很多时候我们希望使用数据库，而不是把数据写在文件里面。本篇文章讨论如何在Python中调用数据库。","text":"很多时候我们希望使用数据库，而不是把数据写在文件里面。本篇文章讨论如何在Python中调用数据库。 数据存储的三种方法: 方法 优点 缺点 把数据存储到内存中 使用方便 程序关闭的时候,内存被释放,数据随之消失 把数据写入到文件中 数据是永久性的,不易丢失 需要经常打开关闭文件,操作比较麻烦 把数据存储到数据库中 永久存储,操作方便 学习难度较大 数据库按照规模大小分为四种: 类别 举例 大型数据库 oracle 中型数据库 Sqlserver 小型数据库 mySQL 微型数据库 sqlite 本文调用的是Python自带的sqlite数据库。 1、调用库 1import sqlite3 # 导入sqlit3库 2、创建数据库和表 123456789# 连接到一个数据库名为 data_base_name 的数据库,如果存在则直接连接,如果不存在则创建data_base=sqlite3.connect(&#x27;data_base_name&#x27;)# 设置数据库光标,你之后所有对数据库进行的操作都是通过光标来执行的cursor=data_base.cursor()# 创建一个表名为 table_name 的数据库表,如果这个表不存在的话# 后面括号里面的内容为这个表的属性,属性与属性之间用 , 隔开,属性名与属性类型之间用 空格 隔开,如果不写类型的话,默认 为text类型cursor.execute(&#x27;create table if not exists table_name(name text,age int,info text)&#x27;)# 数据库的提交,对数据进行增删改后都需要进行数据库的提交data_base.commit() 3、查询符合条件的数据 123cursor.execute(&#x27;select * from table_name&#x27;)result=cursor.fetchall()print(result) 4、增加数据 12cursor.execute(&#x27;insert into table_name (name,age,info) VALUES (&quot;python&quot;,29,&quot;最接近人工智能的计算机语言&quot;)&#x27;)data_base.commit() 5、删除数据 12cursor.execute(&#x27;DELETE FROM table_name WHERE name=&quot;C++&quot;&#x27;)data_base.commit() 6、修改数据 123cursor.execute(&#x27;update table_name set name=&quot;C++&quot;,age=33 WHERE name=&quot;python&quot;&#x27;)cursor.execute(&#x27;update table_name set name=&quot;C++&quot;,age=33 WHERE age=29&#x27;)data_base.commit() 参考文献： 1、Python3之数据库(以SQLite为例)：https://blog.csdn.net/qq_41646358/article/details/81279548 2、Github代码：https://github.com/Cytor/bilibili/blob/master/python/database.ipynb","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Windows下安装PHP","slug":"学习笔记/2019-12-31-Windows下安装PHP","date":"2019-12-31T06:10:00.000Z","updated":"2021-08-14T07:39:28.000Z","comments":true,"path":"2019/12/31/学习笔记/2019-12-31-Windows下安装PHP/","link":"","permalink":"https://lankning.github.io/2019/12/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-12-31-Windows%E4%B8%8B%E5%AE%89%E8%A3%85PHP/","excerpt":"PHP即“超文本预处理器”，是一种通用开源脚本语言。PHP是在服务器端执行的脚本语言，与C语言类似，是常用的网站编程语言。PHP独特的语法混合了C、Java、Perl以及 PHP 自创的语法。利于学习，使用广泛，主要适用于Web开发领域。","text":"PHP即“超文本预处理器”，是一种通用开源脚本语言。PHP是在服务器端执行的脚本语言，与C语言类似，是常用的网站编程语言。PHP独特的语法混合了C、Java、Perl以及 PHP 自创的语法。利于学习，使用广泛，主要适用于Web开发领域。 引言：鲁迅先生说过，”PHP是最好的语言！“。我倒要来看看PHP哪里好了。 然而在我搜资料的时候，我的沙雕舍友问我为什么要搜PHP，我问他有什么问题，他却反问我为什么要php。 Windows安装一、下载Windows下特有的PHP集成工具WampServer。 到WampServer的官网下载最新版本的wanpserver：http://www.wampserver.com/en/#download-wrapper，然后进行安装。 安装完成之后启动，在浏览器里面输入localhost，应该是如下界面。 二、修改php文件的访问路径 打开httpd.conf， 寻找“DocumentRoot”，把后面的值改成我们实际网站需要的路径（修改默认路径地址） 寻找“&lt;Directory “c:&#x2F;wamp&#x2F;www&#x2F;“&gt;”，同样把后面的值改成我们网站存放的实际地址（修改默认权限路径地址） 访问home.php网址： 拓展阅读： 1、MySql数据库是默认没有密码的，需要配置 2、后期Apache也可能需要微调配置 参考资料： 1、windows环境下wampserver安装及配置详细教程：https://jingyan.baidu.com/article/c74d6000bb70110f6a595d8d.html 2、如何修改WAMPServer默认的网站路径地址：https://jingyan.baidu.com/article/ad310e80b7dd801848f49e63.html","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"pip换国内镜像源","slug":"小技巧/2019-12-26-pip换国内镜像源","date":"2019-12-25T16:16:00.000Z","updated":"2021-08-14T08:10:14.000Z","comments":true,"path":"2019/12/26/小技巧/2019-12-26-pip换国内镜像源/","link":"","permalink":"https://lankning.github.io/2019/12/26/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-12-26-pip%E6%8D%A2%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90/","excerpt":"pip国内的一些镜像 阿里云 https://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/","text":"pip国内的一些镜像 阿里云 https://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 以清华镜像为例，食用方法如下。 临时使用1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package 注意，simple 不能少, 是 https 而不是 http 设为默认升级 pip 到最新的版本 (&gt;&#x3D;10.0.0) 后进行配置： 12pip install pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U 参考资料： 1、清华大学：pypi 镜像使用帮助 2、更换pip源到国内镜像","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"deepin安装Hexo","slug":"学习笔记/2019-12-24-deepin安装Hexo","date":"2019-12-24T01:51:00.000Z","updated":"2021-08-14T09:03:34.000Z","comments":true,"path":"2019/12/24/学习笔记/2019-12-24-deepin安装Hexo/","link":"","permalink":"https://lankning.github.io/2019/12/24/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-12-24-deepin%E5%AE%89%E8%A3%85Hexo/","excerpt":"那是一个风雪交加的晚上，我把windows的系统引导分区efi删掉了。卒。 遂清空磁盘，安装deepin。","text":"那是一个风雪交加的晚上，我把windows的系统引导分区efi删掉了。卒。 遂清空磁盘，安装deepin。 更新包 1sudo apt-get update 安装nodejs和npm 官方有说是install nodejs和npm，然而我试了一下，我不能直接install npm。安装node和nodejs-bin替代。 1sudo apt-get install node nodejs-bin 使用淘宝镜像安装hexo 如果不使用淘宝镜像安装就会报出一堆错误。 1sudo npm install -g hexo --registry=https://registry.npm.taobao.org 安装git 12sudo apt-get install gitnpm install --save hexo-deployer-git 如果不安装hexo-deployer-git，可能会报错 ERROR Deployer not found: git 参考资料： 1、hexo安装错误err! 2、hexo文档","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lankning.github.io/tags/Hexo/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"先进制造技术课程笔记","slug":"学习笔记/2019-12-21-先进制造技术课程笔记","date":"2019-12-21T12:14:00.000Z","updated":"2021-08-14T07:43:40.000Z","comments":true,"path":"2019/12/21/学习笔记/2019-12-21-先进制造技术课程笔记/","link":"","permalink":"https://lankning.github.io/2019/12/21/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-12-21-%E5%85%88%E8%BF%9B%E5%88%B6%E9%80%A0%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/","excerpt":"临时抱佛脚的我又来了，罗列了先进制造技术这门课的问题。","text":"临时抱佛脚的我又来了，罗列了先进制造技术这门课的问题。 一、能场部分注1：EDM – Electrical Discharging Manufacturing 注2：EFM – Energy Field Manufacturing 1、创新与发明的区别在哪里？ 答：创新（invention）是在已有事物的基础上进行某一方面的改动，比如，将电灯泡的灯丝材质由碳丝替换成钨丝。发明（innovation）相比于创新具有更强的创造性，一般是指从无到有的一个过程，比如合成一种全新的发动机材料、提出一套全新的运行方案。 2、能场的本质是什么？ 答：是一种能量的分布形式，它能够向物体做功或者改变系统的状态。 The energy field is the spatial and temporal distribution of energy. The distributions of froces and energy are energy fields. 3、能场制造中的能场具有哪些形式？请列举出相应的例子，并说明能量与材料的具体作用原理。 答：力、电、光、辐射、热。增材制造：一种材料能从多个方向吸收能场的能量，吸收能量之后就会到达一个跟原来材料分离的状态而独立出来。 4、What are the two principal types of EDM processes? Describe the EDM process mechanism. a) type 1, die-sinking EDM; type 2, wire EDM (WEDM); b) EDM Process: Firstly, we move the tool immersed in dielectric liquid close to the workpiece. Then the dielectric liquid between the two electrodes breaks down and suddenly becomes conductive which contributes to high temperature. As a result, the surface of the workpiece will be removed. 5、Explain the different methods used to improve ﬂushing in EDM. a) controlling the fluid flow (normal flow, reverse flow, jet flushing, and immersion flushing); b) modifying the electrode shape; c) imparting relative movement between the workpiece and the tool electrode. 6、Why vibration can improve EDM process? The high-frequency pumping action of the vibrating surface accelerates the slurry circulation and reduces the machining time. The vibrations can be imparted either to the workpiece or the tool electrode. These vibrations introduce acoustic streaming in the dielectric tank and particles move along this stream. 英 中 ultrasonic 超声波 spatial 空间性 temporal 瞬时性 utilize 应用 二、激光部分 1、What are the general advantages and disadvantages of material processing with laser radiation? Advantages:a. The conversion of laser energy into thermal energy at the workpiece enables processing with a much higher quality.b. In terms of energy field manufacturing, laser energy can be tailored to the material properties allowing a very flexible adjustment of the interaction that can lead to vaporization, melting, or just surface modification. Disadvantages:a. the relatively low electrical to laser optical conversion efficiency.b. the high investment costs 2、Which are the processing parameters during laser cutting? Show their interdependency. Processing parameters: 符号 含义 d thickness of sheet 板材厚度 v cutting speed 切割速率 P laser power 激光功率 A absorptivity 吸收率 Interdependency: a. With the same material and laser power(P), d and v are negatively correlated.b. With the same material and thickness of sheet(d), P and v are positively correlated.c. With the same environment, A and v is positively correlated. It means the speed of cutting willbe improved while the absorptivity is higher.d. The value of A is affected by the material properties, such as melting temperaD ture, density, and the specific thermal capacity 3、Describe photochemical processing and photothermal processing. Discuss the relationship between laser pulse duration and the thermal relaxation time, in another word, laser excited electronic states and thermalization rate, in these two processes photochemical processing. Conclusion: Laser pulse duration and the thermal relaxation time are are positively correlated, which means the thermal relaxation time will be reduced when laser pulse duration is reduced. Inference: We can use TT to represent the duration of laser pulse, while f&#x3D;1Tf&#x3D;1T. So when TT becomes lower, ff will become higher. Due to the relationship of P&#x3D;W∗fP&#x3D;W∗f, where PP is a constant, so WW will be lower. It is easy to know the positive relationship between PP and dd (the penetration depth of laser), so dd will be lower, too. The formula to calculate thermal relaxation time can be presented as below:$$t_r&#x3D;\\frac{d^2}{4k}$$where kk is also a constant that stands for the demision of heat dispersion. So if the duration of laser pulse is reduced, the thermal relaxation time will also be reduced. 4、Describe the advantages of laser surface processing over mechanical, chemical, and electric discharge texturing. Name three applications of laser surface processing. Advantages over mechanical texturing: a. The laser power density is high, and the workpiece absorbs the laser and the temperature rises rapidly to melt or vaporize. Even materials with high melting point, high hardness and brittleness (such as ceramics, diamonds, etc.) can be processed by laser. b. The laser head is not in contact with the workpiece, and there is no problem of wear of the processing tool; c. The workpiece is free from stress and is not easily contaminated; d. The laser beam is easy to control and easy to combine with precision machinery, precision measurement technology and electronic computer to achieve high automation of processing and high machining accuracy; Advantages over chemical texturing: a. Alloying elements that are inserted in the near-surface area by laser power are completely molten in the process and change the chemical composition and therefore the properties of the material. Thus, low-cost substrate materials can be alloyed to create surface zones with a high quality. b. the possibility of automation or the reducedgeneration of toxic by products. Advantages over electric discharge texturing: a. Those non-conductive materials can be processed by laser, but cannot with electric discharge b. If laser processing is used, the internal stress of the workpiece will not increase. Applications: a. Laser cladding: The buildup of layers on a substrate material under the utilization of an additive material. b. Repair welding: It is used for high-quality and expensive workpieces in the range of cladding. c. Laser marking: It has great potential concerning resistance of the mark, high-contrast marking, and processing speed. 三、纳米制造部分 1、Summarize the application&#x2F;impact of photolithography. Photolithography is the most significant fabrication process that has revolutionized modern life. The manufacturing of modern gadgets, such as computers, digital TVs, radios, and cell phones, involves photolithography. At the same time, photolithography is acclicable to lots of materials, such as silicon, silica, copper, etc. 2、Why is there a need to develop non-photolithographic processes? As the feature size gets smaller, the requirement for infrastructure gets prohibitively expensive and it is eventually impractical to continuously utilize photolithography in the fabrication of structures with dimensions less than tens of nanometers. The use of an optical field as the manufacturing field in photolithography has an ultimate limitation in the smallest feature sizes this field can handle and eventually it will be technically impossible to generate structures at nanometer scales. 3、Summarize the different fields used in several soft lithography processes. Fabricate structures of mesoporous silica Functional mesoporous silica-based waveguide shape Hierarchically ordered mesoporous silica generated The fabrication of nanocrystal laser 4、Summarize the applications of soft lithography and imprinting lithography. Processing various materials into functional devices, including inorganic materials and fragile, bioactive materials Generating micro and nano reactors for the synthesis of materials at nanometer sizes 5、What is the self-assembly process? How does it fit into intelligent energy field manufacturing? Self-assembly is defined as the process of generating structures with nanometer dimensions by taking advantage of many different fields, such as the chemical field, biointeraction field, flow field, etc. The future of nano-manufacturing development will focus highly on precision, low cost, adaptability to various applications, and being environmentally friendly. And at that time, we may rely more on self-assembly to make nano-structures, which leads to lower carbon footprint and being more friendly to environment. 英 中 photolithography 光刻技术 fabrication 制造 gadgets 小玩意儿 silicon 硅 silica 二氧化硅 copper 铜 soft lithography 软光刻 imprinting lithography 压印光刻 self-assembly 自组装 参考资料： 1、Intelligent Energy Field Manufacturing: Interdisciplinary Process Innovations","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"记一次电子书的制作（从爬取网上资源开始）","slug":"骚操作/2019-12-07-记一次电子书的制作（从爬取网上资源开始）","date":"2019-12-07T12:14:00.000Z","updated":"2021-08-14T08:18:56.000Z","comments":true,"path":"2019/12/07/骚操作/2019-12-07-记一次电子书的制作（从爬取网上资源开始）/","link":"","permalink":"https://lankning.github.io/2019/12/07/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-12-07-%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%B5%E5%AD%90%E4%B9%A6%E7%9A%84%E5%88%B6%E4%BD%9C%EF%BC%88%E4%BB%8E%E7%88%AC%E5%8F%96%E7%BD%91%E4%B8%8A%E8%B5%84%E6%BA%90%E5%BC%80%E5%A7%8B%EF%BC%89/","excerpt":"想到好久没有看小说了，去各大网站看看之后发现了一些爽文，可是他们都没有提供一键下载的服务。由此就产生了这一篇记录，涉及python爬虫知识、文件格式转化问题，参考了各大论坛的操作，最后以epub的格式呈现。","text":"想到好久没有看小说了，去各大网站看看之后发现了一些爽文，可是他们都没有提供一键下载的服务。由此就产生了这一篇记录，涉及python爬虫知识、文件格式转化问题，参考了各大论坛的操作，最后以epub的格式呈现。 主要分为两个步骤，一是用爬虫将网页上的小说内容爬取下来；二是将txt文件转化为我们要的epub格式文件，适合电纸书阅读。 一、爬取小说设计思路： 1、封装好，用户输入小说的目录页url地址 2、得到小说所有章节的对应url，组成一个list 3、在url list里面循环，一章一章爬取小说的标题和正文并存储到指定目录 实现过程： 这里我们使用python和它的一些库，包括bs4，requests，retrying。 在爬取的过程中，可能会因为访问过频繁或者网络原因而被拒绝访问。因此我们需要一个重试函数，能够在报错的情况下反复尝试。我们使用retrying和requests库来实现 得到目录页上陈列的各章节链接。这部分每个网站可能不一样，需要根据自己的情况修改 得到每一个章节url对应的标题和内容 我们发现正文中有很多无关内容以及不正常的字符、缩进等，因此我们需要额外写一个文字过滤器，此过滤器在上面get_text()函数中已经调用了。 开始读取内容并存储 爬虫源代码 二、txt文件转化为epub文件我习惯于EPUB格式的电子书，如果你熟悉使用mobi格式的电子书，可以参考书伴网的EasyPub教程来转化，可以配置封面什么的。 这里我使用NeatReader的本地转化器，他们家的产品做的还挺用心的、功能也不错。 另一种选择是使用参考资料1里面的在线转化器，没有使用过，不作评价。 参考资料： 1、TXT转EPUB工具","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"阿里云服务器上手问题","slug":"小技巧/2019-12-05-阿里云服务器上手问题","date":"2019-12-05T12:14:00.000Z","updated":"2021-08-14T08:10:44.000Z","comments":true,"path":"2019/12/05/小技巧/2019-12-05-阿里云服务器上手问题/","link":"","permalink":"https://lankning.github.io/2019/12/05/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-12-05-%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%89%8B%E9%97%AE%E9%A2%98/","excerpt":"又忍不住开始剁手，在阿里云搞了一个服务器（虽然也不知道干嘛）。记录一下整个过程以及遇到的问题。","text":"又忍不住开始剁手，在阿里云搞了一个服务器（虽然也不知道干嘛）。记录一下整个过程以及遇到的问题。 1、新用户免费体验有一个新用户的免费体验套餐，开发者的分为两种。第一种性能低一点但是时间长，第二章性能好一点但是时间短。 2、学生优惠阿里云的学生服务器叫“云翼计划”，一个月9.5元。跟腾讯云相比，不限续费次数，很实惠！同时24岁以下自动获得学生身份，CPU性能不限。 套餐也是分为两种，第一种性能好，限流量（1000G&#x2F;月，应该够了）；第二种差一些，但是无限流量。 3、远程连接首先在windows菜单里面搜索“远程”，然后输入服务器的公网IP地址进行登录。 在阿里云的控制台里面把自己服务器的登陆密码改掉，改掉之后要重启哦！然后接着连接。 4、通过ie浏览器下载文件 登入之后ie浏览器会报错如下： 打开IE浏览器，单击右上侧设置图标，然后单击 Internet选项。 单击 安全 &gt; Internet &gt; 自定义级别，然后单击 下载 &gt; 文件下载 &gt; 启用 &gt; 确定。 参考资料： 1、如何使用远程桌面连接云服务器 (以阿里云为例) 2、Windows实例中无法通过IE浏览器下载文件","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"安卓手机termux安装jupyter","slug":"骚操作/2019-12-05-安卓手机termux安装jupyter","date":"2019-12-05T12:14:00.000Z","updated":"2021-08-14T08:19:26.000Z","comments":true,"path":"2019/12/05/骚操作/2019-12-05-安卓手机termux安装jupyter/","link":"","permalink":"https://lankning.github.io/2019/12/05/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-12-05-%E5%AE%89%E5%8D%93%E6%89%8B%E6%9C%BAtermux%E5%AE%89%E8%A3%85jupyter/","excerpt":"Termux是一个Android下一个高级的终端模拟器, 开源且不需要root, 支持apt管理软件包，十分方便安装软件包, 完美支持Python, PHP, Ruby, Go, Nodejs, MySQL等。随着智能设备的普及和性能的不断提升，如今的手机、平板等的硬件标准已达到了初级桌面计算机的硬件标准, 用心去打造完全可以把手机变成一个强大的工具.","text":"Termux是一个Android下一个高级的终端模拟器, 开源且不需要root, 支持apt管理软件包，十分方便安装软件包, 完美支持Python, PHP, Ruby, Go, Nodejs, MySQL等。随着智能设备的普及和性能的不断提升，如今的手机、平板等的硬件标准已达到了初级桌面计算机的硬件标准, 用心去打造完全可以把手机变成一个强大的工具. 虽然jupyter要按装的话依赖很多，但其实步骤其实很简单。 1234apt update # 更新包apt-get upgrade # 更新包pkg install clang libzmq fftw freetype python #安装依赖pip install jupyter # 安装jupyter 安装完成之后，还可以安装numpy、matplotlib等包 1pip install numpy matplotlib 安装过程可能会很漫长，我在骁龙855的手机上大概用了一两分钟，而在麒麟960的手机上用了大约十分钟还不见结束。至于骁龙625？抱歉，我没有尝试的勇气","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"记C#窗体写作中遇到的一些问题","slug":"学习笔记/2019-12-02-记C#窗体写作中遇到的一些问题","date":"2019-12-02T12:14:00.000Z","updated":"2021-08-14T07:44:22.000Z","comments":true,"path":"2019/12/02/学习笔记/2019-12-02-记C#窗体写作中遇到的一些问题/","link":"","permalink":"https://lankning.github.io/2019/12/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-12-02-%E8%AE%B0C#%E7%AA%97%E4%BD%93%E5%86%99%E4%BD%9C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","excerpt":"最近帮老师写一个窗体应用，逻辑并不复杂。话说原来是有一个的，代码全套，可惜是我没有一丁点了解的java，于是用C#重构一个。 上一次使用C#的时候还是一年之前，当我把VSCode安装回来的时候盯着屏幕发现：实在是啥也想不起来了。于是有了这一篇笔记，记录我这次恢复记忆中遇到的问题，为下次失忆做准备！","text":"最近帮老师写一个窗体应用，逻辑并不复杂。话说原来是有一个的，代码全套，可惜是我没有一丁点了解的java，于是用C#重构一个。 上一次使用C#的时候还是一年之前，当我把VSCode安装回来的时候盯着屏幕发现：实在是啥也想不起来了。于是有了这一篇笔记，记录我这次恢复记忆中遇到的问题，为下次失忆做准备！ Q1：窗口跳转 首先要有两个窗口，如果已经有了一个，就在资源管理器的项目条目上新建一个C#项。图片示意如下","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"jupyter的远程控制","slug":"骚操作/2019-11-29-jupyter的远程控制","date":"2019-11-29T02:43:00.000Z","updated":"2021-08-14T08:20:32.000Z","comments":true,"path":"2019/11/29/骚操作/2019-11-29-jupyter的远程控制/","link":"","permalink":"https://lankning.github.io/2019/11/29/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-11-29-jupyter%E7%9A%84%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6/","excerpt":"手头有一台亚马逊的ec2微实例闲置，于是就想在这个小小的服务器上搭建一个Jupyter，让我能在任何地方进行远程访问。亲测可行！","text":"手头有一台亚马逊的ec2微实例闲置，于是就想在这个小小的服务器上搭建一个Jupyter，让我能在任何地方进行远程访问。亲测可行！ 已知： jupyter notebook是基于网页打开的 默认的端口是8888 想法：用内网穿透将8888端口映射出去 结果：失败，jupyter会拒绝我们的访问 解决方案： 生成配置文件 1jupyter notebook --generate-config 生成密码 打开python，创建一个密码。这个密码就是以后我们访问的时候需要输入验证的。 12345&gt;&gt;&gt; from notebook.auth import passwd&gt;&gt;&gt; passwd()Enter password: Verify password: &#x27;sha1:ce...密码串&#x27; 把这里的输入密码之后生成的字符串给记下来 修改配置文件 linux下可以使用vim直接修改，命令是 $vim ~/.jupyter/jupyter_notebook_config.py ；windows下，在目录C:\\Users\\Administer\\.jupyter下找到config.py文件，用记事本打开。 把原来的内容清空后，输入以下内容： 12345c.NotebookApp.ip=&#x27;127.0.0.1&#x27;c.NotebookApp.password = u&#x27;sha1:ce...刚才复制的那个密码串&#x27;c.NotebookApp.open_browser = Falsec.NotebookApp.allow_remote_access = Truec.NotebookApp.port =8888 #指定端口 终端输入jupyter notebook，启动jupyter notebook 开启8888端口映射，即可远程访问！ 我暂时使用的是sunny-ngrok内网穿透，可以用一个免费的隧道进行端口映射。当然你也可以选择花生壳，nat123等工具。 参考资料： 1、简书：玩转jupyter + 远程访问 2、jupyter notebook 初步使用配置调整","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"TensorFlow 2.x可视化--类激活图","slug":"学习笔记/2019-11-26-TensorFlow_2.x可视化--类激活图","date":"2019-11-26T12:14:00.000Z","updated":"2021-08-14T07:45:00.000Z","comments":true,"path":"2019/11/26/学习笔记/2019-11-26-TensorFlow_2.x可视化--类激活图/","link":"","permalink":"https://lankning.github.io/2019/11/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-26-TensorFlow_2.x%E5%8F%AF%E8%A7%86%E5%8C%96--%E7%B1%BB%E6%BF%80%E6%B4%BB%E5%9B%BE/","excerpt":"卷积神经网络在分类问题中如何更好地可视化以证明它确实学习到了一些“知识”？这是写论文的时候导师给我的一个难题。 集思广益之后我发现了这个——“类热力图”。它可以表现出卷积神经网络具体在关注哪些地方，对哪些特征比较敏感。","text":"卷积神经网络在分类问题中如何更好地可视化以证明它确实学习到了一些“知识”？这是写论文的时候导师给我的一个难题。 集思广益之后我发现了这个——“类热力图”。它可以表现出卷积神经网络具体在关注哪些地方，对哪些特征比较敏感。 类激活映射(CAM)是一种生成热力图的技术，用于突出图像的类的特定区域。 由于最终的表达形式看起来像是热力图，即神经网络越“重视”的地方越红，所以我把它叫做“类热力图”，但是多数时候我们都叫它“类激活图”。 如果将“类热力图”在训练过程中可视化，我们将会得到以下的效果。 计算方法：给定一张输入图像，对于一个卷积层的输出特征，用类别相对于通道的梯度对这个特征图中的每个通道进行加权。 通俗地来讲，就是计算最后一个卷积层对应预测结果的梯度，梯度越大代表该通道越重要，越重要的通道最后就越红色。 程序实现包括以下几个步骤： 载入库和模型 读取一张图片进行判断 计算类激活图 将类激活图加诸原来的图像上面 我在我先前训练的tensorflow2.0图像分类实例跑了一下，得到了以下结果： 代码下载：我的Github仓库 参考资料： 1、可视化卷及神经网络热力图 2、论文：Grad-CAM: Why did you say that? 3、知乎大佬：如何利用CAM（类激活图）动态可视化模型的学习过程","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"目标检测--训练集标注工具labelImg的配置和使用","slug":"学习笔记/2019-11-23-目标检测--训练集标注工具labelImg的配置和使用","date":"2019-11-23T12:14:00.000Z","updated":"2021-08-14T07:45:36.000Z","comments":true,"path":"2019/11/23/学习笔记/2019-11-23-目标检测--训练集标注工具labelImg的配置和使用/","link":"","permalink":"https://lankning.github.io/2019/11/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-23-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B--%E8%AE%AD%E7%BB%83%E9%9B%86%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7labelImg%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"我想要自己训练一个目标检测网络，首先需要的就是训练集。可是图片中物体的定位怎么写呢，难道要自己记录目标图像的中心点和锚框大小吗？哭了。。所幸，发现了这个labelImg工具。","text":"我想要自己训练一个目标检测网络，首先需要的就是训练集。可是图片中物体的定位怎么写呢，难道要自己记录目标图像的中心点和锚框大小吗？哭了。。所幸，发现了这个labelImg工具。 作者演示教程： labelImg是一个开源的工具，有可视化界面，如下所示。 安装 Installationwindows下有现成的应用程序可用，百度网盘链接： https://pan.baidu.com/s/1d27UMi 但是在使用这个应用的时候我发现，如果把压缩包解压之后运行这个程序，则小黑框一闪而没，根本用不了。只有在压缩包里面直接打开是可以用的。 使用 Usage 在labelImg文件中，有个data文件夹，里面有predefined_classes.txt记录着分类名称，可以手动更改类别 选择File-&gt;Change Saved Dir（不同版本稍微有些差异，也可能叫做changedefault annatation saved dir）,然后选择一个空文件夹作为你生成的标记xml存放的位置 点击Open Dir选择你的影像图片文件夹 之后，图片便加载进来了，点击左侧Create RectBox，就可以在图像上绘制矩形框了。因为版本差异，绘制矩形框有的需要一直按住鼠标左键，有的则只用初始和结束位置点击一下，视具体版本情况而定。 绘制结束后，会弹出一个框，选择你要标记的类别，比如dog，如果列表里面没有这个类别，可以在方框中输入，最后点击OK。此时，按住Ctrl+S才算保存，之后，可以使用鼠标点击next image进入下一张或者使用快捷键D进入下一张，最终每张图片标注的结果将保存在xml文件中，xml文件和图片名称一致。 快捷键： Ctrl + u Load all of the images from a directory Ctrl + r Change the default annotation target dir Ctrl + s Save Ctrl + d Copy the current label and rect box Space Flag the current image as verified w Create a rect box d Next image a Previous image del Delete the selected rect box Ctrl++ Zoom in Ctrl– Zoom out ↑→↓← Keyboard arrows to move selected rect box 参考资料： 1、源码地址 2、Bilibili视频 3、Windows下深度学习标注工具LabelImg安装和使用指南","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Hexo的icarus主题配置记录","slug":"学习笔记/2019-11-22-Hexo的icarus主题配置记录","date":"2019-11-22T12:14:00.000Z","updated":"2021-08-14T09:02:24.000Z","comments":true,"path":"2019/11/22/学习笔记/2019-11-22-Hexo的icarus主题配置记录/","link":"","permalink":"https://lankning.github.io/2019/11/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-22-Hexo%E7%9A%84icarus%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"刚刚上手的hexo默认的是lanscape主题，而网上流行的主要是next主题，前者太丑，后者太简单，于是我选来选去选择了icarus主题。本篇主要记录hexo的icarus主题配置过程中的一些疑难问题以及解决办法。","text":"刚刚上手的hexo默认的是lanscape主题，而网上流行的主要是next主题，前者太丑，后者太简单，于是我选来选去选择了icarus主题。本篇主要记录hexo的icarus主题配置过程中的一些疑难问题以及解决办法。 1、新建markdown文件的头部写法 我一开始生成了pages之后发现我没有categories，怎么办呢？在创建hexo新文章的时候，默认只会给出title, date, tags三个选项，我们需要把他们扩充成下面几项。其中thumbnail是预览页面展示的图片。 12345title: hexo icarus主题配置的记录date: 2019-11-22 19:22:30categories: [hexo]tags: [hexo]thumbnail: https://blog.zhangruipeng.me/hexo-theme-icarus/images/logo.svg 2、加入评论系统 我这里使用的是gitment。 Gitment是imsun实现的一款基于 GitHub Issues 的评论系统。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown &#x2F; GFM 和代码高亮支持。尤为适合各种基于 GitHub Pages 的静态博客或项目页面。 虽然 Gitment 只能使用 GitHub 账号进行评论，但考虑到博客受众，这是可以接受的。 操作步骤结合icarus作者的教程以及imsun的博客。 需要在主题下的config文件中修改原来的comment部分为： 123456comment: type: gitment owner: xxxxxxxx # (required) GitHub user name repo: xxxxxxxx # (required) GitHub repository name client_id: xxxxxxxx # (required) OAuth application client id client_secret: xxxxxxxx # (required) OAuth application client secret 发现激活不成功，经过搜索，将layout目录下的gitment.ejs这个文件中的两行代码改掉即可。 原来为： 12&lt;link rel=&quot;stylesheet&quot; href=&quot;https://imsun.github.io/gitment/style/default.css&quot;&gt;&lt;script src=&quot;https://imsun.github.io/gitment/dist/gitment.browser.js&quot;&gt;&lt;/script&gt; 修改为： 12&lt;link rel=&quot;stylesheet&quot; href=&quot;https://billts.site/extra_css/gitment.css&quot;&gt;&lt;script src=&quot;https://billts.site/js/gitment.js&quot;&gt;&lt;/script&gt; 3、左边个人信息栏更换图标 原主题给定的是Github, Facebook, Twitter, Dribbble, RSS这六个网页，不符合中国大陆网友的一般习惯（至少不符合我的使用习惯），于是我想把这六个改为Github, Gitee, Bilibili这三个。 仔细查询之后发现theme的config里面使用的是Fontawesome的图标，自己想要什么图标上去搜就好了，注意还要把原来的link替换成自己的。需要重点注意的是，Github之类的这些分类冒号后面不能写注释，一写就报错。修改如下： 12345678910social_links: Github: icon: fab fa-github url: &#x27;https://github.com/Cytor/&#x27; Gitee: icon: fab fa-git-square url: &#x27;https://gitee.com/cytor&#x27; Bilibili: icon: fas fa-tv-retro url: &#x27;https://space.bilibili.com/390519714&#x27; 参考资料 1.icarus作者博客 2.icarus作者Github 3.gitment作者博客 4.解决hexo gitment 的object ProgressEvent问题","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lankning.github.io/tags/Hexo/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"产品数据管理期末题","slug":"学习笔记/2019-11-21-产品数据管理期末题","date":"2019-11-21T12:14:00.000Z","updated":"2021-08-14T09:00:52.000Z","comments":true,"path":"2019/11/21/学习笔记/2019-11-21-产品数据管理期末题/","link":"","permalink":"https://lankning.github.io/2019/11/21/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-21-%E4%BA%A7%E5%93%81%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%9C%9F%E6%9C%AB%E9%A2%98/","excerpt":"产品数据管理期末大作业答案。","text":"产品数据管理期末大作业答案。 1、Review of PDM history and main functions. （简述PDM产生的背景、发展历程和主要功能，英文答题） 背景：在 20世纪的60、70年代，企业在其设计和生产过程中开始使用CAD、CAM等技术，新技术的应用在促进生产力发展的同时也带来了新的挑战，主要包括：企业在产品开发过程中需存储与管理大量数据；异构计算机应用系统需要信息集成以及在更高层次上企业在生产过程中需要实现过程集成。到了20世纪80年代，关系数据库技术得到飞速的发展，并得到广泛的应用。产品数据管理(Product Data Management，PDM)正是在这一背景下应运而生的一项新的管理思想和技术 历程： 配合CAD工具的PDM系统：这些产品的目标主要是解决大量电子数据的存储和管理问题，提供了维护“电子绘图仓库”的功能。它仅在一定程度上缓解了“信息孤岛”问题，仍普遍存在功能较弱、集成能力和开放程度较低等问题。 专业PDM产品产生：在第二代PDM出现了许多新功能，如对产品生命周期内多种形式产品数据的管理能力、产品结构与配置管理、电子数据发布和更改控制、基于成组技术的零件分类管理等，同时软件的集成能力和开放程度也有较大提高，少数优秀的PDM产品可以真正实现企业级的信息集成和过程集成。 PDM的标准化阶段：1997年2月，OMG组织公布了其PDM Enabler标准草案，使得不同PDM可以互操作。 CPC和PLM：即协同产品商务和产品全生命周期管理，基于网络的分布式计算技术、Web和Java技术等的应用。 功能： 文档管理：文档分类；文档审批发放；浏览与圈阅 产品结构管理：零部件分类管理；BOM多视图管理 工程更改管理：更改流程；发布管理 应用集成：PDM的管理的主要对象来源于CAD系统，因此每一个PDM系统都有与之相对应的CAD系统，并且有很好的集成。 2、简述文档管理的主要内容和功能 主要内容（网上答案）：分类与查询管理、物理存储策略、逻辑组织机制、浏览与圈阅、审批发放流程、版本管理、权限控制。 主要内容（课件答案）： 实现文档的层次与联系控制 通过权限控制来保证产品数据的完整性与安全性 提供快速有效的信息访问 实现以产品数据为核心的信息共享 功能：通过文档管理，可以让企业很好地组织、管理、控制文档的建立、修改、发布和存档工作。企业人员也可以更加方便、快捷、有效地查找和引用所需要的各种数据和信息。 3、阐述你对产品结构和配置管理的认识 产品结构和配置管理是产品组织和管理的一种形式，它以电子仓库为底层支持，以材料明细表为其组织核心，把定义最终产品的所有工程数据和文档联系起来，实现产品数据的组织、管理与控制，并在一定目标或规则约束下，向用户或应用系统提供产品结构的不同视图和描述，如设计视图、装配视图、制造视图计划视图等。 产品结构是对产品构成的描述，是产品的基本特征。产品结构管理的作用主要有：1）描述产品的零部件组成，包括这些零部件的结构关系、数量和版本；2）物料清单是PDM与ERP进行集成的核心数据对象，它可以由产品结构信息按一定规律导出；3）产品结构是组织与产品相关数据的核心，通过它可以查找到产品中用了哪些零部件，各零部件被用到哪些产品中，与各零部件相关的有哪些文档 ；4）能在产品结构上方便地查看产品、部件、零件和文档的版本信息 产品配置是和产品结构紧密相关的概念，是指对被描述在技术文档中或者体现在产品实际使用过程中的产品功能特性和物理特性进行表示。由于对产品的特性需求最终是通过实际的产品结构来实现的，因此产品配置的结果是具体的产品结构。其作用主要有：1）确保产品结构信息的正确性和可回溯性；2）尽量以面向订单的配置来满足客户对产品及功能的个性化需求，减少重复设计；3）通过配置来管理相似产品，简化产品维护工作，减少产品数据量；4）支持企业减少产品的内部多样化，增加产品的外部多样化，实现从批量生产向批量定制的转换。 4、回答产品开发过程中工程变更的定义以及PDM的对策 工程变更是指在设计完成，各种图纸、文档即将发布或正式发布之后，再针对设计中的尺寸、形状、公差、功能、材料等方面出现的问题所作的一些修改。 基于PDM的变更管理正是为解决上述问题提供了有效途径。首先PDM能够提供给企业一个协同的公共平台，以实现信息的交流与共享，这就消除了企业中各个独立的应用系统所造成的“信息孤岛”现象，不但保证了变更数据高效地在各部门、人员之间的正确流动，而且还能保证数据在变更前后的完整性、一致性。其次，借助PDM中的过程管理、数据对象的生命周期管理等．可以动态地追踪数据的实时状态以及对数据历史状态的追溯，这为管理者实时监控变更活动、有目的地推动或调整变更流程提供了可靠的依据。 5、简述企业应用集成的不同层次及集成方式 不同层次： 封装：电子文件保存在PDM中，在需要时启动应用工具编辑，并能够将修改后的电子文件保存回PDM系统。 单向集成：在封装的基础上，还能提供集成接口从电子文件中提取的管理信息，如图纸的图号、名称、材料等。 双向集成：一般只在同一软件公司提供的产品才可以实现。在PDM和应用系统中都可以处理产品数据，并能够保证数据的一致性。 集成方法： API函数接口：由PDM调用应用提供的API函数来获取需要的信息 交换文件：应用系统与PDM预先约定，双方按约定输出或读入标准格式的交换文件 共享数据库：同样是预先约定，只是输入&#x2F;输出都是基于共享数据集 共用数据库：应用系统与PDM使用的是一个数据库 参考资料： 1、简述PDM 产生的背景、发展历程及主要功能 2、清华——产品数据管理.ppt","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"目标检测(Object Detection)简易应用","slug":"学习笔记/2019-11-20-目标检测(Object_Detection)简易应用","date":"2019-11-20T15:14:00.000Z","updated":"2021-08-14T07:48:34.000Z","comments":true,"path":"2019/11/20/学习笔记/2019-11-20-目标检测(Object_Detection)简易应用/","link":"","permalink":"https://lankning.github.io/2019/11/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-20-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B(Object_Detection)%E7%AE%80%E6%98%93%E5%BA%94%E7%94%A8/","excerpt":"目标检测是计算机视觉中最重要最核心的部分之一，在这里面综合运用了计算机视觉上的各种方法和手段，对于无人驾驶等行业具有重要的意义。本篇文章主要使用Tensorflow Hub对于目标检测算法进行简单的应用。","text":"目标检测是计算机视觉中最重要最核心的部分之一，在这里面综合运用了计算机视觉上的各种方法和手段，对于无人驾驶等行业具有重要的意义。本篇文章主要使用Tensorflow Hub对于目标检测算法进行简单的应用。 1、Tensorflow HubTensorFlow Hub 是一个库，用于发布、发现和使用机器学习模型中可重复利用的部分。模块是一个独立的 TensorFlow 图部分，其中包含权重和资源，可以在一个进程中供不同任务重复使用（称为迁移学习）。 使用较小的数据集训练模型， 改善泛化效果，以及 加快训练速度 2、应用环境：tensorflow2.0 源代码下载：TF-Hub Object Detection Example 有几个问题： 只能整个仓库一起下载，但是整个仓库不大，只有500+k 国内基本上用不了TF Hub，被墙了，如果要下载TF Hub上对应的model，必须要挂个梯子 缩进问题很严重 3、目标检测的发展历程 论文可以参见参考资料1下载，代码可以参见参考资料2下载。 参考资料： 1、Gtihub:deep_learning_object_detection 2、Github:awesome-object-detection 3、TF-Hub","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"机械设计--查询轴承的额定动载荷值","slug":"学习笔记/2019-11-20-机械设计--查询轴承的额定动载荷值","date":"2019-11-20T12:14:00.000Z","updated":"2021-08-14T09:00:58.000Z","comments":true,"path":"2019/11/20/学习笔记/2019-11-20-机械设计--查询轴承的额定动载荷值/","link":"","permalink":"https://lankning.github.io/2019/11/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-20-%E6%9C%BA%E6%A2%B0%E8%AE%BE%E8%AE%A1--%E6%9F%A5%E8%AF%A2%E8%BD%B4%E6%89%BF%E7%9A%84%E9%A2%9D%E5%AE%9A%E5%8A%A8%E8%BD%BD%E8%8D%B7%E5%80%BC/","excerpt":"今天写作业，轴承部分需要用到查询6311轴承的额定动载荷值。可是书上没有对应的表格数据，同时我又不想去图书馆借大部头的《机械设计手册》。这就有了这篇笔记，主要记录如何用电脑查取机械设计相关的数据。","text":"今天写作业，轴承部分需要用到查询6311轴承的额定动载荷值。可是书上没有对应的表格数据，同时我又不想去图书馆借大部头的《机械设计手册》。这就有了这篇笔记，主要记录如何用电脑查取机械设计相关的数据。 一、寻找《手册》电子版最正规的方法当然是寻找《机械设计手册》的电子版了。我在搜索的时候发现了一个神奇的网站，“非标机械设计论坛”，其中有大佬已经发出了机械设计手册的第五版和第六版的pdf，然鹅下载之后我发现版本好像和想象中的有些不一样，并没有我要查的轴承信息。 发现论坛上有人在说这个软件包，我想也不错啊。下载安装完了之后就被这古老的画风感动到了。经查，也确实没有轴承额定载荷的详细信息。 天罗地网终于找到了我要的《手册》，应该是成大先同志编写的大部头，5本一共800多M。 百度网盘： https://pan.baidu.com/s/1qWp25Yk （提取码：r2hk，解压密码： www.jxsjgcs.com） 经查，这个版本的确实没错了！但是，实在是太多了，看到人眼花缭乱！ 二、找企业我去了精工的中国区网站，惊喜地发现真的有轴承型号查询，一边感叹日本人的工匠精神一边输入6311之后，却发现只有内外径之类的少量信息。点击“查看详情”结果是啥都没有。 三、看看有没有专门的网页搜这个的还真的有，而且数据就恰好有额定载荷，（哭）。。。 型号查询网，嗯，很简单直男的名字。查询结果很优秀！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorFlow 2.x下运行1.x版本的代码","slug":"学习笔记/2019-11-19-TensorFlow_2.x下运行1.x版本的代码","date":"2019-11-19T12:14:00.000Z","updated":"2021-08-14T07:49:48.000Z","comments":true,"path":"2019/11/19/学习笔记/2019-11-19-TensorFlow_2.x下运行1.x版本的代码/","link":"","permalink":"https://lankning.github.io/2019/11/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-19-TensorFlow_2.x%E4%B8%8B%E8%BF%90%E8%A1%8C1.x%E7%89%88%E6%9C%AC%E7%9A%84%E4%BB%A3%E7%A0%81/","excerpt":"遇到的问题：tensorflow1.x的许多API在2.0版本中弃用了，怎么办？只能动手改代码了吗，可是很多代码都是复制粘贴的，看懂就要好久。 当我在苦苦改代码时，涉及到一个tf.function函数的操作怎么也改不掉报错，于是询问万能的群友，他说有一个方法可以“把程序简单地从1升级到2”。百度了下，虽然没找到“升级”方法，但是找到了将tensorflow“降级”运行的方法！","text":"遇到的问题：tensorflow1.x的许多API在2.0版本中弃用了，怎么办？只能动手改代码了吗，可是很多代码都是复制粘贴的，看懂就要好久。 当我在苦苦改代码时，涉及到一个tf.function函数的操作怎么也改不掉报错，于是询问万能的群友，他说有一个方法可以“把程序简单地从1升级到2”。百度了下，虽然没找到“升级”方法，但是找到了将tensorflow“降级”运行的方法！ 在程序文件的开头加入以下两行代码： 1import tensorflow.compat.v1 as tftf.disable_v2_behavior() 程序就欢快地跑起来啦！ 参考资料： 1、升级到tensorflow2.0，我整个人都不好了","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorFlow 2.0：建立图像分类网络","slug":"学习笔记/2019-11-18-TensorFlow_2.0：建立图像分类网络","date":"2019-11-18T15:14:00.000Z","updated":"2021-08-14T07:50:18.000Z","comments":true,"path":"2019/11/18/学习笔记/2019-11-18-TensorFlow_2.0：建立图像分类网络/","link":"","permalink":"https://lankning.github.io/2019/11/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-18-TensorFlow_2.0%EF%BC%9A%E5%BB%BA%E7%AB%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/","excerpt":"既然google官方已经推出了tensorflow2.0的正式版，tensorflow的一些新特性让他变得更加便于使用，未来必将取代tensorflow1.x系列，为了避免被淘汰。我开始尝试tensorflow2.0，这是第一篇关于tensorflow2.0的文章，内容是使用tensotflow2.0实现一个图像分类卷积网络。","text":"既然google官方已经推出了tensorflow2.0的正式版，tensorflow的一些新特性让他变得更加便于使用，未来必将取代tensorflow1.x系列，为了避免被淘汰。我开始尝试tensorflow2.0，这是第一篇关于tensorflow2.0的文章，内容是使用tensotflow2.0实现一个图像分类卷积网络。 keras作为tensorflow的一个子模块添加到里面，故可以方便地调用，和1.x版本里面使用keras没有太大什么区别，有变化的地方我会在下面写出来。 这一次我们还是循规蹈矩地做一个三分类的网络。 1、预读取训练数据 图片数据的预读取可以参照我之前一篇文章《神经网络训练–数据预读取和存储》，但是这里因为tensorflow2.0里面集成的keras特性，训练时采用的labels不可以是独热编码(one-hot label)，取而代之的是索引值，因此需要对预读取的代码进行修改。 这样一来，操作上确实是简单了一些，但是代价是逻辑上的不直观。我个人觉得得不偿失。 修改的部分代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940# 载入库from skimage.io import imreadfrom skimage.transform import resizeimport osimport numpy as np# 路径下图片读取，给与标签def load_images(path,reshape=224): contents = os.listdir(path) classes=[each for each in contents if os.path.isdir(os.path.join(path,each))] print(&#x27;目录下有%s&#x27; % classes) # 用labels来存储图片的类别 labels = [] # images数组用来存储图片数据 images = [] i = 0 # 对每个不同种类读取图片到list并且+标签 for i,each in enumerate(classes,0): class_path = os.path.join(path,each) files = os.listdir(class_path) print(&quot;Starting &#123;&#125; images&quot;.format(each),&#x27;数量为&#x27;,len(files)) for file in files: # 载入图片并放入batch数组中 img = imread(os.path.join(class_path, file)) img = img / 255.0 # 这里输入的是图片的缩放尺寸 img = resize(img, (reshape, reshape)) images.append(img.reshape((reshape,reshape,3))) labels.append(i) images = np.array(images) labels = np.array(labels) print(&#x27;总共读取了%d张图片&#x27;%images.shape[0]) return images,labels # 返回图片以及对应的标签path=&#x27;../三类图片/&#x27;train_x,train_y = load_images(path)# 以.npy格式存储在当前目录下np.save(&quot;train_x.npy&quot;,train_x) np.save(&quot;train_y.npy&quot;,train_y) 2、训练程序部分 主要是以下几个步骤： 载入库 读取训练数据 构建神经网咯模型 开始训练 训练过程可视化 下面是源代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#!/usr/bin/env python# coding: utf-8# 载入库import tensorflow as tffrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2Dfrom tensorflow.keras import Model,Sequentialimport matplotlib.pyplot as pltimport numpy as np# 载入训练数据train_x = np.load(&quot;train_x.npy&quot;)train_y = np.load(&quot;train_y.npy&quot;)# 展示一个图片作为样本看看plt.imshow(train_x[0])plt.show()print(train_x.shape)print(train_y.shape)# 模型构建model = Sequential()model.add(Conv2D(32, 3, activation=&#x27;relu&#x27;, input_shape=(224, 224, 3)))model.add(MaxPooling2D((2, 2)))model.add(Conv2D(64, 3, activation=&#x27;relu&#x27;))model.add(MaxPooling2D((2, 2)))model.add(Conv2D(64, 3, activation=&#x27;relu&#x27;))model.add(MaxPooling2D((2, 2)))model.add(Conv2D(128, 3, activation=&#x27;relu&#x27;))model.add(MaxPooling2D((2, 2)))model.add(Conv2D(128, 3, activation=&#x27;relu&#x27;))model.add(MaxPooling2D((2, 2)))model.add(Flatten())model.add(Dropout(0.2))model.add(Dense(1024,activation=&#x27;relu&#x27;))model.add(Dense(1024,activation=&#x27;relu&#x27;))model.add(Dense(3,activation=&#x27;softmax&#x27;))# 模型编译model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])# 开始训练history = model.fit(train_x, train_y, batch_size=20, epochs=5)# 可视化l = np.array(history.history[&#x27;loss&#x27;])a = np.array(history.history[&#x27;accuracy&#x27;])step = np.linspace(1,50,50)plt.plot(step,l,label=&quot;Train Loss&quot;)plt.legend(loc=&#x27;upper right&#x27;)plt.title(&#x27;epoch-loss&#x27;)plt.xlim((0, 50))plt.gca().set_ylim(bottom=0)plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show()plt.plot(step,a,label=&quot;Train Acc&quot;)plt.legend(loc=&#x27;lower right&#x27;)plt.title(&#x27;epoch-acc&#x27;)plt.xlim((0, 50))plt.gca().set_ylim(bottom=0)plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;acc&#x27;)plt.show() Reference: 1、Convolutional Neural Network (CNN) 2、我的Github仓库源码","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"如何注册一个coding个人版账户","slug":"小技巧/2019-11-18-如何注册一个coding个人版账户","date":"2019-11-18T12:14:00.000Z","updated":"2021-08-14T08:11:56.000Z","comments":true,"path":"2019/11/18/小技巧/2019-11-18-如何注册一个coding个人版账户/","link":"","permalink":"https://lankning.github.io/2019/11/18/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-11-18-%E5%A6%82%E4%BD%95%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AAcoding%E4%B8%AA%E4%BA%BA%E7%89%88%E8%B4%A6%E6%88%B7/","excerpt":"网友都说代码托管github，码云（gitee），码市（coding）这三个比较好，我已经有了前面两个，最近心血来潮想要注册一个coding账户，却遇到了困难。","text":"网友都说代码托管github，码云（gitee），码市（coding）这三个比较好，我已经有了前面两个，最近心血来潮想要注册一个coding账户，却遇到了困难。 首先我是直接去了coding的官网，发现右上角有“个人版登录”、“登录”、“注册”三个按钮，我眉头一皱发现事情并没有那么简单。作为一穷二白的非典型性程序员肯定是从“个人版登录”进去再找注册按钮啦。果然不出我所料，“个人版登录”里面确实有一个“注册”按钮，可是当我点击注册的时候，却出现了如下画面！ 我：？？？？？？？？？？ 我是要注册个人账号欸，怎么又给我导向了团队账号？经过实测发现这个页面和官网右上角的注册页面是一样的！ 解决办法： 1、去腾讯云开发者平台官网注册一个账号，我之前注册过腾讯云了，所以很简单地就好了。 2、账号注册好了之后，修改账户配置。首先设置密码，然后添加邮箱，最后修改用户名。比如我gitHub和gitee都是用的cytor为名字，那么这里我就将用户名改为cytor以便于和其他的平台一致。 3、接下来，可以进入到coding官网的个人版登录页面登陆啦。值得一提的是coding的网页交互做的和github以及gitee有区别，后两者基本相同，而coding给人的感觉是独具一格，用了就回不去了。 个人感觉 和github差不多，无限项目、无限容量，git单仓库2G，仓库总共100G，很nice了 国内组织，还是很照顾国内用户网速的，在有限的测试里面基本秒开！ coding-page服务全部给https解析，而且自动部署（码云免费版要手动） coding的个人版配置如下，来源：官网 - 定价。 资源配额 成员数 ≤ 5 人 不限 不限 项目数 不限 不限 不限 总存储容量 不限 不限 不限","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"Hexo中git的配置","slug":"学习笔记/2019-11-18-Hexo中git的配置","date":"2019-11-18T11:14:00.000Z","updated":"2021-08-14T09:02:32.000Z","comments":true,"path":"2019/11/18/学习笔记/2019-11-18-Hexo中git的配置/","link":"","permalink":"https://lankning.github.io/2019/11/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-18-Hexo%E4%B8%ADgit%E7%9A%84%E9%85%8D%E7%BD%AE/","excerpt":"hexo框架下文章写好并生成之后需要推送到GitHub或者其他具有静态页面托管的平台上面，然而一般都会发生很多问题。","text":"hexo框架下文章写好并生成之后需要推送到GitHub或者其他具有静态页面托管的平台上面，然而一般都会发生很多问题。 一、报错 ERROR Deployer not found: git 安装hexo-deployer-git 1npm install --save hexo-deployer-git 二、报错Please tell me who you are. 设置自己的GitHub邮箱号和用户名 12git config --global user.email &quot;you@example.com&quot;git config --global user.name &quot;Your Name&quot; 三、一次性推送到多个平台，该怎么做？ 这个问题很简单，只需要在根目录的config文件里修改即可。 打开”_config.yml”文件，在最下面将deploy那一块代码修改为如下形式即可。 1234567deploy: type: git repo: gitee: 你的gitee仓库提交地址 github: 你的github仓库提交地址 coding: 你的coding仓库提交地址 branch: master — 我是分割线 — 百度上那些扯什么公钥、ssh的，Windows下没有必要，真的。 当在windows环境下，在git bash里面输入“hexo d”进行提交的时候，会自动弹出一个窗口让你输入你每个平台的用户名和密码，第一次完成之后，以后每次提交都不需要输入账户密码等额外操作了。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lankning.github.io/tags/Hexo/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"自控原理复习","slug":"学习笔记/2019-11-16-自控原理复习","date":"2019-11-16T12:14:00.000Z","updated":"2021-08-14T09:01:04.000Z","comments":true,"path":"2019/11/16/学习笔记/2019-11-16-自控原理复习/","link":"","permalink":"https://lankning.github.io/2019/11/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-16-%E8%87%AA%E6%8E%A7%E5%8E%9F%E7%90%86%E5%A4%8D%E4%B9%A0/","excerpt":"还有两天就考试，好耶（哭泣）！开始预习课本了！本篇进行第三章节的重点梳理。第四章第五章来不及写成博客了（继续哭泣）…","text":"还有两天就考试，好耶（哭泣）！开始预习课本了！本篇进行第三章节的重点梳理。第四章第五章来不及写成博客了（继续哭泣）… 第三章 自动控制系统的时域分析3.1 掌握系统稳定性的充要条件，并能根据劳斯判据判定系统的稳定性。（*）1892年李普亚诺夫首先提出了稳定性的严格数学定义，根据稳定性的定义（P62），当系统满足以下条件时，系统稳定，此条件时充要的。$$\\lim_{n \\rightarrow \\infty}C(t)&#x3D;0$$线性系统稳定的充要条件是：系统特征方程的根（即系统的闭环极点）均为负实数或具有负实部的共轭复数。也就是说，系统的全部闭环极点都在复数平面虚轴的左半部。 劳斯稳定判据：在写成s的多项式形式的标准方程中，实部为正数的根的个数等于劳斯表的第一列元素符号改变的次数。 因此，系统稳定的充要条件是：特征方程的全部系数都是正数，并且劳斯表第一列元素都是正数。 3.2 掌握典型输入信号的时域及频域表达式，并掌握阶跃响应性能指标。（*）1）典型输入信号： 单位阶跃函数 时域表达式：$$l(t)&#x3D;\\left{\\begin{aligned}1&amp;,t\\ge0\\0&amp;,t&lt;0\\\\end{aligned}\\right.$$拉氏变换：$ L[l(t)]&#x3D;\\frac{1}{s}$ 频域表达式： 单位斜坡函数 时域表达式：$$r(t)&#x3D;\\left{\\begin{aligned}t&amp;,t\\ge0\\0&amp;,t&lt;0\\\\end{aligned}\\right.$$ 拉氏变换：$L[t∗l(t)]&#x3D;\\frac{1}{s^2}$ 频域表达式： 单位抛物线函数（加速度阶跃函数） 时域表达式：$$r(t)&#x3D;\\left{\\begin{aligned}&amp;\\frac{1}{2}t^2&amp;,t\\ge0\\&amp;0&amp;,t&lt;0\\\\end{aligned}\\right.$$拉氏变换：$L[\\frac{1}{2}t^2∗l(t)]&#x3D;\\frac{1}{s^3}$ 频域表达式： 2）阶跃响应性能指标： 延迟时间tdtd 指输出第一次达到50%稳态值所需时间上升时间trtr 指输出响应第一次到达稳态值的时间峰值时间tptp 指输出超过稳态值到达第一个峰值cmaxcmax所需要的时间最大超调量σσ% 指输出量的最大值超出稳态值的百分比，即 $$\\sigma&#x3D;\\frac{c_max-c_\\infty}{c_\\infty}*100$$ 调节时间tsts 当阶跃响应曲线到达并不再超出误差带所需最小时间，一般取5%c∞c∞的误差振荡次数N 在调节时间内响应曲线偏离稳态值的振荡次数稳态误差essess 当时间t趋于无穷大时，系统单位阶跃响应的稳态值与输入量l(t)l(t)之差，即 $$ess&#x3D;l−c(\\infty)$$ 以上指标中，四个时间反映了系统的快速性，σσ和N反映了平稳性，称为动态性能指标；essess描绘了系统的稳态响应，反映了系统的静态性能，又称为静态性能指标。 3.3 掌握控制系统的动态性能指标求取。重点掌握二阶系统的指标求取，对于高阶系统应掌握主导极点的确定方法。（*）1）一阶系统的动态指标（P73） 可以归纳为几个步骤： 写出闭环传递函数$Φ(s)$，并且与典型形式$Φ(s)&#x3D;\\frac{K}{Ts+1}$对照写出T和K 求取输出量$c(t)$，$c(t)$是$C(t)$的拉式反变换，$C(t)&#x3D;L^{−1}(Φ(s)R(s))$ $c(t)$可以分解成两个式子，分别代表调节响应$c_t(t)$和稳态响应$c_{ss}(t)$ 2）二阶系统的动态指标（P75） 典型形式：$Φ(s)&#x3D;\\frac{K}{T^2S^2+2ξTs+1}$ 若K&#x3D;1，又可以写为$Φ(s)&#x3D;\\frac{w_n^2}{S^2+2ξw_ns+w_n^2}$，式中$w_n&#x3D;\\frac{1}{T}$ 当输入信号是单位阶跃函数的时候，$R(s)&#x3D;\\frac{1}{s}$，则$$C(s)&#x3D;Φ((s)R(S)&#x3D;\\frac{w_n^2}{S^2+2ξw_ns+w_n^2}\\frac{1}{s}&#x3D;\\frac{1}{s}−\\frac{s+2ξw_n}{S^2+2ξw_ns+w_n^2}&#x3D;C_{ss}(s)+C_t(s)$$这里面的ξξ和ωnωn被称为二阶系统的特征参数，经过拉式反变换：$$c_{ss}&#x3D;1;c(t)&#x3D;L^{-1}(-\\frac{s+2\\xi w_n}{s^2+2\\xi w_n+s^2})$$$c_t(t)$的特征方程为其分母，两个特征根为$$s_{1,2}&#x3D;−ξω_n±ω_n\\sqrt{ξ^2−1}$$这里面ξ（阻尼系数）的取值不同时间响应曲线有不同的形状： $ξ&#x3D;0$特征方程有一对共轭虚根（零阻尼）-&gt; 无衰减的周期振荡 $0&lt;ξ&lt;1$ 特征方程有一对共轭复根（欠阻尼）-&gt; 衰减的振荡$ξ&#x3D;1$ 特征方程有一对相等的负实数根（临界阻尼）-&gt; 单调的衰减过程$ξ&gt;1$ 特征方程有两个不同的负实数根（过阻尼）-&gt; 两个指数衰减状态的叠加 [需要掌握的公式] 欠阻尼状态，最大超调量σ%完全由阻尼系数ξ决定：$σ&#x3D;exp(−πξ&#x2F;\\sqrt{1−ξ^2})$ 当ξ比较小时，调节时间：$ts≈\\frac{3}{ξω_n}$（取Δ&#x3D;0.05） 阻尼角β公式：$β&#x3D;arccosξ$ 拉氏变换的终值定理：$\\lim_{t \\rightarrow \\infty}f(t)&#x3D;lim_{s \\rightarrow 0}sF(s)$ 当闭环传递函数的$K≠0$时，需要算出ξξ的值并查图来获得调整时间： [带有零点的二阶系统] 影响：一般来说会是系统响应迅速且具有较大的超调量σσ%。零点与一堆共轭复数在复平面上的相对位置决定了零点对阶跃响应的影响。用α&#x3D;z&#x2F;(ξωn)α&#x3D;z&#x2F;(ξωn)来量化，αα越小，影响程度越大。 规律：有了零点并不会导致时间常数T0T0，但是会增大阻尼系数ξξ，那么就会影响调节时间和最大超调量两个值。 调节时间：$t_s&#x3D;(3+ln\\frac{l}{z})\\frac{1}{ξω_n}$ 最大超调量，查图3-28（P90）： 3)高阶系统主导极点的确定方法 闭环主导极点的概念：这一对极点离虚轴最近，并且其他的零极点要么很远要么抵消了。 非主导极点的判定：当引进的实数极点与主导极点的模值之比$α&#x3D;\\frac{p_3}{ω_n}$大于5时，可以认为时非主导极点，影响可以忽略。 3.4 熟悉系统的稳态误差概念，并要求能够求取给定输入作用下及扰动输入作用下稳态误差。（*）1）稳态误差的定义 从输入端定义为稳定时输入信号和反馈信号之差：$e_{ss}&#x3D;lim_{t→∞}(r(t)−b(t))$ 从输出端定义为输出量的期望值和实际值之差：$e_{ss}&#x3D;lim_{t→∞}(c_0(t)−c(t))$ 由第一种定义推导出来，$e_{ss}&#x3D;lim_{s→0}\\frac{sR(s)}{1+G_K(s)}$ 2）工程上根据积分环节的个数υυ对系统进行分类，分别称为0型、Ⅰ型系统、Ⅱ型系统等 3）例题3-19（P109） 3.5 掌握不同系统型别下，系统的静态位置误差系数KpKp、静态速度误差系数KvKv以及静态加速度误差系数KaKa的求取，以及它们与稳态误差的关系。（*） 单位阶跃函数输入 $K_p$ 与稳态误差的关系$ess&#x3D;\\frac{1}{K_p}$ 对0型系统，$K_p&#x3D;1+K_0$；对于非0型系统，$K_p→∞,e_{ss}&#x3D;0$ 单位斜坡函数输入 $K_v$ 与稳态误差的关系$ess&#x3D;\\frac{1}{K_v}$ 对0型系统，$K_v&#x3D;0,e_{ss}→∞$；对于Ⅰ型系统，$K_v&#x3D;K_0,ess&#x3D;\\frac{1}{K_0}$；对于Ⅱ型系统，$K_p→∞,e_{ss}&#x3D;0$ 单位抛物线函数输入$K_a$ 与稳态误差的关系$ess&#x3D;\\frac{1}{K_a}$ 对0型系统，$K_a&#x3D;0,e_{ss}→∞$；对于Ⅰ型系统，$K_a&#x3D;0,e_{ss}&#x3D;→∞$；对于Ⅱ型系统，$K_a&#x3D;K_0,ess&#x3D;\\frac{1}{K_0}$ 表3-6（P105）完美概括： 3.6 了解PID控制器各部分的作用，并能根据实际系统需求选取合适、经济的控制器。PID调节器各部分的作用分别是比例(P)、积分(I)、微分(D)控制算法。 比例，反应系统的基本（当前）偏差，系数大，可以加快调节，减小误差，但过大的比例使系统稳定性下降，甚至造成系统不稳定； 积分，反应系统的累计偏差 ，使系统消除稳态误差，提高无差度，因为有误差，积分调节就进行，直至无误差； 微分，反映系统偏差信号的变化率，具有预见性，能预见偏差变化的趋势，产生超前的控制作用，在偏差还没有形成之前，已被微分调节作用消除，因此可以改善系统的动态性能。但是微分对噪声干扰有放大作用，加强微分对系统抗干扰不利。 参考资料： 1、自动控制原理（第四版，高国燊等人著） 2、PID调节器各部分的作用分别是什么？","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"自控原理实验（下）","slug":"学习笔记/2019-11-15-自控原理实验（下）","date":"2019-11-15T13:14:00.000Z","updated":"2021-08-14T09:01:08.000Z","comments":true,"path":"2019/11/15/学习笔记/2019-11-15-自控原理实验（下）/","link":"","permalink":"https://lankning.github.io/2019/11/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-15-%E8%87%AA%E6%8E%A7%E5%8E%9F%E7%90%86%E5%AE%9E%E9%AA%8C%EF%BC%88%E4%B8%8B%EF%BC%89/","excerpt":"本次实验将要通过根轨迹来分析系统性能。 本篇文章记录自动控制原理的后三个实验，包括“基于MATLAB控制系统的根轨迹及其性能分析”，“基于MATLAB控制系统的Nyquist图及其稳定性分析”和“基于MATLAB控制系统的Bode图及其频域分析”。","text":"本次实验将要通过根轨迹来分析系统性能。 本篇文章记录自动控制原理的后三个实验，包括“基于MATLAB控制系统的根轨迹及其性能分析”，“基于MATLAB控制系统的Nyquist图及其稳定性分析”和“基于MATLAB控制系统的Bode图及其频域分析”。 $4. 基于MATLAB控制系统的根轨迹及其性能分析1、实验目的（1）熟练掌握使用MATLAB绘制系统零极点图和根轨迹图的方法； （2）学会分析控制系统根轨迹的一般规律。 （3）利用根轨迹图进行系统性能分析。 2、开环闭环传递函数 G(s)称为前向通道传递函数，是输出Xo(s)与偏差E(s)之比； H(s)称为反馈回路传递函数，是反馈信号B(s)与输出Xo(s)之比； 而G(s)*H(s)是被人为定义为系统的开环传递函数Gk(s)，也是反馈信号与偏差之比； 闭环传递函数的定义则为输出与输入之比。 3、根轨迹3.1 概念根轨迹是开环系统某一参数从零变到无穷时，闭环系统特征方程式的根在s平面上变化的轨迹。根轨迹是分析和设计线性定常控制系统的图解方法，使用十分简便，特别在进行多回路系统的分析时，应用根轨迹法比用其他方法更为方便，因此在工程实践中获得了广泛应用。 3.2 根轨迹与系统稳定性1.如果根轨迹全部位于s平面左侧，就表示无论增益怎么改变，特征根全部具有负实部，则系统就是稳定的。 2.如果根轨迹在虚轴上，表示临界稳定，也就是不断振荡。 3.如果根轨迹根轨迹全部都在s右半平面，则表示无论选择什么参数，系统都是不稳定的。 也就是说增益在一定范围内变化时，系统可以保持稳定，但是当增益的变化超过这一阈值时，系统就会变得不稳定，而这一阈值就是出现在根轨迹与虚轴的交点上，在这一点系统临界稳定。最终可由增益的取值范围判断系统的稳定性。 3.3 绘制法则根轨迹的绘制具有以下绘制法则： 法则1.起点和终点 根轨迹的起点和终点。根轨迹起于开环极点（包括无限极点），终于开环零点（包括无限零点）。 法则2.分支数、对称性和连续性 根轨迹的分支数、对称性和连续性。根轨迹的分支数与开环有限零点数m和有限极点数n中的大者相等，它们是连续的并且对称于实轴。 法则3.渐近线 根轨迹的渐近线。当开环n&gt;m时，有n-m条根轨迹分支沿着与实轴交角为$\\varphi_a$、交点为$\\sigma_a$的一组渐近线趋向无穷远处，且有$\\varphi_a&#x3D;\\frac{(2k+1)\\pi}{n&#x3D;m}(k&#x3D;0,1,2,…,n-m-1)$和$\\sigma_a&#x3D;\\frac{\\sum_{i&#x3D;1}^{n}p_i-\\sum_{j&#x3D;1}^{m}}{n-m}$ 法则4.在实轴上的分布 根轨迹在实轴上的分布。实轴上的某一区域，若其右边开环实数零、极点个数之和为奇数，则该区域必是根轨迹。 法则5.分离点与分离角 根轨迹的分离点与分离角。两条或两条以上根轨迹分支在s平面上相遇又立即分开的点，称为根轨迹的分离点，分离点的坐标d是下列方程的解：$$\\sum_{j&#x3D;1}^m\\frac{1}{d-z_j}&#x3D;\\sum_{i&#x3D;1}^m\\frac{1}{d-p_i}$$ 式中，$z_j$为各开环零点的数值；$p_i$为各开环极点的数值；分离角为$(2k+1)\\pi&#x2F;l$ 法则6.起始角与终止角 根轨迹的起始角与终止角。根轨迹离开开环复数极点处的切线与正实轴的夹角，称为起始角；根轨迹进入开环复数零点处的切线与正实轴的夹角，称为终止角。这些角度都可以由特定关系式求出。 法则7.与虚轴的交点 根轨迹与虚轴的交点。若根轨迹与虚轴相交，则交点上的$K’$值和$\\omega$值可用劳斯判据确定，也可令闭环特征方程中的$s&#x3D;j\\omega$，然后分别令其实部和虚部为零而求得。 法则8.根之和 根之和。$$\\sum_{i&#x3D;1}^ns_i&#x3D;\\sum_{i&#x3D;1}^np_i$$ 3.4 实验例子 已知系统的开环传递函数为$G_k(s)&#x3D;\\frac{s^2+5s+5}{s(s+1)(s^2+2s+2)}$，绘制系统的零极点图 1num=[1 5 5];den=[1 3 4 2 0];pzmap(num,den);grid; 2）已知系统的开环传递函数为$G_k(s)&#x3D;\\frac{k}{s(s+1)(s+2)}$，绘制控制图系统的根轨迹图，并分析根轨迹的一般规律 1num=[1];den=[1 3 2 0];rlocus(num,den);grid 根轨迹的一般规律：[黑人问号.jpg] 3）在实验内容（2）中控制系统的根轨迹上分区段取点，构造闭环系统传递函数，分别绘制其对应的阶跃响应曲线，并比较分析 1k=1;z=[];p=[0 -1 -2];[num,den]=zp2tf(z,p,k);rlocus(num,den);grid[k,r]=rlocfind(num,den)[num,den]=zp2tf(z,r,k);step(num,den) s轴右侧 -&gt; 不稳定状态 s轴左侧的曲线弯头部分，产生一对共轭复根 -&gt; 欠阻尼状态 曲线零点处，产生两个相同的特征根 -&gt; 临界稳定状态 左边线段处，特征根均为负实数 -&gt; 过阻尼状态 参考资料： 1、百度百科：根轨迹 2、开环传递函数与闭环传递函数区别？ $5. 基于MATLAB控制系统的Nyquist图及其稳定性分析1、实验目的（1）熟练掌握使用MATLAB绘制系统Nyquist图的方法； （2）能够分析控制系统Nyquist图的基本规律； （3）加深理解控制系统奈奎斯特稳定性判据的实际应用； （4）学会用奈氏图设计控制系统。 2、概念解释2.1 幅相频率特性曲线以角频率$\\omega$为参变量，当从$\\omega$从$0\\to\\infty$变化时，频率特性构成的向量在复平面上描绘出的曲线称为幅相频率特性曲线，又称为极坐标图，或Nyquist曲线，简称奈氏图。 一般表达形式，其中$A(\\omega)$和$\\varphi(\\omega)$分别代表了系统的幅频特性和相频特性：G(jω)&#x3D;A(ω)ejφ(ω)&#x3D;A(ω)cos(φ(ω))+j∗A(ω)sin(φ(ω))G(jω)&#x3D;A(ω)ejφ(ω)&#x3D;A(ω)cos(φ(ω))+j∗A(ω)sin(φ(ω)) 2.2 奈奎斯特稳定性判据（又称奈氏判据）奈奎斯特稳定性判据是利用系统开环频率特性来判断闭环系统稳定性的一个判据，便于研究当系统结构参数改变时对系统稳定性的影响。其内容是：反馈控制系统稳定的充分必要条件是当$\\omega$从$-\\infty\\to+\\infty$时，开环系统的奈氏曲线$G_k(j\\omega)$不穿过（-1，j0）点且逆时针包围临界点（-1，j0）的圈数N等于开环传递函数的正实部极点数P。具体地说： ①对于开环稳定的系统，闭环系统稳定的充分必要条件为开环系统的奈氏曲线$G_k(j\\omega)$不包围（-1，j0）点。反之闭环系统不稳定。 ②对于开环不稳定系统，有P个开环极点位于右半s平面，则闭环系统稳定的充分必要条件为当$\\omega$从$-\\infty\\to+\\infty$时，开环系统的奈氏曲线$G_k(j\\omega)$逆时针包围（-1，j0）点P次。 重要公式： *N &#x3D; Z - P * 当闭环系统稳定时，Z&#x3D;0，上式可变为N &#x3D; - P 3、实验内容1）已知系统的开环传递函数为$G_k(s)&#x3D;\\frac{10}{s^2+2s+10}$，绘制其Nyquist图 1num=10;den=[1 2 10];nyquist(num,den)grid 2）已知系统的开环传递函数为$G_k(s)&#x3D;\\frac{0.5}{s^3+2s^2+s+0.5}$，绘制其Nyquist图，并判定系统的稳定性 1% 第一步，绘制系统的Nyquist图，相应的程序为：num=0.5;den=[1 2 1 0.5];nyquist(num,den)grid% 第二步，确定开环极点在右半s平面的个数p,相应的程序为p=[1 2 1 0.5];roots(p) 运行结果：s右半平面有3个开环极点，所以P&#x3D;3。看图可知，N&#x3D;0。 所以Z&#x3D;N+P&#x3D;0+3&#x3D;3，闭环系统不稳定。 参考内容： 1、欧拉公式 2、百度百科：奈奎斯特稳定判据 $6. 基于MATLAB控制系统的Bode图及其频域分析1、实验目的（1）熟练掌握运用MATLAB命令绘制控制系统Bode图的方法； （2）了解系统Bode图的一般规律及其频域指标的获取方法； （3）熟练掌握运用Bode图分析控制系统稳定性的方法。 2、相关概念2.1 对数频率特性曲线又称频率特性的对数坐标图或伯德（Bode）图，由对数幅频特性曲线（纵坐标为$10lg|G_k(j\\omega)|$，单位是分贝，dB）和对数相频特性曲线（纵坐标为度，°）组成，两者的横坐标都是角频率$\\omega$，采用$lg(\\omega)$分度。 用对数频率特性曲线表示系统频率特性的优点是： ①幅频特性的乘除运算转变为加减运算； ②对系统作近似分析时，只需画出对数幅频特性曲线的渐近线，大大简化了图形的绘制； ③可以用实验方法将测得的系统（或环节）频率响应的数据画在半对数坐标纸上，根据所做出的曲线，估计被测系统的传递函数。 2.2 对数稳定判据对数频率特性曲线是奈氏判据移植到对数频率坐标的结果。若$G_k(j\\omega)$包围（-1，j0）点，即$G_k(j\\omega)$在点（-1，j0）左边有交点，在Bode图中表现为$L(\\omega)&gt;0$分贝所在的频段范围内，$\\varphi(\\omega)$与-180°线有交点。 对数频率稳定性的判据为：闭环系统稳定的充分必要条件是当$\\omega$从零变化到$+\\infty$时，在开环系统对数幅频特性曲线$L(\\omega)&gt;0$分贝的频段内，相频特性$\\varphi(\\omega)$穿越$(2k+1)\\pi(k&#x3D;0,\\pm1,\\pm2,…)$的次数N为$\\frac{P}{2}$，其中$N&#x3D;N_+-N_-$，$N_+$为正穿越次数，$N_-$为负穿越次数，P为开环传递函数的正实部极点数。 2.3 稳定裕度1）相角裕度$\\gamma$ 2）幅值裕度$h_g$ 3）关于相角裕度和增益裕度的几点说明：控制系统的相角裕度和幅值裕度是系统幅相特性曲线对（-1，j0）点靠近程度的度量。因此，这两个裕度可以用来作为设计准则。只用幅值裕度或相角裕度都不足以说明系统的相对稳定性，必须同时给出这两个量。 对于最小相位系统，只有当相角裕度和幅值裕度都是正值时系统才是稳定的。负的裕度表示系统不稳定。为了得到满意的性能，相角裕度应当在30°-60°之间，幅值裕度应大于6dB。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"自控原理实验（上）","slug":"学习笔记/2019-11-09-自控原理实验（上）","date":"2019-11-09T12:14:00.000Z","updated":"2021-08-14T09:01:18.000Z","comments":true,"path":"2019/11/09/学习笔记/2019-11-09-自控原理实验（上）/","link":"","permalink":"https://lankning.github.io/2019/11/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-09-%E8%87%AA%E6%8E%A7%E5%8E%9F%E7%90%86%E5%AE%9E%E9%AA%8C%EF%BC%88%E4%B8%8A%EF%BC%89/","excerpt":"近期即将迎来自动控制原理的考试，考前要做六个实验，遂写下两篇文章为记。 本篇记录前三个实验，包括“时域分析法”，“Simulink仿真”，“用Matlab实现几种典型信号时间响应”。","text":"近期即将迎来自动控制原理的考试，考前要做六个实验，遂写下两篇文章为记。 本篇记录前三个实验，包括“时域分析法”，“Simulink仿真”，“用Matlab实现几种典型信号时间响应”。 $1. 时域分析实验1、实验目的：1、观察单位阶跃信号输入时二阶系统的时间响应，分析ξ、Wn对响应曲线及瞬态响应指标tn tp ts Mp%的影响。 2、了解二阶系统瞬态响应指标的意义其计算。 2、实验内容2.1 将系统的零极点增益模型转换成传递函数模型G(s)&#x3D;6(s+3)(s+1)(s+2)(s+5)G(s)&#x3D;6(s+3)(s+1)(s+2)(s+5) 1k=6z=[-3]p=[-1,-2,-5][num,den]=zp2tf(z,p,k); 2.2 对典型二阶系统G(s)&#x3D;ω2s2+2ξωns+ω2nG(s)&#x3D;ω2s2+2ξωns+ωn2输入单位阶跃信号1（t）,且wn&#x3D;1，ξ分别等于-0.1；-0.2；0；0.1；0.5；1；1.5。及ξ&#x3D;0.5，wn分别等于1; 10; 30; 50的响应曲线。1wn=1kosi=[0 , 0.1 , 0.5 , 1 , 1.5]figure(1)hold onfor kos=kosinum=[ wn ^ 2];den=[1 , 2*kos* wn , wn^ 2];step(num,den)endtitle(&#x27;Step Response&#x27;)hold offgridzoom on 3、遇到问题：3.1matlab中，zp2tf()函数作用：将系统函数的零极点形式 (zp) 转化为系统函数一般形式 (tf) 的系数。 在这里2应该代表转换；zp，zero point &amp; pole -&gt; 零极点；tf, transfer function -&gt; 传递函数。 在matlab中，有一个函数tf(?)，是传递函数的意思，一般学自动控制原理的时候经常用，在s域中，比如要输入G（s）&#x3D;1&#x2F;（s^2+2s+1），就可以在matlab中输入G&#x3D;tf（[1],[1 2 1]）。 零极点形式：分子式系数为k，零点从分子产生（z1, z2, …），极点从分母中产生（p1, p2, …）。 举栗：得到了系统函数H(s)的零极点的值，z为零点的值，p为极点的值，k为系数，如图所示，n1为a的值，d1为b的值，这里的n1,d1,z,p均为向量形式。 3.2 matlab中，step()函数官方注释Step response plot of dynamic system; step response data 官方Description step calculates the step response of a dynamic system. For the state-space case, zero initial state is assumed. When it is invoked with no output arguments, this function plots the step response on the screen. 作用：将一个动态系统的阶跃响应绘图 3.3 matlab中，tf()函数官方注释 Transfer function model 官方Description Use tf to create real-valued or complex-valued transfer function models, or to convert dynamic system models to transfer function form. Transfer functions are a frequency-domain representation of linear time-invariant systems. For instance, consider a continuous-time SISO dynamic system represented by the transfer function sys(s) = N(s)/D(s), where s = jw and N(s) and D(s) are called the numerator and denominator polynomials, respectively. The tf model object can represent SISO or MIMO transfer functions in continuous time or discrete time. 4、知识整理4.1 Z变换Z变换（英文：z-transformation）可将时域信号（即：离散时间序列）变换为在复频域的表达式。它在离散时间信号处理中的地位，如同拉普拉斯变换在连续时间信号处理中的地位。离散时间信号的Z变换是分析线性时不变离散时间系统问题的重要工具，在数字信号处理、计算机控制系统等领域有着广泛的应用。 Z变换在离散系统中的地位与作用，类似于连续系统中的拉氏变换 。同时具有许多重要的特性：如线性、时移性、微分性、序列卷积特性和复卷积定理等等。 已有现成的与拉氏变换表类似的Z表。对于一般的信号序列，均可以由表上直接查出其Z变换。相应地，当然也可由信号序列的Z变换查出原信号序列，从而使求取信号序列的Z变换较为简便易行。 4.2 系统函数用单位脉冲响应h(n)可以表示线性时不变离散系统，这时 y（n）&#x3D;x（n）*h（n） 两边取z变换：**Y(z)&#x3D;X(z)H(z)**则定义为系统函数。 定义： 系统函数是个具有实系数的复变量S的有理函数，即实有理函数，所以它的极点和零点或者是实数而位于实轴上，或者是成共轭对的复数而位于与实轴对称的位量上。就是说，系统函数的极点和零点的分布必定对实轴成镜像对称。 常用系统：因果系统、稳定系统、因果稳定系统 极点和零点： 系统函数的极点和零点的分布必定对实轴成镜像对称。 系统函数一般有n个有限的极点和m个有限的零点。 如果n&gt;m，则当s为无穷大时。函数值limx→∞H(s)&#x3D;limx→∞bmsmansnlimx→∞H(s)&#x3D;limx→∞bmsmansn为零，所以H(s)在无穷大处有一个（n-m）阶的零点，零极点个数都是n个；如果n&lt;m，则当s为无穷大时，函数值limx→∞H(s)&#x3D;limx→∞bmsmansnlimx→∞H(s)&#x3D;limx→∞bmsmansn亦为无穷大，所以H(s)在无穷大处有一个（m-n）阶的极点，零极点个数都是m个。 根据函数分子和分母幂次的高低，可以有若干零点在无穷大处，或者若干极点在无穷大处，即从广义上来说，系统函数极点和零点的数目应该相等。(看不懂) 4.3 线性时不变系统两方面，一方面是线性，满足叠加原理；另一方面是时不变特性。 时不变系统的定义： 就是系统的参数不随时间而变化，即不管输入信号作用的时间先后，输出信号响应的形状均相同，仅是从出现的时间不同。 用数学表示为T[x(n)]&#x3D;y[n]则 T[x(n-n0)]&#x3D;y[n-n0]，这说明序列x(n)先移位后进行变换与它先进行变换后再移位是等效的。 4.4 单位脉冲响应介绍：单位脉冲响应(Unit impulse response)系统对单位脉冲输入的响应。也称作记忆函数。脉冲响应确定一个线性系统的特性，包含有与频率域中的传输函数相同的信息，而传输函数是脉冲响应的拉普拉斯变换。线性系统的输出由系统的输入与它的脉冲响应的卷积给出。 含义： 单位脉冲响应是指一个无穷大的瞬时冲激，并且由于其在时间轴上的积分为1，而t又趋向于零，所以单位脉冲响应的大小应该是无穷大，但是要知道的是，无穷大量也有大小比较，所以单位脉冲响应可以用一个系数对之进行量度。 场景： 在数字信号处理中，单位脉冲响应代表系统的性质，是描述系统的数学公式，也是系统的数学模型。例如：当系统的初始状态为零时，这时给系统输入一个单位脉冲序列x(n)&#x3D;δ(n)，则系统的输出称为单位脉冲响应，简称脉冲响应，用符号h(n)表示。δ(n)&#x3D;{1(当n&#x3D;0时)0(当n≠0时)δ(n)&#x3D;{1(当n&#x3D;0时)0(当n≠0时) 参考资料： 1、[n1,d1]&#x3D;zp2tf(z,p,k)在matlab中什么意思 2、matlab里面的tf函数是什么怎么用 3、MATLAB中的step()函数 4、百度百科：Z变换 5、百度文库：第六章 系统函数3-4 6、百度百科： 线性时不变系统 7、百度百科：单位脉冲响应 $2. Simulink仿真实验内容：用Matlab仿真（simulink）图示系统输入单位阶跃信号1(t)的响应，分析响应曲线的稳态响应Xoss(t),振荡频率wd(rad&#x2F;s)最大超调量Mp,峰值时间tp,进入稳态值+5%误差带的调整时间ts。 实践过程1、进入matlab的simulink进行控件的排布和拖放 2、调整时间3、得出结果图参考资料： 1、MATLAB使用Simulink 进行建模与仿真方法 $3. 用Matlab实现几种典型信号时间响应1、实验内容掌握在matlab环境下建立控制系统模型的方法，并学会调用相应的函数实现单位脉冲信号，单位阶跃信号和单位斜坡信号的响应； 2、典型信号时间响应2.1 单位阶跃响应 单位阶跃函数 单位阶跃函数（Unit Step Function）属于典型输入信号，是一种狄利克雷函数，其形式如下：u(x)&#x3D;{0,t&lt;01,t&gt;0u(x)&#x3D;{0,t&lt;01,t&gt;0很明显的一点是，单位阶跃函数在t&#x3D;0这一点是不连续的。 零状态响应 所谓零状态响应是指系统在接收到指定输入之前处于初始状态，即保证系统是完全因为指定输入（在此为单位阶跃输入）而产生的响应变化。 单位阶跃响应 单位阶跃响应，就是指系统在接收到单位阶跃函数输入后产生的零状态响应。 作用和意义 a) 系统动态性能分析 动态性能是系统性能的一个十分重要的指标，通常用阶跃信号作用来测定系统的动态性能。 一般认为，阶跃信号对于系统来说是十分严峻的工作状态，因为阶跃信号中存在跃断点（不连续点）。 针对零初始状态系统在单位阶跃输入下的响应情况，定义了一系列动态性能指标，用以评判系统的动态性能，如超调量、衰减比、上升时间、调节时间、峰值时间等等。 b) 建立系统响应模型 对于典型的输入信号，如冲激信号、阶跃信号、斜坡信号等，都建立有响应模型（在此即单位阶跃响应模型）。根据模型，可以快速判断出实际系统的动态性能指标参数，只需要代入实际系统的相关测量参数，就可以定量分析其性能指标。 2.2 单位脉冲响应 单位脉冲函数 单位脉冲序列δ(n)的数学定义是δ&#x3D;{0t≠0∞t&#x3D;0δ&#x3D;{0t≠0∞t&#x3D;0而脉冲的面积，即冲量为单位1S&#x3D;∫+∞−∞δ(t)dt&#x3D;1S&#x3D;∫−∞+∞δ(t)dt&#x3D;1 脉冲响应函数 在信号与系统或电路理论等学科中，冲激响应(或叫脉冲响应)一般是指系统在输入为单位冲激函数时的输出（响应）。对于连续时间系统来说，冲激响应一般用函数h(t)来表示。对于无随机噪声的确定性线性系统，当输入信号为一脉冲函数 δ（t） 时，系统的输出响应 h（t）称为脉冲响应函数。 脉冲响应函数可作为系统特性的时域描述。 至此，系统特性在时域可以用h(t)来描述，在频域可以用H(ω)来描述，在复数域可以用H(s) 来描述。三者的关系也是一一对应的。 对于任意的输入 u（t）， 线性系统的输出 y（t）表示为脉冲响应函数与输入的卷积， 即如果系统是物理可实现的,那么输入开始之前，输出为0，即当 τ&lt;0时 h(τ)&#x3D;0，这里τ 是积分变量。 卷积 简单定义：卷积是分析数学中一种重要的运算。 设:f(x),g(x)是R1上的两个可积函数，作积分：∫+∞−∞f(τ)g(x−τ)dt∫−∞+∞f(τ)g(x−τ)dt可以证明，关于几乎所有的实数x，上述积分是存在的。这样，随着x的不同取值，这个积分就定义了一个新函数h(x)，称为函数f与g的卷积，记为*h(x)&#x3D;(f*g)(x)*。 单位脉冲响应 单位脉冲响应，就是指系统在接收到单位脉冲函数输入后产生的零状态响应。 2.3 单位斜坡响应 斜坡函数 斜坡函数是一元实函数，因其图像像斜坡而得名。斜坡函数在负半轴函数值为零，正半轴为形如y&#x3D;At的正比例函数。A&#x3D;1时，称为单位斜坡函数。斜坡函数是系统动力学中经常用来研究系统模型及其反馈系统的有关信息的测试函数。 其函数表达式为：r(t)&#x3D;max(0,t)r(t)&#x3D;max(0,t) 单位斜坡响应 单位斜坡响应，就是指系统在接收到单位斜坡函数输入后产生的零状态响应。 3、问题Q：Matlab中没有斜坡响应信号对应的函数，为什么能用阶跃信号来求解？ A：因为斜坡响应信号的一阶导数就是阶跃信号，四种典型信号的关系如下： 参考资料： 1、百度百科：单位阶跃响应 2、自动控制原理（第四版，高国燊等人著） 3、单位阶跃响应单位斜坡响应 4、[小技巧]让Hexo在使用Mathjax时支持多行公式","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"学科笔记","slug":"学科笔记","permalink":"https://lankning.github.io/tags/%E5%AD%A6%E7%A7%91%E7%AC%94%E8%AE%B0/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Linux解决ssh关闭之后程序终止问题","slug":"小技巧/2019-11-07-Linux解决ssh关闭之后程序终止问题","date":"2019-11-07T12:14:00.000Z","updated":"2021-08-14T08:13:22.000Z","comments":true,"path":"2019/11/07/小技巧/2019-11-07-Linux解决ssh关闭之后程序终止问题/","link":"","permalink":"https://lankning.github.io/2019/11/07/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-11-07-Linux%E8%A7%A3%E5%86%B3ssh%E5%85%B3%E9%97%AD%E4%B9%8B%E5%90%8E%E7%A8%8B%E5%BA%8F%E7%BB%88%E6%AD%A2%E9%97%AE%E9%A2%98/","excerpt":"今天用ssh连接安卓手机上运行的linux deploy，本来运行了一个python脚本，结果一把ssh窗口关掉后台就停止运行了。经过百度，使用nohup命令。","text":"今天用ssh连接安卓手机上运行的linux deploy，本来运行了一个python脚本，结果一把ssh窗口关掉后台就停止运行了。经过百度，使用nohup命令。 nohup 是 no hang up 的缩写，就是不挂断的意思。 nohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。 用途：LINUX命令用法，不挂断地运行命令。 在命令行输入以下指令就好了： 1sudo nohup python3 main.py &gt;&gt;/home/cytor/main.out 2&gt;&amp;1 &amp; 其中 ‘&#x2F;home&#x2F;cytor&#x2F;main.out’ 指定了输出内容保存的位置和名称。 而0，1，2则代表不同的输出格式： 0 – stdin (standard input)， 1 – stdout (standard output)， 2 – stderr (standard error) ； 2&gt;&amp;1是将标准错误（2）重定向到标准输出（&amp;1），标准输出（&amp;1）再被重定向输入到myout.file文件中。 参考资料： 1、nohup 详解 2、nohup百度百科","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"TensorFlow 1.x：keras训练卷积神经网络","slug":"学习笔记/2019-11-06-TensorFlow_1.x：keras训练卷积神经网络","date":"2019-11-06T12:14:00.000Z","updated":"2021-08-14T07:55:10.000Z","comments":true,"path":"2019/11/06/学习笔记/2019-11-06-TensorFlow_1.x：keras训练卷积神经网络/","link":"","permalink":"https://lankning.github.io/2019/11/06/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-06-TensorFlow_1.x%EF%BC%9Akeras%E8%AE%AD%E7%BB%83%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。","text":"Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。 如果你在以下情况下需要深度学习库，请使用 Keras： 允许简单而快速的原型设计（由于用户友好，高度模块化，可扩展性）。 同时支持卷积神经网络和循环神经网络，以及两者的组合。 在 CPU 和 GPU 上无缝运行。 Keras的后台支持tensorflow和theno，看起来就像是一个非常正式的高级封装，非常有助于快速的开发。最近我也正从tensorflow的低级封装转到高级封装，没有别的原因，生命苦短。 本文将进行一个猫狗分类。 首先载入库当然如果没有安装keras的要先安装一下哦，安装keras之前要保证自己的设备上已经有了tensorflow或者theno。 12345import numpy as npimport kerasfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Flattenfrom keras.layers import Conv2D, MaxPooling2Dfrom keras.optimizers import SGD 接着构建模型这里构建模型超级简单，使用Sequential()新建之后再add就可以了。 1234567891011121314151617model = Sequential()# 输入: 3 通道 32x32 像素图像 -&gt; (32, 32, 3) 张量。# 使用 32 个大小为 3x3 的卷积滤波器。model.add(Conv2D(32, (3, 3), activation=&#x27;relu&#x27;, input_shape=(32, 32, 3)))model.add(Conv2D(32, (3, 3),activation=&#x27;relu&#x27;))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.25))model.add(Conv2D(64, (3, 3), activation=&#x27;relu&#x27;))model.add(Conv2D(64, (3, 3), activation=&#x27;relu&#x27;))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(256, activation=&#x27;relu&#x27;))model.add(Dropout(0.5))model.add(Dense(2, activation=&#x27;softmax&#x27;)) 接下来读取训练数据数据的预读取已经完成，详见神经网络训练–数据预读取和存储。 训练数据一共是20对图片和标签，其中标签最好使用keras的to_categorical转化一下。我这里train_y原来就是0&#x2F;1，shape是(20,1)，经过转化之后，值变成了[1,0]&#x2F;[0,1]，shape变成了(20,2)。 12345# 直接读取之前存储的二进制文件train_x = np.load(&quot;train_x.npy&quot;)train_y = np.load(&quot;train_y.npy&quot;)# 必须要把label搞一个to_categoricaltrain_y = keras.utils.to_categorical(train_y) 编译、训练选用梯度下降法SGD，编译之后训练100个epoch。 12345sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)model.compile(loss=&#x27;categorical_crossentropy&#x27;, optimizer=sgd, metrics=[&quot;accuracy&quot;])his = model.fit(train_x, train_y, batch_size=10, epochs=100)score = model.evaluate(train_x, train_y, batch_size=20) 过程可视化将mode.fit的结果通过图像展示出来看看。 1234567891011121314151617181920l = np.array(his.history[&#x27;loss&#x27;])import matplotlib.pyplot as pltstep = np.linspace(1,100,100)plt.plot(step,l,label=&quot;Train Loss&quot;)plt.legend(loc=&#x27;upper right&#x27;)plt.title(&#x27;epoch-loss&#x27;)plt.xlim((0, 100))plt.gca().set_ylim(bottom=0)plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show()a = np.array(his.history[&#x27;accuracy&#x27;])plt.plot(step,a,label=&quot;Train Accuracy&quot;)plt.legend(loc=&#x27;lower right&#x27;)plt.title(&#x27;epoch-acc&#x27;)plt.xlim((0, 100))plt.ylim((0, 1.005))plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;acc&#x27;)plt.show() [ 参考资料： 1、Keras中文文档–开始使用 Keras Sequential 顺序模型","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"神经网络训练--数据预读取和存储","slug":"学习笔记/2019-11-04-神经网络训练--数据预读取和存储","date":"2019-11-04T12:14:00.000Z","updated":"2021-08-14T07:56:34.000Z","comments":true,"path":"2019/11/04/学习笔记/2019-11-04-神经网络训练--数据预读取和存储/","link":"","permalink":"https://lankning.github.io/2019/11/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-04-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83--%E6%95%B0%E6%8D%AE%E9%A2%84%E8%AF%BB%E5%8F%96%E5%92%8C%E5%AD%98%E5%82%A8/","excerpt":"在我训练卷积神经网络的过程中，每一次训练都需要读取训练图片、测试图片，每一张图片都很大，所以读取数据就需要很长时间。但是训练的时候往往会把图片压缩，因此就产生了将图片第一次读取之后就以训练的shape存储在本地供下一次读取。","text":"在我训练卷积神经网络的过程中，每一次训练都需要读取训练图片、测试图片，每一张图片都很大，所以读取数据就需要很长时间。但是训练的时候往往会把图片压缩，因此就产生了将图片第一次读取之后就以训练的shape存储在本地供下一次读取。 我们这里使用numpy将读取进来的图片数据和对用的label存储到同级目录下面。其中，load_images函数使用的是skimage和sklearn两个包，源码可见于tensorflow卷积等操作的高级封装 1234567import numpy as np#首先读取数据path = &#x27;./pics&#x27;train_x,train_y = load_images(path)# 转存为二进制文件方便下次读取np.save(&quot;train_x.npy&quot;,train_x) np.save(&quot;train_y.npy&quot;,train_y) 完成之后，下次训练时需要载入，则使用以下代码即可： 123# 直接读取之前存储的二进制文件train_x = np.load(&quot;train_x.npy&quot;)train_y = np.load(&quot;train_y.npy&quot;) 这样就迅速得到了训练集内容。 以下是读取展示： 展示其shape 展示其图像","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"目标检测--滑动窗口算法的原理和实现","slug":"学习笔记/2019-11-01-目标检测--滑动窗口算法的原理和实现","date":"2019-11-01T14:14:00.000Z","updated":"2021-08-14T07:57:06.000Z","comments":true,"path":"2019/11/01/学习笔记/2019-11-01-目标检测--滑动窗口算法的原理和实现/","link":"","permalink":"https://lankning.github.io/2019/11/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B--%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%AE%97%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/","excerpt":"滑动窗口算法作为最原始最简单的深度学习目标检测算法，容易上手并且原理简单，深受鄙人的喜爱。 本文将简单介绍滑动窗口算法的原理并且使用python实现它。","text":"滑动窗口算法作为最原始最简单的深度学习目标检测算法，容易上手并且原理简单，深受鄙人的喜爱。 本文将简单介绍滑动窗口算法的原理并且使用python实现它。 原理 首先选定一个特定大小的窗口，并使用以上的卷积神经网络判断这个窗口中有没有目标物体，滑动目标检测算法会从左上角向右并向下滑动输入窗口，并将截取的图像都输入到 已经训练好的卷积神经网络中 以固定步幅滑动窗口，遍历图像的每个区域 然后使用比以上使用的窗口大一些的窗口，重复进行以上操作。然后再使用比上一次更大的窗口进行图像的截取与检测。 所以无论目标在图像中的什么位置,总有一个窗口可以检测到它。 缺点： 但是滑动窗口目标检测算法有十分消耗计算成本的缺点，因为使用窗口会在原始图片中截取很多小方块,并且卷积神经网络需要一个个的进行处理。虽然使用较大的步长可以有效的节省计算成本，但是粗粒度的检测会影响性能，小步幅和小窗口就会大量的耗费计算成本 早些时候在普通的线性分类器上使用滑动窗口目标检测算法可以有很好的性能，但是对于卷积神经网络这种对于图像识别相当耗费性能的算法而言，需要对滑动窗口算法进行重新设计。 实现1. 载入需要的库123456import numpy as npimport tensorflow as tfimport cv2import timeimport matplotlib.pyplot as pltfrom skimage.io import imreadfrom skimage.transform import resize 2. 神经网络的重载 首先需要提前训练神经网络，这里没有啥好讲的，可以参照我之前的两篇博文 《tensorflow卷积等操作的高级封装》 《tensroflow实战–训练BP神经网络》 重载 调用第一步里面训练好的神经网络，对每一个格子进行0&#x2F;1判别（0为没有目标，1为有目标） 1234567891011121314time_start = time.time()saver=tf.train.import_meta_graph(&#x27;./model/model.ckpt.meta&#x27;) sess=tf.Session()sess.run(tf.compat.v1.global_variables_initializer())saver.restore(sess, tf.train.latest_checkpoint(&#x27;./model/&#x27;))# 直接获取保存的变量# 获取placeholder变量input_x = sess.graph.get_tensor_by_name(&#x27;x:0&#x27;)input_y = sess.graph.get_tensor_by_name(&#x27;y:0&#x27;)keep_prob = sess.graph.get_tensor_by_name(&#x27;keep_prob:0&#x27;)# 获取需要进行计算的operatory_conv = sess.graph.get_tensor_by_name(&#x27;y_conv:0&#x27;)time_end = time.time()print(&#x27;模型重载完成！耗时%ss&#x27;%str(time_end-time_start)) 3. 滑动窗口的实现据吴恩达口述，可以使用卷积的操作代替图片的切割， 卷积神经网络的滑动窗口实现提高了整个算法的效率。但是鄙人没能搞明白为什么以及怎么做，因此笔者还是采用了原始的图像切割方法。 先读取图片 1234567def load_image(path): img = imread(path) img = resize(img,(900,900)) return imgpath = &#x27;路径&#x27;x_image = load_image(path,k) 将大图片分割成30x30的小图片，这里面大图片宽高最好是30的倍数，可以载入的时候先resize一下。上图像切割代码： 123456789101112131415def fenge(image): #得到图片的高和宽 h,w,d = image.shape small_img = np.zeros((int(h/30)*int(w/30),30,30,3)) #30x30图片分割 for i in range(int(h/30)):#行 for j in range(int(w/30)):#列 small_img[i*int(w/30)+j,:,:,:]=image[30*i:30*i+30,30*j:30*j+30,:] small_img = small_img.astype(int) return small_img# 获取image的shapeh,w,d = x_image.shape# 30x30图片分割small_img = fenge(x_image) 原图的shape假设为(900,900,3)，切割之后就变成了(900,30,30,3) 4. 小格子判别图像切割完毕，现在需要对30x30的小格子进行识别。 做出预测： 12345pred = sess.run(y_conv, &#123;input_x: small_img,keep_prob:1.&#125;)print(pred.shape)print(&#x27;预测完成!&#x27;)img_label = np.zeros(1080,dtype=np.int)img_label = pred[:,0].astype(int) 为存在目标的格子添加边框： 12345678def add_bound(img): img = cv2.rectangle(img,(0,0),(29,29),(255,0,0),1) return img##加边框for i in range(len(img_label)): if img_label[i]==1: small_img[i*30:i*30+30,:,:] = add_bound(small_img[i*30:i*30+30,:,:]) 5. 重排图像并保存123456789101112131415#small_img重排for i in range(int(h/30)):#行 for j in range(int(w/30)):#列 x_image[30*i:30*i+30,30*j:30*j+30,:]=small_img[i*int(w/30)+j,:,:,:]plt.rcParams[&#x27;savefig.dpi&#x27;] = 300 #图片像素plt.rcParams[&#x27;figure.dpi&#x27;] = 100 #分辨率plt.axis(&#x27;off&#x27;)plt.imshow(x_image)plt.savefig(&#x27;judge.png&#x27;,bbox_inches=&#x27;tight&#x27;,pad_inches=0.0)#,dpi=300plt.show()print(&#x27;图片存好了!&#x27;)# 关闭tf.sessionsess.close() 6. 效果图 参考资料： 1、[DeeplearningAI笔记]卷积神经网络3.1-3.5目标定位&#x2F;特征点检测&#x2F;目标检测&#x2F;滑动窗口的卷积神经网络实现&#x2F;YOLO算法","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Windows上安装自带的Linux","slug":"骚操作/2019-11-01-windows上安装自带的linux","date":"2019-11-01T12:14:00.000Z","updated":"2021-08-14T08:21:12.000Z","comments":true,"path":"2019/11/01/骚操作/2019-11-01-windows上安装自带的linux/","link":"","permalink":"https://lankning.github.io/2019/11/01/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-11-01-windows%E4%B8%8A%E5%AE%89%E8%A3%85%E8%87%AA%E5%B8%A6%E7%9A%84linux/","excerpt":"因为专业课程原因，需要使用Solidworks，我不得不把电脑从deepin回退到Windows10。怀着对linux简单粗暴的命令行的回忆，我发现了Windows上可以下载自带的Ubuntu等linux系统，开心坏了。以下就是具体的安装步骤。","text":"因为专业课程原因，需要使用Solidworks，我不得不把电脑从deepin回退到Windows10。怀着对linux简单粗暴的命令行的回忆，我发现了Windows上可以下载自带的Ubuntu等linux系统，开心坏了。以下就是具体的安装步骤。 修改设置 首先我们要打开Windows功能 在这里把勾打上 然后打开设置–更新和安全–针对开发人员，选择开发人员模式–确定启动，就行了 安装Ubuntu 打开MS Store，搜索linux 选择Ubuntu并安装 打开Ubuntu程序，配置用户名和密码，Over~ 参考资料： 1、在win10下安装自带的linux,并进行相应的配置","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"目标检测--YOLO的原理步骤学习笔记","slug":"学习笔记/2019-11-01-目标检测--YOLO的原理步骤学习笔记","date":"2019-11-01T09:14:00.000Z","updated":"2021-08-14T07:57:36.000Z","comments":true,"path":"2019/11/01/学习笔记/2019-11-01-目标检测--YOLO的原理步骤学习笔记/","link":"","permalink":"https://lankning.github.io/2019/11/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-11-01-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B--YOLO%E7%9A%84%E5%8E%9F%E7%90%86%E6%AD%A5%E9%AA%A4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"YOLO (You Only Look Once)是一种端到端学习的目标检测算法，已经更新迭代了好几代，因为响应迅速、抓取准确等优点被广泛使用。本文以吴恩达深度学习作业(提取码:cw7y)中的无人驾驶路测场景为例子整理。","text":"YOLO (You Only Look Once)是一种端到端学习的目标检测算法，已经更新迭代了好几代，因为响应迅速、抓取准确等优点被广泛使用。本文以吴恩达深度学习作业(提取码:cw7y)中的无人驾驶路测场景为例子整理。 第一步：网格化&#x2F;训练网络将训练图片（这里的shape是608，608，3）划分为19x19的网格，每一个网格有两个属性——锚框（anchor box）和类别（classes）。每个网格对应有5个锚框，80个类别。 ![architecture](https://s2.ax1x.com/2019/11/01/K7v22q.png 因此，我们将要训练一个端到端的神经网络，输入的shape是（m,608,608,3），输出的shape是（m,19,19,5,85）。这里的m是一次输入的图片数量。我们观察上图可以看到85&#x3D;80类别+5参数，这5个参数分别代表什么呢？ 符号 意义 pc 目标网格内有无要检测的目标，取值为[0,1] bx|by bx 和by确定的是边界框相对于网格单元的中心坐标 bw|bh bw 和bh确定的是边界框相对于整个图像的宽和高 加上这5个参数，我们就能得到边界框的准确位置了。通过下图，我们可以观察这5个参数究竟是如何运作的，能得到什么。 例设这里的box1是我们取神经网络的output[0,0,0,0,:]，神经网络判断这个格子里面有要检测的目标，可能性为pc，我们把pc乘上ci就得到了全局的存在可能性{pcci}，score&#x3D;max{pcci}&#x3D;0.44，查一下数组的索引得到对应的类别是car。 本来$$\\sum_{i&#x3D;0}^nc_i&#x3D;1$$ $c_i$对应的是以这个格子为系统，各个分类的概率，当我们乘上pc之后， pcci就变成了一个全局的概率，有利于以后不同格子之间的对比。 当我们把这个神经网络训练好了之后，如果不考虑锚框的话，就可以得到下图类似的可视化效果 考虑锚框的话，就得到下图可视化效果 第二步：过滤锚框 阈值过滤（thresholding） 经过第一步的分析，每一个锚框都有一个对应的score属性，这个属性在全局是公平的。这一步，我们选定一个阈值排除掉score过于小的锚框，一般可以取0.7，视情况调整。 非最大值抑制（Non-max suppression） 有的时候，对于同一辆车，神经网络会给出多个锚框，在这种情况下我们使用非最大值抑制就可以选择出最合适的一个框。 非最大值抑制使用了一个重要指标——交并比(IoU, Intersection over Union)，其定义图如下。 在本例中，给三个锚框按照score降序分别标号为A,B,C， 如果B和C与A的交并比大于一个阈值sigma，就舍弃B,C并保留A；如果B和C与A的交并比均小于阈值sigma，则保留B和C，再对B和C进行非最大值抑制。 第三步：边框回归（Bounding Box Regression）为什么要进行边框回归呢？因为有的时候神经网络返回的锚框并不准确，如下图红框。因此我们就需要边框回归使得红框拓展为绿框使得边界框变得更加准确。 边框回归的步骤：（详细见参考资料4，我也不太明白） 先做平移变换 再做尺度缩放 总结一图以概之： 参考资料： 1、简书:YOLO 2、Markdown公式、特殊字符、上下标、求和&#x2F;积分、分式&#x2F;根式、字体 3、非最大值抑制（Non-max suppression） 4、边框回归(Bounding Box Regression)详解","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"GANs简述","slug":"学习笔记/2019-10-30-GANs简述","date":"2019-10-30T12:14:00.000Z","updated":"2021-08-14T07:58:04.000Z","comments":true,"path":"2019/10/30/学习笔记/2019-10-30-GANs简述/","link":"","permalink":"https://lankning.github.io/2019/10/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-10-30-GANs%E7%AE%80%E8%BF%B0/","excerpt":"GANs概述：内置两个神经网络–生成器G和判断器D。生成器会产生一个假的输出，目的是为了能欺骗判断器；而判断器的目的是为了能准确地判断生成器发来的结果。","text":"GANs概述：内置两个神经网络–生成器G和判断器D。生成器会产生一个假的输出，目的是为了能欺骗判断器；而判断器的目的是为了能准确地判断生成器发来的结果。 适用于：数据较少，但要求较高的地方 缺点： 难训练，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D&#x2F;G 的训练需要精心的设计 模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习 特征： 具有创造性（具有制造以假乱真的能力） 类似于周伯通的左右互搏之术，无聊的时候自己玩，慢慢功力也惊人了 应用案例： |提高图片分辨率 |照片修复(这就是我们需要用到的地方，修补缺陷再和原图量化差距) |生成假的人脸（实际上这些人不存在） |根据人脸生成对应的漫画表情（iPhone的相机有类似的应用） |图像风格迁移（让左上角的原图获得其他图片的风格，形成了新的图片） |3D自动建模– 给出多个不同角度的2D图像，就可以生成一个3D模型 参考资料： 1、生成对抗网络 – Generative Adversarial Networks | GAN 2、Artistic Style Transfer with Convolutional Neural Network 3、Understanding Generative Adversarial Networks (GANs)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorFlow 1.x 实战--训练BP神经网络","slug":"学习笔记/2019-10-26-TensorFlow_1.x_实战--训练BP神经网络","date":"2019-10-26T12:14:00.000Z","updated":"2021-08-14T07:58:48.000Z","comments":true,"path":"2019/10/26/学习笔记/2019-10-26-TensorFlow_1.x_实战--训练BP神经网络/","link":"","permalink":"https://lankning.github.io/2019/10/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-10-26-TensorFlow_1.x_%E5%AE%9E%E6%88%98--%E8%AE%AD%E7%BB%83BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"BP(back propagation)神经网络是1986年由Rumelhart和McClelland为首的科学家提出的概念，是一种按照误差逆向传播算法训练的多层前馈神经网络，是目前应用中最基本的神经网络。","text":"BP(back propagation)神经网络是1986年由Rumelhart和McClelland为首的科学家提出的概念，是一种按照误差逆向传播算法训练的多层前馈神经网络，是目前应用中最基本的神经网络。 运行环境：tensorflow1.14.0 新建程序文件打开ide我这里使用的是jupyter notebook，优点是容易调试，简单清爽。 在终端输入jupyter notebook即可在浏览器里面打开，windows是在cmd里面输入。 载入必要的库123456789# 第一步：引入库import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinefrom skimage.io import imreadfrom skimage.transform import resizeimport osimport random 载入封装好的函数 封装生成参数函数，全连接层函数等 12345678910111213141516# 第二步：封装卷积函数等def weight_variable(shape): initial = tf.truncated_normal(shape, mean=0, stddev=0.01) #正态初始化 return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)def fulc(x,next_depth): depth = x.get_shape()[-1].value w = weight_variable([depth, next_depth]) b = bias_variable([next_depth]) r = tf.nn.relu(tf.nn.bias_add(tf.matmul(x, w), b)) return r 封装读取图片函数（顺便给标签） 123456789101112131415161718192021222324252627282930# 第三步：封装读取图片并自动给标签函数def load_images(path): contents = os.listdir(path) classes = [each for each in contents if os.path.isdir(os.path.join(path,each))] print(&#x27;目录下有%s&#x27; % classes) # 用labels来存储图片的类别 labels = [] # images数组用来存储图片数据 images = [] # 对每个不同种类读取图片到list并且+标签 for each in classes: class_path = os.path.join(path,each) files = os.listdir(class_path) print(&quot;Starting &#123;&#125; images&quot;.format(each),&#x27;数量为&#x27;,len(files)) for ii, file in enumerate(files, 1): # 载入图片并放入batch数组中 img = imread(os.path.join(class_path, file)) img = img / 255.0 img = resize(img, (32, 32)) images.append(img.reshape((32,32,3))) labels.append(each) images = np.array(images) #将labels的list形式转换为one_hot_label from sklearn.preprocessing import LabelBinarizer lb = LabelBinarizer() lb.fit(labels) labels_vecs = lb.transform(labels) print(&#x27;总共读取了%d张图片&#x27;%images.shape[0]) # print(labels,labels_vecs) return images,labels_vecs # 返回图片以及对应的标签 随机抽取图片并打乱顺序 123456789101112131415def next_batch(train_data, train_target, batch_size): #抽取数据 index = [ i for i in range(0,len(train_data))] np.random.shuffle(index); batch_data = np.zeros((batch_size,train_data.shape[1],train_data.shape[2],train_data.shape[3])); batch_target = np.zeros((batch_size,train_target.shape[1])); rand = random.randint(1,4)*2 for i in range(0,batch_size): batch_data[i,:,:,:] = train_data[index[i],:,:,:] #rotate(train_data[index[i]],rand,height,width) batch_target[i,:] = train_target[index[i],:] state = np.random.get_state() np.random.shuffle(batch_data) np.random.set_state(state) np.random.shuffle(batch_target) return batch_data, batch_target 封装神经网络结构把上面的封装好的函数拿来用。 12345678910111213141516# 第四步：封装神经网络的创建函数def create(x_images,keep_prob):#x_images的shape是h,w,d h,w,d=x_images.get_shape().value #first fully layer h_conv_flat = tf.reshape(x_images,[-1,h*w*d]) h_fc1 = fulc(h_conv_flat,1024) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #second fully layer h_fc2 = fulc(h_fc1_drop,1024) h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob) #third full layer h_fc3 = fulc(h_fc2_drop,1) out = tf.nn.sigmoid(h_fc3,name=&#x27;out&#x27;) # 二分类（输出为1个数字）可以用sigmoid；多分类用softmax print(&#x27;模型建立好了！&#x27;) return out tensorflow特色占位在tensorflow1.x版本内，训练前需要先在内存中“占位”。 既然如此，我们把模型创建、损失函数的定义、准确率的定义也放到这一块。 123456789101112131415161718192021# 占位x_images = tf.placeholder(tf.float32,[None,32,32,3],name=&#x27;x_images&#x27;)y = tf.placeholder(tf.float32,[None,1],name=&#x27;y&#x27;)keep_prob = tf.placeholder(tf.float32,name=&#x27;keep_prob&#x27;)# 模型创建y_conv = create(x_images,keep_prob)# 定义损失函数、预测函数和训练过程pred = tf.round(y_conv,name=&#x27;predict&#x27;)cross_entropy = tf.reduce_mean(tf.reduce_mean(tf.square(y_conv-y)),name=&#x27;cross_entropy&#x27;)train_step = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(cross_entropy)# 多分类定义准确率# correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))# correct_prediction = tf.cast(correct_prediction, tf.float32)# accuracy = tf.reduce_mean(correct_prediction,name=&#x27;accuracy&#x27;)# 二分类定义准确率correct_prediction = tf.equal(pred,y)correct_prediction = tf.cast(correct_prediction, tf.float32)accuracy = tf.reduce_mean(correct_prediction,name=&#x27;accuracy&#x27;) 开始训练训练目标：训练集{batch_x,batch_y}100%正确 训练集：从{train_x，train_y}中抽取20对 每10次迭代打印并记录一次loss&amp;acc值 1234567891011121314151617181920212223242526272829saver = tf.compat.v1.train.Saver()# 为保存模型做准备with tf.Session() as sess: sess.run(tf.compat.v1.global_variables_initializer()) step = 1 acc=0 while acc!=1:# 正确率达到100%才结束训练 batch_x,batch_y = next_batch(train_x,train_y,20) # print(batch_y) _ = sess.run(train_step,feed_dict=&#123;x_images: batch_x, y: batch_y, keep_prob: 0.75&#125;) if step % 10 == 0: predt,acc,loss=sess.run([pred,accuracy,cross_entropy],feed_dict=&#123;x_images: batch_x, y: batch_y, keep_prob: 1.&#125;) print (&#x27;step:%d,train loss:%f&#x27; % (step,loss)) print(&#x27;train accuracy:%f&#x27; % acc) # 把训练损失的变化记录到本地，以便于以后的查阅 with open(&quot;trainloss.txt&quot;,&quot;a+&quot;) as f: f.write(&#x27;step:%d,train loss:%f\\n&#x27; % (step,loss)) # ---下面这个部分是为了接下来的误差、准确率的可视化--- if step==10: l = np.array(loss) a = np.array(acc) s = np.array(step) else: l = np.append(l,np.array(loss)) a = np.append(a,np.array(acc)) s = np.append(s,np.array(step)) # ---结束可视化数据的收集--- step += 1 saver.save(sess,&quot;./model/net.ckpt&quot;)# 当训练完成，把参数保存下来 训练过程的可视化使用以下代码 12345678910plt.plot(s,l)plt.title(&#x27;step-loss&#x27;)plt.xlabel(&#x27;step&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show()# -------loss&amp;&amp;acc---------plt.plot(s,a)plt.title(&#x27;step-acc&#x27;)plt.xlabel(&#x27;step&#x27;)plt.ylabel(&#x27;acc&#x27;)plt.show() 效果如图： KDUrJH.png 最后：本次实验中训练次数较少，且没有设置测试集或验证集，因此仅能作为参考，具体项目切不可如此。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"python3下安装pip最简单的方法","slug":"骚操作/2019-10-24-python3下安装pip最简单的方法","date":"2019-10-24T12:14:00.000Z","updated":"2021-08-14T08:21:52.000Z","comments":true,"path":"2019/10/24/骚操作/2019-10-24-python3下安装pip最简单的方法/","link":"","permalink":"https://lankning.github.io/2019/10/24/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-10-24-python3%E4%B8%8B%E5%AE%89%E8%A3%85pip%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"使用一个.py脚本自动安装，非常简单！ 核心步骤： 1wget https://bootstrap.pypa.io/get-pip.py","text":"使用一个.py脚本自动安装，非常简单！ 核心步骤： 1wget https://bootstrap.pypa.io/get-pip.py 一、准备工作安装好Python3和wget，如果没有安装好，就输入下面的指令安装。 1sudo apt-get install python3 wget 二、下载安装pip的脚本Bootstrap是美国Twitter公司的设计师Mark Otto和Jacob Thornton合作基于HTML、CSS、JavaScript 开发的简洁、直观、强悍的前端开发框架。不知道为啥可以从它的网站上下载这个脚本。 1wget https://bootstrap.pypa.io/get-pip.py 三、安装以及错误解决！python运行它！ 1sudo python3 get-pip.py 安装结束，可以正常运行pip了。 安装报错： 我安装时报错 原因是没有安装python-distuils这个组件，安装一下就好了 1sudo apt-get install python3-distutils 效果展示","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"deepin上软件推荐","slug":"小技巧/2019-10-22-deepin上软件推荐","date":"2019-10-22T12:14:00.000Z","updated":"2021-08-14T08:14:28.000Z","comments":true,"path":"2019/10/22/小技巧/2019-10-22-deepin上软件推荐/","link":"","permalink":"https://lankning.github.io/2019/10/22/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-10-22-deepin%E4%B8%8A%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/","excerpt":"一开始是因为win10专业版过期了，也不想在用盗版的路上越走越远，所以给电脑重置了deepin系统，截止到今天用了将近二十天了。虽然生态还是比不上windows10，但基本日常软件都有linux版或者替代品，以此篇做总结。","text":"一开始是因为win10专业版过期了，也不想在用盗版的路上越走越远，所以给电脑重置了deepin系统，截止到今天用了将近二十天了。虽然生态还是比不上windows10，但基本日常软件都有linux版或者替代品，以此篇做总结。 一、办公软件1、WPS全套 – 代替MSOffice金山公司专门为linux开发，系统自带，包括word&#x2F;ppt&#x2F;excel&#x2F;pdf四个组件。 与Windows版本的基本一致，有些许差别，比如没有划词翻译等。 一般办公使用完全够了。 2、GIMP – 代替PhotoShop应用市场有，与Windows的PS版本对应，是开源的。布局、功能与PS基本一致，很容易上手。虽然有大神做出了PS的wine版，然而终究不如一键安装的GIMP方便。 3、雷鸟邮件Thunderbird 是一款免费的电子邮件应用程序，是Mozilla公司发布的开源邮件客户端。 软件配置简单，定制自由—还附有强大功能（反垃圾、反钓鱼等）！虽然界面有些简陋，但是可以自己换外观。 二、截图录屏等1、自带截图区域截图快捷键：Ctrl+Alt+A 全屏截图快捷键：PrtSC键 2、自带录屏可以选择保存为mp4还是gif格式，缺点是不能录入声音 3、Kazam小巧方便，功能强大。 可以区域录制视频，可以录入声音，可以录制中暂停。 4、OneShot Vedio Editor视频剪辑工具，应用市场有下载。大概类似于Pr，但是我不会用。 三、即时通讯1、QQ（wine版）应用市场可以下载，由于是wine版，所以运行起来比较慢。 有一个bug：聊天使用截图的时候双击无法放到聊天窗口，要先保存再手动发图。 2、微信应用市场下载，完美支持。 3、TIM应用市场下载量第一 四、远程控制1、Teamviewer应用市场下载，远程控制神器。 2、RemminaRemmina是一个用GTK +编写的远程桌面客户端，旨在对需要在大型显示器或小型上网本前使用大量远程计算机的系统管理员和旅行者有用。 Remmina在集成且一致的用户界面中支持多种网络协议。 目前，RDP，VNC，SPICE，NX，XDMCP，SSH和EXEC受支持.Remmina是一个用GTK +编写的远程桌面客户端，旨在对需要在其中的许多远程计算机上工作的系统管理员和旅行者有用 大型显示器或小型上网本。 Remmina在集成且一致的用户界面中支持多种网络协议。 当前支持RDP，VNC，SPICE，NX，XDMCP，SSH和EXEC。 五、下载1、百度网盘应用市场有一个wine版，现在官方出了linux版。好像不怎么限速，很爽。 2、迅雷迅雷是迅雷公司开发的一款基于多资源超线程技术的下载软件，作为“宽带时期的下载工具”，迅雷针对宽带用户做了优化，并同时推出了“智能下载”的服务。迅雷利用多资源超线程技术基于网格原理，能将网络上存在的服务器和计算机资源进行整合，构成迅雷网络，通过迅雷网络各种数据文件能够传递。多资源超线程技术还具有互联网下载负载均衡功能，在不降低用户体验的前提下，迅雷网络可以对服务器资源进行均衡。","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"解决deepin下百度网盘一直缓冲的问题","slug":"小技巧/2019-10-22-解决deepin下百度网盘一直缓冲的问题","date":"2019-10-22T12:14:00.000Z","updated":"2021-08-14T08:14:00.000Z","comments":true,"path":"2019/10/22/小技巧/2019-10-22-解决deepin下百度网盘一直缓冲的问题/","link":"","permalink":"https://lankning.github.io/2019/10/22/%E5%B0%8F%E6%8A%80%E5%B7%A7/2019-10-22-%E8%A7%A3%E5%86%B3deepin%E4%B8%8B%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E4%B8%80%E7%9B%B4%E7%BC%93%E5%86%B2%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"百度网盘推出了linux版本，我在官网下载安装之后在deepin上面完美运行，美滋滋… 然而好景不长，当我关掉之后再次打开时，百度网盘就陷入了一直缓冲的状态。如封面图。","text":"百度网盘推出了linux版本，我在官网下载安装之后在deepin上面完美运行，美滋滋… 然而好景不长，当我关掉之后再次打开时，百度网盘就陷入了一直缓冲的状态。如封面图。 亲测：当出现如下情况时，打开命令终端输入以下命令即可 1sudo rm -rf ~/baidunetdisk 将baidunetdisk这个文件夹移除以后又可以正常登录了。 参考路径： 1、百度网盘(Linux)版本最近突然打不开了…【已解决】","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[],"keywords":[{"name":"小技巧","slug":"小技巧","permalink":"https://lankning.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"如何在Hexo中使用本地图片","slug":"学习笔记/2019-10-21-如何在Hexo中使用本地图片","date":"2019-10-21T13:14:00.000Z","updated":"2021-08-14T09:03:40.000Z","comments":true,"path":"2019/10/21/学习笔记/2019-10-21-如何在Hexo中使用本地图片/","link":"","permalink":"https://lankning.github.io/2019/10/21/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-10-21-%E5%A6%82%E4%BD%95%E5%9C%A8Hexo%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/","excerpt":"在hexo中新建.md文件写markdown的时候希望插入本地图片，而当使用hexo generate命令之后发现生成的网页中根本没有相应的图片。这个时候该怎么办呢？ 办法一：从路径入手，虽然比较笨笨，但目前看来还算行之有效。 办法二：简单，使用图床服务。","text":"在hexo中新建.md文件写markdown的时候希望插入本地图片，而当使用hexo generate命令之后发现生成的网页中根本没有相应的图片。这个时候该怎么办呢？ 办法一：从路径入手，虽然比较笨笨，但目前看来还算行之有效。 办法二：简单，使用图床服务。 如果我有两篇文章要写，第一篇标题是“如何撩妹”，第二篇的题目是“如何哄女孩开心” 办法一详细步骤如下： 在_posts路径下新建两篇文章对应名字的文件夹。当在markdown写文章的时候，把本地图片放到对应的文件夹里面。 文件夹结构如下所示： _posts&#x2F; 如何撩妹.md 如何撩妹&#x2F; 如何哄女孩开心.md 如何哄女孩开心&#x2F; 文章写好后，使用”hexo generate”命令自动生成静态网页。 我们进入到“public”文件夹里面看，文章在“.&#x2F;2019&#x2F;10&#x2F;21&#x2F;如何撩妹”和“.&#x2F;2019&#x2F;10&#x2F;21&#x2F;如何哄女孩开心”这个文件夹里面。 一开始的时候文章.md文件和对应的图片文件夹是平行的，而这里跟文章同级的目录并没有对应的照片文件夹。 所以我们将“如何撩妹&#x2F;”和“如何哄女孩开心&#x2F;”这个文件夹从“source&#x2F;_posts&#x2F;“文件夹复制到对应的“public”文章目录下，和html文件同级。如图： 办法二详细步骤如下： 百度图床服务，我这里使用的是“路过图床“ 注册一个账号 将要使用的图片上传到图床，可以得到图片的地址，如图： 接下来就能在markdown里面应用啦！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lankning.github.io/tags/Hexo/"}],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"使用samba搭建内网文件服务器","slug":"骚操作/2019-10-21-使用samba搭建内网文件服务器","date":"2019-10-21T12:14:00.000Z","updated":"2021-08-14T08:16:04.000Z","comments":true,"path":"2019/10/21/骚操作/2019-10-21-使用samba搭建内网文件服务器/","link":"","permalink":"https://lankning.github.io/2019/10/21/%E9%AA%9A%E6%93%8D%E4%BD%9C/2019-10-21-%E4%BD%BF%E7%94%A8samba%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"近期被百度网盘的限速困扰，再加上淘宝上各种家用nas的广告轰炸，于是就起了一个自建nas的想法。作为尝试的第一步，应该是掌握在linux上搭建文件服务器的方法，于是就有了这篇小短文。","text":"近期被百度网盘的限速困扰，再加上淘宝上各种家用nas的广告轰炸，于是就起了一个自建nas的想法。作为尝试的第一步，应该是掌握在linux上搭建文件服务器的方法，于是就有了这篇小短文。 环境： 安卓手机（已root）上面运行linux deploy 电脑系统deepin，通过ssh连接手机 第一步：安装Samba输入命令： 1sudo apt-get install samba 没有意外的话安装就完成了。 第二步：新建（或制定）共享文件夹 新建共享文件夹 在这里我在home目录下新建一个share文件夹 1sudo mkdir /home/share 给予共享文件夹权限 1sudo chmod 777 /home/share 第三步：创建登录账号 添加一个账户名，比如新账户名叫做pony 1sudo useradd pony 为新建的账户添加密码，输入此命令后会确认两遍密码 1sudo smbpasswd -a pony 第四步：修改配置文件 使用vim打开配置文件，一般配置文件的目录都是固定的 1sudo vim /etc/samba/smb.conf 在开头的 [gobal] 区域添加 1security = user 在最后添加一段 注解： comment是欢迎语，随便你写什么； path路径要填入自己第二步新建文件夹的地址； 剩下的是配置能否写入等权限，不用改动 1[share]comment = Welcome to SMB server!path = /home/sharebrowseable = yeswritable = yesguest ok = yes 第五步：启动smb输入以下命令即可启动smb 12sudo service smbd restart 现在，在你的文件管理器里面键入”smb:&#x2F;&#x2F;ip地址&#x2F;share”就能看到你的文件服务器里的内容啦。附图如下： 2019年11月份 Windows下实测写入速度，还是比较给力的：","categories":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}],"tags":[],"keywords":[{"name":"骚操作","slug":"骚操作","permalink":"https://lankning.github.io/categories/%E9%AA%9A%E6%93%8D%E4%BD%9C/"}]},{"title":"如何在电脑上安装TensorFlow","slug":"学习笔记/2019-10-20-如何在电脑上安装TensorFlow","date":"2019-10-20T13:14:00.000Z","updated":"2021-08-14T08:00:10.000Z","comments":true,"path":"2019/10/20/学习笔记/2019-10-20-如何在电脑上安装TensorFlow/","link":"","permalink":"https://lankning.github.io/2019/10/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-10-20-%E5%A6%82%E4%BD%95%E5%9C%A8%E7%94%B5%E8%84%91%E4%B8%8A%E5%AE%89%E8%A3%85TensorFlow/","excerpt":"Tensorflow是谷歌的一个深度学习方面的开源框架，其源代码见诸于github。1.x版本入门的时候有点难度，需要配置很多参数才可以；2.x版本貌似有了很大改观，在2.x中，官方非常提倡使用keras。无论是1还是2版本，总体来说还是大大方便了我们实现各种神经网络的。","text":"Tensorflow是谷歌的一个深度学习方面的开源框架，其源代码见诸于github。1.x版本入门的时候有点难度，需要配置很多参数才可以；2.x版本貌似有了很大改观，在2.x中，官方非常提倡使用keras。无论是1还是2版本，总体来说还是大大方便了我们实现各种神经网络的。 不管怎么说，让我们首先安装tensorflow吧（现在已经默认2.0版本）。 1. Windows系统 首先需要安装python（最新的版本是python3.8） ‘win+R’ 组合键打开命令提示符，输入‘cmd’ 进入小黑框 输入 ‘pip install tensorflow’ ，等待安装结束即可 如果需要安装gpu版本的，查询自己的电脑GPU计算能力等是否符合tensorflow的GPU版本要求，确认无误后输入命令 ‘pip install tensorflow-gpu’。结束后需要配置CUDA等，这部分可以参考百度PaddlePaddle的安装说明。 2. Deepin系统 Deepin系统很好，自带python2和python3，直接在终端输入 ‘pip3 install tensorflow’ 即可 Deepin对显卡的驱动好像不怎么样，所以如果有同学知道怎么在deepin上面配置tensorflow的GPU版本麻烦告诉我，谢谢。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"TensorFlow 1.x 卷积等操作的高级封装","slug":"学习笔记/2019-10-20-TensorFlow_1.x_卷积等操作的高级封装","date":"2019-10-20T12:14:00.000Z","updated":"2021-08-14T08:00:40.000Z","comments":true,"path":"2019/10/20/学习笔记/2019-10-20-TensorFlow_1.x_卷积等操作的高级封装/","link":"","permalink":"https://lankning.github.io/2019/10/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019-10-20-TensorFlow_1.x_%E5%8D%B7%E7%A7%AF%E7%AD%89%E6%93%8D%E4%BD%9C%E7%9A%84%E9%AB%98%E7%BA%A7%E5%B0%81%E8%A3%85/","excerpt":"前一段时间写了一些程序，自己搭建卷积神经网络的时候需要用到不少tensorflow的自带低级封装还有一些常用的读取操作等，虽然已经有了keras等高级封装可以直接调用，但还是想自己写一写。 tensorflow版本：1.14","text":"前一段时间写了一些程序，自己搭建卷积神经网络的时候需要用到不少tensorflow的自带低级封装还有一些常用的读取操作等，虽然已经有了keras等高级封装可以直接调用，但还是想自己写一写。 tensorflow版本：1.14 1. 卷积函数1234567891011121314151617def weight_variable(shape): initial = tf.truncated_normal(shape, mean=0, stddev=0.01)#正态初始化 return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)def conv2d(x, W):#步长为1 return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&#x27;SAME&#x27;)def conv(x,next_depth): depth = x.get_shape()[-1].value w = weight_variable([3, 3, depth, next_depth]) b = bias_variable([next_depth]) r = tf.nn.relu(tf.nn.bias_add(conv2d(x, w), b)) return r 2. 池化函数12def max_pool(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding=&#x27;SAME&#x27;) 3. 读取图片顺便加标签 文件夹结构（假设目录下面有17个文件夹，每个文件夹里面有若干对应种类的图片）： 12345678910./–./dogs–./cats–./tigers… 读取的图片压缩为32323的尺寸，便于神经网络的快速迭代 1234567891011121314151617181920212223242526272829303132333435363738# 调用skimage的函数from skimage.io import imreadfrom skimage.transform import resizedef load_images(path): contents = os.listdir(path) classes = [each for each in contents if os.path.isdir(os.path.join(path,each))] print(&#x27;目录下有%s&#x27; % classes) # 用labels来存储图片的类别 labels = [] # images数组用来存储图片数据 images = [] # 对每个不同种类读取图片到list并且+标签 for each in classes: class_path = os.path.join(path,each) files = os.listdir(class_path) print(&quot;Starting &#123;&#125; images&quot;.format(each),&#x27;数量为&#x27;,len(files)) for ii, file in enumerate(files, 1): # 载入图片并放入batch数组中 img = imread(os.path.join(class_path, file)) img = img / 255.0 # print(img.shape) img = resize(img, (32, 32)) # print(img.shape) images.append(img.reshape((32,32,3))) labels.append(each) images = np.array(images) #将labels的list形式转换为one_hot_label from sklearn.preprocessing import LabelBinarizer lb = LabelBinarizer() lb.fit(labels) labels_vecs = lb.transform(labels) print(&#x27;总共读取了%d张图片&#x27;%images.shape[0]) # print(labels,labels_vecs) return images,labels_vecs # 返回图片以及对应的标签 4. 神经网络模型的建立下面的示例结构为：3层卷积+2层全连接 图片的输入x_images的shape是32323 123456789101112131415161718192021222324252627282930313233343536373839404142434445def create(x_images,keep_prob):#x_images的shape是32,32,3 h = 32 w = 32 d = 3 #first layer conv1 = conv(x_images,16) pool1 = max_pool(conv1) h = int(np.ceil(h/2)) w = int(np.ceil(w/2)) d = 16 #second layer conv2 = conv(pool1,32) pool2 = max_pool(conv2) h = int(np.ceil(h/2)) w = int(np.ceil(w/2)) d = d*2 #third layer conv3 = conv(pool2,64) pool3 = max_pool(conv3) h = int(np.ceil(h/2)) w = int(np.ceil(w/2)) d = d*2 #first fully layer w_fc1 = weight_variable([h*w*d,1024]) b_fc1 = bias_variable([1024]) h_conv_flat = tf.reshape(pool3,[-1,h*w*d]) h_fc1 = tf.nn.relu(tf.nn.bias_add(tf.matmul(h_conv_flat, w_fc1), b_fc1)) h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #second fully layer w_fc2 = weight_variable([1024,1024]) b_fc2 = bias_variable([1024]) h_fc2 = tf.nn.relu(tf.nn.bias_add(tf.matmul(h_fc1_drop, w_fc2), b_fc2)) h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob) #third full layer w_fc3 = weight_variable([1024,17]) b_fc3 = bias_variable([17]) h_fc3 = tf.add(tf.matmul(h_fc2_drop, w_fc3), b_fc3,name=&#x27;h_fc3&#x27;) out = tf.nn.softmax(h_fc3,name=&#x27;out&#x27;) print(&#x27;模型建立好了！&#x27;) return out","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[],"keywords":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://lankning.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]}]}